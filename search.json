[
  {
    "objectID": "ray_tracing.html#ray-paths-and-wave-guide-effects",
    "href": "ray_tracing.html#ray-paths-and-wave-guide-effects",
    "title": "Ray Tracing",
    "section": "Ray paths and wave-guide effects",
    "text": "Ray paths and wave-guide effects\n\nThe discussion before means that reading the sound speed profile\nAssuming sound speed profile only varies with depth (generaly true for range &lt; \\(20\\) km\nSeveral rays pattern can appear depending on the source depth\n\n\n\n\n\n\n\n\n\n\n\n\nSSP is measured: note the change in SSP at the surface (higher at 30m than at 0m)\n\nLet’s zoom in:\n\nSource is at the surface\n\nRays will bend upwards until they hit the surface and will be reflected down, etc.\nNot all rays will bend upwards so much that they hit the surface. It depends on the initial ray angle.\n\n&lt;/tr&gt;&lt;/table&gt;\nAn approximation is shown in the picture below.\nThis is called surface sound channel.\n\n\n\n\n\n\n\n&lt;/tr&gt;&lt;/table&gt;\nSource at the minimum of the sound speed: internal sound channel\n\nRay pointing downwards propagates within regions where sound speed increases: angle decreases, and bend upwards.\n\nDepending on the initial angles some rays will graze or hit the sea bottom.\n\nRay pointing upwards propagates within regions where sound speed increases: angle decreases, and bend downwards\n\nDepending on the initial angle, some rays might get inside the surface channel\n\nIntuitively, rays tend to go to the minimum of the sound speed.\n\n\n\n\n\n\n\n\n&lt;/tr&gt;&lt;/table&gt;    \nBottom limited sound channel\n\nUpwards rays will bend downwards and have total reflections (reflections generated by refraction)\nDownwards rays do not have total reflections and they all hit the seabed.\n\n\n\n\n\n\n\n\n&lt;/tr&gt;&lt;/table&gt;    Let’s go back to our experimental picture:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRay bending is possible only if the medium is not isotrope (speed changes along some directions, i.e. depth)\nAlong each of the rays travels our harmonic wave.\nSome rays will go through the same point in space and they all interfere.\nWe saw this already with the Lloys’ mirror case. But in that case we only had two rays and was easier to describe. All these rays interfere with each other (some constructively, some other destructively).\nUnisotropic propagation contributes to propogation loss.\nWhen we have multiple paths that the sound can take (see for instance, internal sound channel, km 5) is called multi-path structure.\nMulti-path can causes interference patterns (constructive or destructive) - i.e. an additinal loss factor.\nConvergent zones are all areas where interference patterns is in-phase (i.e. constructive)\n\nIntruitively, if we start with uniformely spaced rays: - Denser rays (at least in some areas) should correspond to maxima (constructive interference) - Sparser rays corresponds to minima - The density of the rays corresponds to the acoustic intensity",
    "crumbs": [
      "Ray Tracing"
    ]
  },
  {
    "objectID": "ray_tracing.html#sofar-sound-fixing-and-ranging-channel",
    "href": "ray_tracing.html#sofar-sound-fixing-and-ranging-channel",
    "title": "Ray Tracing",
    "section": "SOFAR (SOund Fixing And Ranging) Channel",
    "text": "SOFAR (SOund Fixing And Ranging) Channel\n\nGeneralises the internal sound channel\nCorresponds to the global minimum of the SSP\nIn deep water (&gt;600m), the global minimum always exists\n\n\n\n\n\n\n\n\n\nSound can travel thousands of km without significant loss. In some cases even half way around the world (Australia to Bermuda)\nTo compare, similar sound level would only travel kms in air\n\n\nHistory of the SOFAR Channel\nAdapted from History of the SOFAR channel and Sound travel in the SOFAR channel.\n\nIn the spring of 1944, ocean scientists, Maurice Ewing and J. Worzel, departed Woods Hole, Massachusetts, aboard the research vessel R/V Saluda to test a theory that predicted that low-frequency sound should be able to travel long distances in the deep ocean. \nA deep receiving hydrophone was hung from R/V Saluda. A second ship dropped 4-pound explosive charges set to explode deep in the ocean at distances up to 900 miles from the R/V Saluda’s hydrophone. Ewing and Worzel heard, for the first time, the characteristic sound of a SOFAR (SOund Fixing And Ranging) transmission, consisting of a series of pulses building up to its climax.\n\n\nimport IPython\n\n\nIPython.display.Audio(\"./mp3/SOFAR1.mp3\")\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nAlthough sound travels away from a sound source in all directions, only sound traveling away from a source on paths that leave the source at specific angles will reach a receiver at a specific location. The sound waves traveling on these different paths have slightly different travel times. A single explosive source will therefore be heard as a number of separate arrivals, leading to the characteristic signature of a SOFAR transmission building up to its climax. The final pulse of sound is typically the loudest and comes from the sound wave that travels nearly on the sound channel axis. Although this sound wave travels the shortest distance, it travels in the region near the sound speed minimum where the sound speed is lowest.",
    "crumbs": [
      "Ray Tracing"
    ]
  },
  {
    "objectID": "ray_tracing.html#surface-duct-and-shadow-zones",
    "href": "ray_tracing.html#surface-duct-and-shadow-zones",
    "title": "Ray Tracing",
    "section": "Surface duct and shadow zones",
    "text": "Surface duct and shadow zones\n\n\n\n\n\n\n\nWhat happens to those rays that get out of the surface duct?\n\nIt depends..if there is a SOFAR channel below.\nNote the presence of an area where there are NO acoustic rays: shadow zone.",
    "crumbs": [
      "Ray Tracing"
    ]
  },
  {
    "objectID": "ray_tracing.html#wrap-up",
    "href": "ray_tracing.html#wrap-up",
    "title": "Ray Tracing",
    "section": "Wrap up",
    "text": "Wrap up\n\nThis is a qualitative analysis: Given a SSP profile, intuitively understand how sound propagates.\nTransmission Loss affects the Signal-to-Noise Ratio:\n\nHigher Loss, Lower SNR\nLowe Loss, Higher SNR\n\nMulti-path structure generates Symbolic Interference\n\nSymbolic interference, often referred to as symbol interference or inter-symbol interference (ISI), occurs when signals from multiple paths interfere with each other. Specifically, the overlapping of symbols from different paths at the receiver can cause the symbols to become indistinct or overlap in time, making it difficult for the receiver to accurately decode the intended message. This interference is a direct result of the multi-path structure of the environment through which the acoustic signals travel.\nWhen signals overlap at the receiver, they sum up and the symbols that the signal is carring interfere with each other.",
    "crumbs": [
      "Ray Tracing"
    ]
  },
  {
    "objectID": "ray_tracing.html#a-very-simple-ray-tracer",
    "href": "ray_tracing.html#a-very-simple-ray-tracer",
    "title": "Ray Tracing",
    "section": "A Very Simple Ray Tracer",
    "text": "A Very Simple Ray Tracer\n\nsource\n\nSoundParticle\n\n SoundParticle (r0, d0, theta0, ssp)\n\n*Models the movement of a sound particle along a ray.\nExample usage:\nsp = SoundParticle(r0=0, d0=50, theta0=np.deg2rad(-1), ssp=ssp)\nprint('Initial conditions:', sp)\n\n# initial state \nr_t, d_t, q_t, c_t = sp.get_state()\nr, d, q, c = [], [], [], []\n\n# simulation times\nt0 = 0\ntf = 4\ndt = 0.01\nfor t in np.arange(t0, tf, dt):  \n    r.append(r_t)\n    d.append(d_t)\n    q.append(q_t)\n    c.append(c_t)\n    sp.move(dt)     \n    r_t, d_t, q_t, c_t = sp.get_state()*\n\nsource\n\n\nSSP\n\n SSP (depths, speeds)\n\nDefines one sound speed profile (depth (m) and speed (m/s) at each depth)\nLet’s try it out.\nBelow there are three different sound speed profiles, similar to those experimentally collected before. Each one gives rise to a different type of propogation.\nTry them all out.\n\n# increasing sound speed (surface duct)\n# ssp = SSP(np.linspace(0, 15, 9), \n#           [1501, 1501.5, 1502, 1502.5, 1503, 1504.5, 1508, 1509, 1510])\n\n# internal sound channel\n# ssp = SSP(np.linspace(0, 15, 9),\n#           [1505, 1504.5, 1503, 1502.5, 1503, 1504.5, 1508, 1509, 1510])\n\n# bottom limited sound channel\nssp = SSP([0, 10, 25, 50, 100, 150, 250],\n          [1501, 1502, 1505, 1490, 1480, 1480, 1485])\n\n\nssp.plot()\nssp.plot_speed_at_depth(10)\n\n\n\n\n\n\n\n\nAnd now we can try what happens when we change the depth of the source using the \\(d0\\) variable: - d0=8m - d0=50m - d0=100m\n\n# theta0: negative angles: downwards\n# theta0: positive angles: upwards\nsp = SoundParticle(r0=0, d0=50, theta0=np.deg2rad(-1), ssp=ssp)\nprint('Initial conditions:', sp)\n\n# initial state \nr_t, d_t, q_t, c_t = sp.get_state()\nr, d, q, c = [], [], [], []\n\n# simulation times\nt0 = 0\ntf = 4\ndt = 0.01\nfor t in np.arange(t0, tf, dt):  \n    r.append(r_t)\n    d.append(d_t)\n    q.append(q_t)\n    c.append(c_t)\n    sp.move(dt)     \n    # print(sp)\n    r_t, d_t, q_t, c_t = sp.get_state()\n    \n##\n## Plot\nplt.scatter(r[0], d[0], color='r', linewidth=3)\nplt.plot(r, np.array(d), color='k')\nplt.ylim((min(ssp._depths), max(ssp._depths)))\nplt.gca().invert_yaxis()\nplt.xlabel('Range (m)')\nplt.ylabel('Depth (m)');\n\nInitial conditions: range (m): 0.00, depth (m): 50.00, angle (deg): -1.00, speed (m/s): 1490.00\n\n\n\n\n\n\n\n\n\nAnd we can plot more rays:\n\nsource_depth_m = 50\n\nfor theta0 in range(5, -5, -1):\n    # theta0: negative angles: downwards\n    # theta0: positive angles: upwards\n    sp = SoundParticle(r0=0, d0=source_depth_m, theta0=np.deg2rad(theta0), ssp=ssp)\n    print('Initial conditions:', sp)\n\n    # initial state \n    r_t, d_t, q_t, c_t = sp.get_state()\n    r, d, q, c = [], [], [], []\n\n    # simulation times\n    t0 = 0\n    tf = 4\n    dt = 0.01\n    for t in np.arange(t0, tf, dt):  \n        r.append(r_t)\n        d.append(d_t)\n        q.append(q_t)\n        c.append(c_t)\n        sp.move(dt)     \n        # print(sp)\n        r_t, d_t, q_t, c_t = sp.get_state()\n\n    ##\n    ## Plot\n    plt.scatter(r[0], d[0], color='r', linewidth=3)\n    plt.plot(r, np.array(d), color='k')\n    plt.ylim((min(ssp._depths), max(ssp._depths)))\n    plt.gca().invert_yaxis()\n    plt.xlabel('Range (m)')\n    plt.ylabel('Depth (m)');\n\nInitial conditions: range (m): 0.00, depth (m): 50.00, angle (deg): 5.00, speed (m/s): 1490.00\nInitial conditions: range (m): 0.00, depth (m): 50.00, angle (deg): 4.00, speed (m/s): 1490.00\nInitial conditions: range (m): 0.00, depth (m): 50.00, angle (deg): 3.00, speed (m/s): 1490.00\nInitial conditions: range (m): 0.00, depth (m): 50.00, angle (deg): 2.00, speed (m/s): 1490.00\nInitial conditions: range (m): 0.00, depth (m): 50.00, angle (deg): 1.00, speed (m/s): 1490.00\nInitial conditions: range (m): 0.00, depth (m): 50.00, angle (deg): 0.00, speed (m/s): 1490.00\nInitial conditions: range (m): 0.00, depth (m): 50.00, angle (deg): -1.00, speed (m/s): 1490.00\nInitial conditions: range (m): 0.00, depth (m): 50.00, angle (deg): -2.00, speed (m/s): 1490.00\nInitial conditions: range (m): 0.00, depth (m): 50.00, angle (deg): -3.00, speed (m/s): 1490.00\nInitial conditions: range (m): 0.00, depth (m): 50.00, angle (deg): -4.00, speed (m/s): 1490.00\n\n\n\n\n\n\n\n\n\nLet’s make it a class to use it later\n\nsource\n\n\nRayTracer\n\n RayTracer (time, source_depth, min_range, thetas, ssp)\n\ntime : simulation time as [t0, tf, dt] source_depth: depth of the source in m min_range: min_range from source in m thetas: range of tx angles (deg). E.g. thetas=range(5, -5, -1) ssp: sound speed profile (defined using class SSP)\n\n# bottom limited sound channel\nssp = SSP([0, 10, 25, 50, 100, 150, 250],\n          [1501, 1502, 1505, 1490, 1480, 1480, 1485])\n\nsource_depth_m = 50\n# simulation times\nt0 = 0\ntf = 4\ndt = 0.01\nrt = RayTracer(time=[t0, tf, dt], \n               source_depth=source_depth_m, \n               min_range=0, \n               thetas=range(5, -5, -1), \n               ssp=ssp)\n\n\nrt.run()",
    "crumbs": [
      "Ray Tracing"
    ]
  },
  {
    "objectID": "intro.html#lab-overview",
    "href": "intro.html#lab-overview",
    "title": "Underwater Systems",
    "section": "Lab overview",
    "text": "Lab overview\n\n\n\n\n\n\nAndrea Munafo\n\n\n\n\n\n\n\nRiccardo Costanzi\n\n\n\n\n\n\n\nAndrea Caiti\n\n\n\n\n\n\n\n\n\n\n\nFrancesco Ruscio\n\n\n\n\n\n\n\nOlga Sambataro\n\n\n\n\n\n\n\nSimone Tani\n\n\n\n\n\n\n\nRobots and Platforms\n\n\n\n\n\n\nAUV Zeno\n\n\n\n\n\n\n\nAUV X300\n\n\n\n\n\n\n\nBlueROV\n\n\n\n\n\n\n\nLAUV\n\n\n\n\n\n\n\nLocations\n\n&lt;iframe src=\"https://isme.unige.it\" width=\"1000\" height=\"700\"&gt;&lt;/iframe&gt;",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#some-recent-and-current-projects",
    "href": "intro.html#some-recent-and-current-projects",
    "title": "Underwater Systems",
    "section": "Some Recent and Current Projects",
    "text": "Some Recent and Current Projects\n\nHuman-Machine Teaming For the Maritime Environment\n\n\n\n\n\n\nHuman-Machine Teaming For the Maritime Environment\n\n\n\n\n\n\n\nMultiple Autonomies\n\n\n\n\n\n\nMOOS-IvP autonomy system and human-machine teaming put into practice at the MIT facilities. (Courtesy of MIT)\n\n\n\n\n\n\n\nUnderwater acoustic source localization using a multi-robot system\n\n\n\n\n\n\nUnderwater acoustic source localization using a multi-robot system",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#whats-in-this-introduction",
    "href": "intro.html#whats-in-this-introduction",
    "title": "Underwater Systems",
    "section": "What’s in this introduction?",
    "text": "What’s in this introduction?\n\nMotivations\nWhy using robots to explore, monitor, inspect, etc. the sea?\nA short and rough description of underwater systems\nThe Topics of the course",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#motivations",
    "href": "intro.html#motivations",
    "title": "Underwater Systems",
    "section": "Motivations",
    "text": "Motivations\n\nScience Questions\n\n\n\n\nClimate Change\nClimate change, as we’ve seen in recent news and scientific reports, is a global phenomenon with far-reaching impacts on both terrestrial and aquatic ecosystems.\n\nGlobal Temperature Rise\nClimate change is fundamentally driven by the increase in global average temperatures year after year. This rise in temperature is not a uniform process but varies across different regions and timescales.\n\n\n\n\n\n\nThe plot illustrating this is the global average temperature relative to the pre-industrial average (1850-1900) shown above and taken from BBC | Global warming set to break key 1.5C limit for first time\nIn this plot: - Zero on the Vertical Axis: This represents a 50-year average temperature leading up to the 20th century. - Red and Blue Bars: These bars show annual average temperatures relative to the zero point. Red bars indicate years warmer than the average, and blue bars indicate cooler years.\nIt’s important to note that a global temperature rise of about 1.1 degrees Celsius over the last century might seem small, but it signifies a substantial energy imbalance in the Earth’s system. This energy imbalance is a key contributor to various climatic changes.\nThe energy required to raise the temperature of the Earth by one degree Celsius is immense.\n\n\n\nEffects of Temperature Rise\nThe consequences of this temperature rise are diverse, including:\n\nExtreme Weather Events: Such as droughts and floods.\nMelting Glaciers and Polar Ice Caps: Leading to rising sea levels.\nImpact on Marine Life: Changes in ocean temperatures and chemistry affect marine ecosystems.\n\n\nThe Role of Human Activities\nHuman activities, particularly the burning of fossil fuels like coal, oil, and gas, have been central to the rise in global temperatures.\n\n\n\n\n\n\nBurning fossil fuels releases greenhouse gases (GHGs) like carbon dioxide (CO2), methane (CH4), and others into the atmosphere. These gases trap heat from the sun, leading to a warming effect known as the greenhouse effect.\n\n\n\n\n\n\n\n\n\n\nMeasurements of air in ice cores show that for the past 800,000 years up until the 20th century, the atmospheric CO2 concentration stayed within the range 170 to 300 parts per million (ppm), making the recent rapid rise to more than 400 ppm over 200 years particularly remarkable.\n\nsee also here and here.\nThe levels of CO2 in the atmosphere have been remarkably stable over millennia but have shown an unprecedented rise in the last century. Understanding this requires examining historical data:\n\nIce Core Data: Scientists analyze ice cores to measure historical CO2 levels. These cores contain air bubbles that serve as time capsules, preserving atmospheric samples from the past.\nTrends Observed: Historical data shows a dramatic increase in CO2 levels, especially in recent decades. This rise is directly linked to human activities, particularly the burning of fossil fuels.\nAcceleration of CO2 Increase: The rate of increase in CO2 levels is not constant but accelerating. This acceleration implies a continually increasing rate of heat trapping in the atmosphere.\n\nSee also NASA | Ice Cores\n\n\nGlobal Temperature Anomalies\nLobal warming is not uniform across the Earth. Variations exist due to factors like geographical location, land-sea distribution, and atmospheric circulation patterns.\n\nfrom IPython.display import YouTubeVideo\n\nYouTubeVideo('LwRTw_7NNJs', width=800, height=600)\n\n\n        \n        \n\n\n\n\nOceans Are Absorbing Almost All of the Globe’s Excess Heat\n\n\n\n\n\n\n\nMore than 90 percent of the excess heat retained by the Earth as a result of increased greenhouse gases has been absorbed by the oceans.\nOcean temperatures have been consistently rising for at least three decades.\n\nMarine Robotics and Underwater Systems are central to this problem\n\n\n\n\n\n\n\nMIT Understanding the Arctic. Ref. https://news.mit.edu/2021/navigating-beneath-arctic-ice-0423\n\n\n\n\n\n\n\n\nCelebrating Marie Tharp\n\nAmerican geologist and oceanographic cartographer who helped prove the theories of continental drift.\nShe co-published the first world map of the ocean floors.\nOn Nov 21, 1998, the Library of Congress named Tharp one of the greatest cartographers of the 20th century.\n\n\n&lt;iframe src=\"https://www.google.com/doodles/celebrating-marie-tharp\" width=\"1000\" height=\"600\"&gt;&lt;/iframe&gt;\n\n\n\n\n\n\n\n\n\n\nManuscript painting of Heezen-Tharp “World ocean floor” map by Berann (~1955)",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#finding-the-endurance",
    "href": "intro.html#finding-the-endurance",
    "title": "Underwater Systems",
    "section": "Finding the Endurance",
    "text": "Finding the Endurance\nThe wreck of Sir Ernest Shackleton’s ship ‘Endurance’ has been found off the coast of Antarctica more than a century after it sank.\nHistorian Dan Snow, who is a member of the Endurance22 expedition team, said the discovery was ‘like a miracle’ and the ship is ‘almost perfectly preserved’\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsee this for more!",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#blackbox-recovery",
    "href": "intro.html#blackbox-recovery",
    "title": "Underwater Systems",
    "section": "Blackbox recovery",
    "text": "Blackbox recovery\n\n\n\n\n\n\nAir France 447 black box recovey\n\n\n\n\n\nAir France 447 crash from Rio to Paris, June 1st, 2009\n\n\n\n\n\n\n&lt;/tr&gt;\n\n\n\n\n\n\n\n\n\nCountries involved - Origin - Destination - Airspace at accident location - Airline company - Engines manufactures - Insurance companies - Passengers citizenship\nRecovery\n\n13 aircrafts and 2 helicopters (Brasil, France, USA, Spain)\n8 Ships (Brasil, France, USA)\n2 6000m Manned Submarine (the Nautile)\n1 Nuclear Submarine (France)\n3 Autonomous Underwater Vehicles (AUVs)\n1 Remotely Operated Vehicle (ROV)\n1 million \\(km^2\\) of ocean explored\n\nAccording to Wikipedia, the continental United States of America (the 48 states between Canada and Mexico) is 8,080,464.4 square kilometers.\n\ncost \\(\\approx 30\\) MEuros (in 2009)\ncompleted 2Y after the crash\n\n&lt;td&gt; &lt;img src=\"./images/1.introduction/6.remora.png\" alt=\"black-box\" style=\"height: 250px;\"/&gt; &lt;/td&gt; \n&lt;/tr&gt;",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#installation-of-procution-well-jumper",
    "href": "intro.html#installation-of-procution-well-jumper",
    "title": "Underwater Systems",
    "section": "Installation of Procution Well Jumper",
    "text": "Installation of Procution Well Jumper\n\n\n\n\n\n\n\nWell Jumper Installation\n\n\n\n\n\n\nVehicle localised using acoustic baselines",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#operating-rovs",
    "href": "intro.html#operating-rovs",
    "title": "Underwater Systems",
    "section": "Operating ROVs",
    "text": "Operating ROVs\n\nRemotely operated vehicles, or ROVs, allow us to explore the ocean without actually being in the ocean.\nThese underwater machines are controlled by a person typically on a surface vessel, using a joystick in a similar way that you would play a video game. A group of cables, or tether, connects the ROV to the ship, sending electrical signals back and forth between the operator and the vehicle.\nMost ROVs are equipped with at least a still camera, video camera, and lights, meaning that they can transit images and video back to the ship. Additional equipment, such as a manipulator or cutting arm, water samplers, and instruments that measure parameters like water clarity and temperature, may also be added to vehicles to allow for sample collection.\nFirst developed for industrial purposes, such as internal and external inspections of underwater pipelines and the structural testing of offshore platforms, ROVs are now used for many applications, many of them scientific.\nThey have proven extremely valuable in ocean exploration and are also used for educational programs at aquaria and to link to scientific expeditions live via the Internet.\nROVs range in size from that of a small computer to as large as a small truck. Larger ROVs are very heavy and need other equipment such as a winch to put them over the side of a ship and into the water.\nWhile using ROVs eliminates the “human presence” in the water, in most cases, ROV operations are simpler and safer to conduct than any type of occupied-submersible or diving operation because operators can stay safe (and dry!) on ship decks.\nROVs allow us to investigate areas that are too deep for humans to safely dive themselves, and ROVs can stay underwater much longer than a human diver, expanding the time available for exploration.\n\n\n\n\n\n\n\nWHOI Engineer Jared Schwartz pilots the remotely operated vehicle, Saab Seaeye Falcon to investigate an unrecovered mooring anchor. (Photo by Daniel Hentz, Woods Hole Oceanographic Institution). Ref. https://www.whoi.edu/news-insights/content/flight-of-the-underwater-falcon/\n\n\n\n\n\n\n\n\n\n\n\n\n\nOld approach:\n\nOff-shore operator acts on the vehicle\nOff-shore operator controls the arm motors directly (typically limited number of joints)\nInteractions between arm and vehicle’s body\nVoice coordination between the two\nManned Visual Feedback\n\n\nROV More recently\n\n\n\n\n\n\n&lt;figcaption&gt;Video by the National Oceanography Centre of the UK. \n    Ref. https://www.youtube.com/watch?v=d6_dc25U4Uk&lt;/figcaption&gt;\n&lt;/figure&gt;\n\n\nOn the18 August 2012 Isis, the UK’s iconic robotic submarine or ROV (Remotely Operated Vehicle) entered the cold waters of the Atlantic 300 miles from the coast of Spain. The NERC research vessel RRS James Cook carried the newly rebuilt vehicle on its first sea trials after an accident in early 2011 seriously damaged the research ROV.\n\nStructured environments\n\nOperators know how the environment looks like\nROV have automatic controls for:\n\nstation keeping (attitude and position) using up to 8 motors (depends on how many DoF they can control)\n\nForce feedback to control the arm\nOperator acts on a representation of the manipulator (task space)\n\n\n\n\nWorking with ROVs\n\n13 people / 24h\n\n8 Pilot/Technicians (4h shift)\n4 Supervisors (4h shift)\n1 Superintendent (on call)\n\nHow long onboard?\n\n4 to 6 weeks\nROV crews work 6h 7/7\n\n\n\n\n\n\n\n\nPhoto by Woods Hole Oceanographic Institution. Ref. https://www.whoi.edu/press-room/news-release/whois-rov-jason-assists-with-the-successful-recovery-of-two-other-underwater-vehicles/\n\n\n\n\nOcean Exploration Trust’s ROV Hercules and Argus were stranded on the seafloor last week, but were recovered thanks to cooperation from several ocean science and exploration institutions Woods Hole, MA — On Thursday, September 2, 2021 the remotely operated vehicle (ROV) Jason succeeded in helping recover two other underwater vehicles, ROV Hercules and Argus, that were stranded on the seafloor off the coast of British Columbia last week when their tether to the surface broke. The operation came about as a result of close collaboration and mutual aid that are a hallmark of the ocean science and exploration community and the maritime community as a whole.",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#renewable-energy",
    "href": "intro.html#renewable-energy",
    "title": "Underwater Systems",
    "section": "Renewable energy",
    "text": "Renewable energy\n\nMarine energy: Tidal stream and wave power\n\n\n\n\n\n\n\n&lt;figcaption&gt;Video by the Alstom.&lt;/figcaption&gt;\n&lt;/figure&gt;\n\n\n\nPower/communication cables\nFisheries and aquaculture\n\n\n\n\n\n\n\nNTNU AMOS - Centre for Autonomous Marine Operations and Systems\n\n\n\n\n\nFood\nHealth\nSecurity\nSafe\n\n\n\n\n\n\n\n&lt;figcaption&gt;Video by Google.&lt;/figcaption&gt;\n&lt;/figure&gt;\n\n\n\nOther applications\n\nHarbour Security\nMine-Counter Measurements\nIntelligence, Surveillance and Reconnaissance\nInspections, Survey, Monitoring\n\n\nfrom IPython.display import YouTubeVideo\n\ndisplay(YouTubeVideo('tefDNodT1jY', width=800, height=600))",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#autonomous-vehicles",
    "href": "intro.html#autonomous-vehicles",
    "title": "Underwater Systems",
    "section": "Autonomous Vehicles",
    "text": "Autonomous Vehicles\n\nROV\nAUV\nGliders\nSurface vehicles\n\n\n\n\n\n\n\n\n&lt;td&gt; &lt;img src=\"./images/1.introduction/1.auv-example.png\" alt=\"1.auv-example\" style=\"height: 350px;\"/&gt; &lt;/td&gt;    \n&lt;/tr&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnergetic efficient zig zag movement by adjusting resoirting forces\n\n\nWavegliders and Interventions\n\n\n\n\n\n\n\n\n\n\n\n\nBioinspired Robotics\n\n\n\n\n\n\n\n\n\n\n\n\nCosts\n\n1 day of operation for a research vessel: 50K Euros\n1 day of operation with a working class ROV: 100-300K Euros\n1 Robotic Arm suitable for underwater work: 400K Euros\n1 day of grophysical surveys: 1-3M Euros\nAir France black box recovery: 30M Euros\nVessel for geophyical surveys (From design to launch): 200M Euros",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#marine-autonomy-trends",
    "href": "intro.html#marine-autonomy-trends",
    "title": "Underwater Systems",
    "section": "Marine Autonomy Trends",
    "text": "Marine Autonomy Trends\n(Adapted from here)\n\n\n\n\n\n\n\nEarly commercial marine vehicles\nAt the turn of the century, there weren’t many commercial marine vehicles for sale",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#early-autonomy",
    "href": "intro.html#early-autonomy",
    "title": "Underwater Systems",
    "section": "Early Autonomy",
    "text": "Early Autonomy\n\n\n\n\nResearcher/Scientists were not content to be limited to the vehicle manufacturer’s autonomy system.\nHow can they run the autonomy system from the payload computer, i.e., Payload Autonomy\nDo you see limitations or concerns with this?\n\nAutonomy can be complex, sometime is data driven, might be not deterministic and might increase the risk of losing a vehicle. Losing an AUV might set a research group back many years.",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#marine-autonomy-trends-1",
    "href": "intro.html#marine-autonomy-trends-1",
    "title": "Underwater Systems",
    "section": "Marine Autonomy Trends",
    "text": "Marine Autonomy Trends\n\nScripted to Adaptive to Human-Machine Systems\n\n&lt;/tr&gt;\n\n\n\n\n\n\n\n\n\nScripted: trajectory largely determined before the vehicle is launched.\nSensing: Robot needs to know where it is.\nAdaptive, collaborative: trajectory depends in part on what collaborative vehicles are doing\nSensing: Robot needs to know about others\n\n\nScripted Missions\n\n20 years ago, marine autonomy was not a familiar term\nRobots went from waypoint to waypoint and were retrieved.\nScientist then offloaded the data for analysis.\nThe control system, navigation system and all software, were part of what the vehicle manufacturer sold with the platform.\n\n\n\n\n\n\n\n\n\nCan you think of limitations? and of advantages?\n\n\n\nAdaptive autonomy\n\n10 years later (10 years ago): the rise of adaptive autonomy.\nSensor data was no longer just retrieved, post-mission.\nRobots processed sensor data during the mission and adapted their mission trajectories.\nUnscripted, dynamic missions: the autonomy design space becomes huge.\nVehicle manafurers focused their supported missions based on core users.\nOpened payload interface to allow third party autonomy (industry, academic labs, defense labs)\n\n    &lt;td&gt;&lt;/td&gt;\n&lt;td&gt; &lt;img src=\"./images/1.introduction/22.adaptive-autonomy-reacquire.png\" alt=\"23.human-machine\" style=\"height: 350px;\"/&gt; &lt;/td&gt;\n&lt;/tr&gt;",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#marine-autonomy-trends-2",
    "href": "intro.html#marine-autonomy-trends-2",
    "title": "Underwater Systems",
    "section": "Marine Autonomy Trends",
    "text": "Marine Autonomy Trends\n\nMOOS-IvP: Increased level of adoption (original and highly recommended slide pack available here\n\n\n\n\n\n\n\n\n\nA tangible example\n\n\n\n\n\n\n&lt;figcaption&gt;Wall Street Journal August 2016.&lt;/figcaption&gt;\n&lt;/figure&gt;\n\n\nAnd a blog post on the World’s first autonomous ferry\n\n\n\n\n\nAutonomy Trends\n\nAfter more than a decade of software innovation in the payload, there are now many good options for specialized autonomy, sensing, navigation and communications\nMany of these software solutions come from different developers/vendors.\n\n\n\n\n\nGreat benefits for end-users when best-of-practice solutions can be combined\nKey challenge: how to design system protocols/messages to develop systems of autonomy systems",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "intro.html#next-challenges",
    "href": "intro.html#next-challenges",
    "title": "Underwater Systems",
    "section": "Next Challenges",
    "text": "Next Challenges\n\n\n\n\n\n\n\nSee 00_Syllabus.ipynb\n\nfor course structure.",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "the_sonar_equations.html",
    "href": "the_sonar_equations.html",
    "title": "The SONAR equations",
    "section": "",
    "text": "The “sonar equation” is a systematic way of estimating the expected signal-to-noise ratios for sonar (SOund Navigation And Ranging) systems. - The signal-to-noise ratio determines whether or not a sonar will be able to detect a signal in the presence of background noise in the ocean. - It takes into account the source level, sound spreading, sound absorption, reflection losses, ambient noise, and receiver characteristics. - The sonar equation is used to estimate the expected signal-to-noise ratios for all types of sonar systems. - Slightly different versions of the sonar equation are used for active (echo-ranging) and passive sonar systems.\nFundamental equations through which we can measure the performance of an acoustic system (a SONAR).\nA sonar system can be influenced by a number of factors: - environmental conditions (ambient noise, acoustic loss, etc.) - how the sonar system is built (geometry, frequency, array length, etc.)\nThe combination of these aspects give us the overall performance of a specific system in a specific environment\nFor ex. - Bathymetric survey: the right sonar depends on the expected environment when I need to measure the bathymetry in the area of interest\nWhat this means is that the datasheet is usually not enough to characterise the operational performance of the sonar\nNote: - acoustic intensity depends on frequency, but we will see that in the sonar equations frequency is not explicit - what this means is that applying the same equations at different frequencies we obtain different results",
    "crumbs": [
      "The SONAR equations"
    ]
  },
  {
    "objectID": "the_sonar_equations.html#passive-sonar-equation",
    "href": "the_sonar_equations.html#passive-sonar-equation",
    "title": "The SONAR equations",
    "section": "Passive SONAR equation",
    "text": "Passive SONAR equation\n\n\n\n\n\n\n\n\nThe SONAR is a receiver that listens for sound\nA source is emitting a signal with intensity \\(SL\\) (Source Level)\n\nTonals (monofrequency components)\n\nPropulsion machinery (main motors, reductions, etc.)\nAuxiliary machinery (pumps, generators, etc)\netc.\n\n\\(SL\\): Level of acoustic intensity 1m from the source\nBroadband noise\n\nCavitation at or near the propeller\nRadiated flow noise\netc\n\n\\(SL = SSL + 10\\log B\\)\nwhere:\n\n\\(SSL\\) is the pressure spectrum level 1m from the source\n\\(B\\) is the bandwidth of the system in Hz (if SSL is not contant over B, it needs to be split in smaller bands)\n\n\nAll the Ambient Noise present has an intensity \\(N\\) (e.g., marine traffic, etc.)\nThe receiver receives a signal (echo level) with intensity\n\n\\[\nEL = SL - TL\n\\]\n\nTransmission Loss (TL) includes intrinsic attenuation, geometric attenuation, interference (which are also due to the variation of the sound speed in the water column)\n\nTL is due to the environmental effects (except for the noise)\nThere might be one loss that is predominant, for ex. at high freq. TL mostly due to intrinsic attenuation, at low frequency (and deep water) is geometric attenuation\n\nThe equation depends on the frequency so is valid if all the quantities have the same frequencies\n\nNote that interference which depends on the phase is strongly dependent on the frequency and this has a direct effect on the TL\n\n\nThe Signal-to-Noise ratio in dB:\n\\[\nSNR = (SL - TL) - N\n\\]\n\nDetection Threshold and Signal Eccess\n\nWe are interested in listening to some signal (EL) which is due to the sound emitted by the source less than what is loss due to propagation.\nGiven that there is also Ambient noise, when can I detect the signal from the Ambient noise?\nWe define a Detection Threshold (DT) (typically DT=0, SNR &gt; 0 dB)\n\nChoose the right DT value is complex\nTrade off between probability of detecting something but also having as little false alarms as possible\nDepends on the application\n\nThe detection process consists of designating a threshold which, when exceed, causes a detection to be recorded.\nIf the signal is much stronger than the noise, it is clear that a threshold can be defined that will allow valid signals to be recorded while ignoring the noise.\nHowever, when the signal and noise are of comparable size, any threshold that will catch a reasonable number of valid signals will also record “detections” when a valid signal is absent.\n\n\n\n\n\n\n\n\nFigure: Adapted from An introduction to the sonar equations with applications, 1976, pag. 81\n\nWe call Signal Eccess (SE)\n\n\\[\nSE = SNR - DT\n\\]\n\nIf \\(SE&gt;0\\) we “see” the signal, otherwise we do not see it.",
    "crumbs": [
      "The SONAR equations"
    ]
  },
  {
    "objectID": "the_sonar_equations.html#active-monostatic-sonar-equation",
    "href": "the_sonar_equations.html#active-monostatic-sonar-equation",
    "title": "The SONAR equations",
    "section": "Active monostatic SONAR equation",
    "text": "Active monostatic SONAR equation\n\nMonostatic: source and receiver are collocated\n\nMight be the same transducer or different transducers\n\nActive SONAR:\n\nThe system produces sound\nWe have a source with a specific souce (\\(SL\\))\n\nIf souce and receiver are collocated and given that the source has transmitted a signal and I expect to receive a signal\n\nthe signal must be backscatter from something\nthe signal must come back to the receiver (which is collocated with the source)\n\nFor this reason we need to have a “Target” in the area\n\n\n\n\n\n\n\n\n\nTarget\n\nTerminology comes from military applications (active sonars developed to hunt for submarines)\nFor us, target is anything we would like to insonify\nThe backscatter signal depends on the target\n\nWith respect to the wavelength of the signal\nThe intensity of the signal reflected by the target is called Target Strength \\(TS\\)\nThe Target Strength is typically negative!\n\nProvides information on how much signal is lost through scattering in every direction but the backscatting one\n\nThe Target Strength of the target depends on the target shape and where the signal insonifies that specific shape (e.g. submarine)\n\n\n\n\nAmbient Noise\n\nWe have the usual Ambient Noise (\\(N\\))\nWe also have a different type of noise, called Reverberation (\\(RL\\))\n\nDepends on the reflections off the boundaries (sea surface, seabed) and off anything that is present in the water column (e.g., schools of fish, etc.)\nWe call reverberation the scatting coming from anything that is present in the environment except for the target.\nIt can arrive from all directions\nReverberation would not be present if sonar did not transmit\n\n\n\nSignal-To-Noise Ratio\n\\[\nSNR = EL - (N+RL)\n\\]\nAnd the Signal Eccess is\n\\[\nSE = SNR - DT\n\\]\nA further comment on the Signal-to-Noise Ratio:\n\n\\(N+RL\\) means that the reverberation level is multiplied by the noise level (in dB we sum them up). This is not true, because the two signal physically sum up\n\\(N+RL\\) is not a sum even when we are in dB.\nOne of the two terms will be dominant and we reduce the equation to only use that term\n\nThis means:\n\nReceived signal \\(s\\): \\[\nS = 10\\log|s|\n\\]\nAmbient noise \\(n\\): \\[\nN = 10\\log|n|\n\\]\nReverberation level \\(rl\\): \\[\nRL = 10\\log|rl|\n\\]\nSignal to noise ratio \\[\n  snr = \\frac{|s|}{|n+rl|} \\Rightarrow SNR = 10\\log\\frac{|s|}{|n+rl|} \\Rightarrow S-10\\log(|n+rl|)\n  \\]\n\nLet’s analyse \\(10\\log(|n+rl|)\\).\n\\[\n10\\log(|n+rl|) \\le 10\\log(|n|+|rl|)\n\\]\nLet’s consider now the case where the reverberation level is less than the noise (the other case would be the same):\n\\[\n|rl| \\le |n| \\Rightarrow |rl| = k|n|\\;\\; k \\in [0,1]\n\\]\nThis means that\n\\[\n10\\log(|n|+|rl|) = 10\\log((k+1)|n|) = N + 10\\log(k+1) \\;\\; k \\in [0,1]\n\\]\n\nif \\(k=0\\) (no reverberation): we have the usual noise only equation\nif \\(k=1\\) (reverberation is as loud as the noise) and our expression becomes:\n\n\\[\nN + 10\\log(k+1) = N+10\\log2 = N + 3 dB\n\\]\nThis means that \\[10\\log(|n|+|rl|) \\in [N, N+3]\\]\n\nNote that if \\(|rl| &gt; |n|\\) we can repeat the same reasoning with noise as a fraction of the reverberation level and we would obtain:\n\n\\[10\\log(|n|+|rl|) \\in [RL, RL+3]\\]\nWith respect to the larger between \\(N\\) and \\(RL\\), the intensity in dB of their sum, can only be 3dB more than the maximum between \\(N\\) and \\(RL\\) (which is when they both have the same value). Otherwise is less than 3dB.\nThree dB is the usual approximation level that we use.\nIn practise, in most cases we can neglect one of the two terms. In the worst case scenario where the two levels are comparable we add 3dB.\nWe talk about: - Noise limited environments when the ambient noise is prevalent \\(|rl| \\le |n|\\). The SNR only depends on the ambient noise\n\nReverberation limited environments when the reverberation level is prevalent \\(|n| \\le |rl|\\). The SNR only depends on the reverberation Level\n\nFor example, consider the case where the noise and the reverberation level have the same intensity level: - \\(10\\log(N)=60dB\\) - \\(10\\log(RL)=60dB\\)\nIn natural scale we need to sum them and they are equal:\n\\[\nN_{tot} = N+RL=2N \\rightarrow 10\\log2N = 10\\log N + 10\\log2 \\approx 60 + 3 = 10\\log(|n|+|rl|)\n\\]\nIf, for example, \\(N&gt;RL\\), \\(N+RL\\) will be less than \\(2N\\), which means that the difference will be less than 3dB\nIn the sonar equation \\(N+RL\\) = 63 dB (not 120)\n\nOften our systems are able to measure differences of 3dB..\nThis is a confusing way of representing \\(N\\) and \\(RL\\) in the sonar equation but it is standard terminology.\n\nIf we had: \\(N=60dB\\) and \\(RL=40dB\\)\nA difference of \\(20dB\\) corresponds to two orders of magnitude, so \\(RL\\) is negligible and in the sonar equation \\(N+RL\\)=60dB\nWe are implicity assuming Reciprocity - Waves are linear - Environment does not change in time (it can change in space) - Propagation loss in both directions are the same",
    "crumbs": [
      "The SONAR equations"
    ]
  },
  {
    "objectID": "the_sonar_equations.html#active-bistatic-sonar-equation",
    "href": "the_sonar_equations.html#active-bistatic-sonar-equation",
    "title": "The SONAR equations",
    "section": "Active bistatic SONAR equation",
    "text": "Active bistatic SONAR equation\n\nActive: there is a source of sound that transmits a signal\nBistatic: receiver is in a geomtric location that is different from the transmitter\nReceived signal: scattering from the target with some angle (there will be a scattering angle from the target to the receiver)\nThe receiver would receive also scattering from other surfaces or volumes present in the environment\n\n\n\n\n\n\n\n\n\\[\nEL = SL - TL_1 - TL_2 + TS\n\\]\n\\[\nSNR = S - (N+RL)\n\\]\n\\[\nSE = SNR - DT\n\\]",
    "crumbs": [
      "The SONAR equations"
    ]
  },
  {
    "objectID": "the_sonar_equations.html#determining-sonar-performance",
    "href": "the_sonar_equations.html#determining-sonar-performance",
    "title": "The SONAR equations",
    "section": "Determining SONAR performance",
    "text": "Determining SONAR performance\n\nHow can these equations determine the range of the system?\nLet’s focus on a passive sonar (which is easier)\nDT is fixed (chosen by the operator) and is the only parameter of the SONAR\nSL is unknown\n\nLet’s consider a specific example:\n\nDeep waters, sound speed is a Munk profile, etc. (this means that we are in a specific area)\nWe want to listen to sound emitted by a marine mammal\n\n\\(SL=180\\)dB (this might come from previous experiments).\n\\(DT=20\\)dB\n\n\n\n\n\n\n\n\n\n\nAmbient noise: depends on the frequency (e.g., 2-5kHz). Assuming that the sea state is 2 (no experiment if sea state is too rough), so \\(N\\approx60dB\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is the maximum distance of the whale from the receiver at which the receiver can record the whale?\nAssuming that we can neglect interference in this environment.\nThis means that for the TL we can consider the intrinsic attenuation and the geometric attenuation. We are between 2-5kHz and if we look at the attenuation vs frequency:\n\n\n\n\n\n\n\n\nAt \\(5kHz\\), intrinsic attenuation is \\(\\alpha \\approx 1 db/km\\).\nThe geometric attenuation is \\(GA \\approx 20\\log R\\) where \\(R\\) is in metres. - If \\(R=1000m\\), \\(GA=60dB\\)\nIn this scenario, the main attenuation is geometric. This means:\n\\[\nTL = 20\\log R\n\\]\nI have everything I need to use the SONAR equations:\n\n\\(EL = SL - TL = 180 - 20\\log R\\)\n\\(SNR = SL - TL - N = 180 - 20\\log R - 60 = 120 - 20\\log R\\)\n\\(SE =SNR - DT= 120 -20\\log R - 20 = 100 -20\\log R\\)\n\nTo have detection, we need \\(SE \\ge0\\) and the maximum range where \\(SE = 0\\), which means:\n\\[\n20\\log_{10} R = 100 \\Rightarrow R = 10^5 m = 100 km\n\\]\nAt this point we could fine tune it using the intrinsic attenuation. With a 100km propagation a \\(5 dB/km\\) (\\(5\\cdot 10^{-3} dB/m\\)) loss becomes important.\n\\[\nTL = 20\\log R + 5\\cdot10^{-3}R\n\\]\nThe equation becomes:\n\\[\n20\\log_{10} R + 5\\cdot10^{-3}R = 100\n\\]\nThis is a transcendental equation. We can solve it trying a few values to get a maximum range of about 5km.\nI can detect marine mammals up to 5km. I can change the DT to extend the maximum range, but I would increase the number of false alarms as well.\n\nimport numpy as np\n\nfor R in range(1000, 10000, 1000):\n    SE = 20*np.log10(R) + 5e-3*R - 100\n    if abs(SE) &lt; 5: \n        print(f'SE:{SE}, max range: {R}')\n        break\n\nSE:-1.020599913279625, max range: 5000",
    "crumbs": [
      "The SONAR equations"
    ]
  },
  {
    "objectID": "references.html#ocean-acoustics",
    "href": "references.html#ocean-acoustics",
    "title": "References",
    "section": "Ocean Acoustics",
    "text": "Ocean Acoustics\n\nUnderwater acoustic propagation modeling with arlpy and Bellhop. The underwater acoustic propagation modeling toolbox (uwapm) in arlpy is integrated with the popular Bellhop ray tracer distributed as part of the acoustics toolbox. Install Bellhop from this link.\nAn alternative python package is TritonOA which includes useful information on how to install the Acoustic Toolbox here. For Mac OSX we might need a workaround\nDr. Daniel A. Russell, PSU | Wave superposition\nDr. Daniel A. Russell, PSU | Wave demos and animation\nWaves\nAn introduction to underwater acoustics\nAcoustics | NOAA\nAcoustics\nThe-Basics-of-waves\nThe First Studies of Underwater Acoustics: The 1800s\nIntroduction to Oceanography\nTemperature below 1000m\nRay Tracing in Python\nSalinity sensors\nElectrodeless Conductivity Probes\nVASA Stockholm\nSuperposition and Superposition demos\nSOFAR | Applied Underwater Acoustics, page 22, 22.01",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "references.html#the-acoustic-channel",
    "href": "references.html#the-acoustic-channel",
    "title": "References",
    "section": "The Acoustic Channel",
    "text": "The Acoustic Channel\n\nUnderwater acoustic propagation modeling with arlpy and Bellhop. The underwater acoustic propagation modeling toolbox (uwapm) in arlpy is integrated with the popular Bellhop ray tracer distributed as part of the acoustics toolbox. Install Bellhop from this link.\nAn alternative python package is TritonOA which includes useful information on how to install the Acoustic Toolbox here. For Mac OSX we might need a workaround\nIntroduction to Ocean Acoustics\nAcoustics | NOAA\nPublic Technical Reports | Jasco\nComputational Ocean Acoustics\nGood Practice Guide No. 133 Underwater Noise Measurement\nUnderwater Acoustics",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "references.html#ray-tracing",
    "href": "references.html#ray-tracing",
    "title": "References",
    "section": "Ray Tracing",
    "text": "Ray Tracing\n\nJens M. Hovem, Ray Trace Modeling of Underwater Sound Propagation, 2011\nSchool of Marine Sciences. Hands on Oceanography, examples. Includes course SMS 491: Sound in the Ocean\nHow To Hear Halfway Around The World\nWhale Sounds Lab. Has examples of sounds recorded in water.\nIntroduction to Ocean Acoustics. Short descriptions of ocean acoustics. Includes interesting pictures and animations (in Flash).",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "references.html#sonar-practical-applications",
    "href": "references.html#sonar-practical-applications",
    "title": "References",
    "section": "SONAR Practical Applications",
    "text": "SONAR Practical Applications\n\nAcoustic Instruments on the RSS Sir David Atteanborough\nMulitbeam echosounder | NOAA\nSide Scan Sonar | NOAA\nState of the art in multibeam-echosounders\nGEBCO\nOcean Mapping: an Essential Part of Ocean Exploration",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "acoustic_systems.html#acoustic-transducers",
    "href": "acoustic_systems.html#acoustic-transducers",
    "title": "Acoustic systems",
    "section": "Acoustic transducers",
    "text": "Acoustic transducers\n\nWho generates the pressure? who is the source?\nA transducer converts some sort of energy to sound (source) or converts sound energy (receiver) to an electrical signal\nAn acoustic source in water is in general a piezoelectric or piezoceramic element.\n\nRespond to a voltage with a mechanical deformation\nA mechanical deformation produces an electrical signal\n\n\n\n\n\n\n\n\n\nFigure adapted from J.M. Hovem, NTNU\n\nApply an electric signal (sinusoidal) to piezoelectric discs and they deform\nDiscs are anchored to a backloading fixed element and to a Vibrator hear which is a mechanical amplifier\nWhen deployed in water (with appropriate sealings) produces deformations in the water, i.e., pressure perturbations\nTransmitters and Receivers are conceptually the same\n\nFrequency of mechanical vibration (for the same voltage) depends on the specific material and on the geometry.\nAn acoustic transmitter is composed by one or more of these elements\nAn acoustic receiver (i.e., hydrophone) is composed of one or more of these elements (one hydrophone is typically composed by one)\n\nEach basic element can typically be considered as omnidirectionals\n\nFor ex. one hydrophone detects pressure in all directions\n\nThey can be combined together in variuos geometry to obtain directivity of sources and receivers\n\nCan be done both using specific geometry of the composition\nand with signal processing called beamforming\n\n\n\n\n\n\n\n\n\nFigure adapted from J.M. Hovem, NTNU\n\nWhen the geometry is linear, we talk about arrays (of hydrophones) or phased arrays\n\nThey are typically towed by ships (or by UxVs)\n\nArrays can also be spherical or planar (3D)",
    "crumbs": [
      "Acoustic systems"
    ]
  },
  {
    "objectID": "acoustic_systems.html#phased-arrays",
    "href": "acoustic_systems.html#phased-arrays",
    "title": "Acoustic systems",
    "section": "Phased arrays",
    "text": "Phased arrays\n\nOmnidirectional sources are not ideal for a number of applications\nNot ideal for fast steering applications\nThink of fast tracking targets\nPhased arrays streer beams electronically and can generate multiple beams in parallel and steered independently\n\nInterference Pattern of the element determines the directivity and depends on: - Number of elements - Element spacing - Array geometry - Individual antenna patterns (in our case omnidirectional)",
    "crumbs": [
      "Acoustic systems"
    ]
  },
  {
    "objectID": "acoustic_systems.html#near-field-and-far-field",
    "href": "acoustic_systems.html#near-field-and-far-field",
    "title": "Acoustic systems",
    "section": "Near Field and Far Field",
    "text": "Near Field and Far Field\n\nGiven a omnidirectional source (a point source would produce spherical waves in an isotrope medium - spherical attenuation)\nUnfortunately, transducers are not points and we do not have spherical waves when we are close to the source\nWe distringuish between Near and Far Field\n\nSPL: Sound Pressure Level (measure the source level)\n\n\n\n\n\n\n\nFigure: On-axis SPL from a circular piston with radius 6m, f = 1.2 kHz. From Jasco Underwater Acoustics Pocket Handbook, Fig. 17\n\nInterference and diffraction close to the surface of the piston (see max and min of the intensity in the picture above).\n\nNear field\n\nThe distance after which we have monotonic behaviour is called Fresnel Distance\nFar field (or Fraunhofer zone) is where the pressure behaves following spherical attenuation is approximately 4 times the Fresnel Distance\nDepend on frequency and size of the source (higher frequency would have smaller Fresnel distance)\n\nWe will use a Far Field assumption\n\nNote that we defined the source level as the intensity measured at 1m from the source\nIf we want to experimentally measure the SL we would be in the near field so we would not measure the actual SL but rather the interference pattern\nWe would instead go to Far Field to measure the received intensity and then we would use spherical spreading to interpolate and get to 1m from the source.\n\nRequires not to have additional interference in the far field\nFor ex if we position the source and receiver close to the surface we would hit the LLoyd’s mirror and we do not measure the SL again.\n\nOperational source/receiver calibrations are done in deep waters",
    "crumbs": [
      "Acoustic systems"
    ]
  },
  {
    "objectID": "acoustic_systems.html#beamforming",
    "href": "acoustic_systems.html#beamforming",
    "title": "Acoustic systems",
    "section": "Beamforming",
    "text": "Beamforming\nBeamforming is a way of utilizing constructive interference to increase the signal gain at a certain point in space.\n\nBeamforming with linear array\nSuppose you have:\n\na set of hydrophones aligned in a line\nsource in far field\n\nWe would receive a planar wave\n\n\n\n\n\n\n\n\n\n\n\n\nWavefronts hit the hydrophones at different times\nDepends on the arrival angle \\(\\theta\\) of the wavefronts and from the distance between two consecutive hydrophones\nWe use a summation point to sum up all signals \\(P_i\\) received at every hydrophone at a specific point in time\n\n\\[\nR = \\sum_1^N P_i\n\\]\nwhere \\(P_i = P_{max}e^{-ikx_i}\\)\n\nThe intensity is maximised when \\(\\theta=0\\)\n\nSignal arrival is in phase at each hydrophone\n\n\n\n\n\n\n\n\n\n\nWhen \\(\\theta \\ne 0\\), every \\(x_i\\) is different: \\[\nx_{i+1} = x_{i} + dx\n\\]\n\nwhere \\(dx = d\\sin\\theta\\) is the distance to get to the other hydrophone\nthis produces a phase shift at the hydrophone due to the different \\(x_i\\) of the wavefronts.\nWhen \\(\\theta=0\\) all hydrophones receive the same signal (\\(\\sin(0)=0\\)): \\[\nR = \\sum_1^N P_{max}e^{-ikx}\\;\\;\\text{since}\\;\\; x_i=x,\\; \\forall i\n\\]\n\nThe arriving wave will have maxs and mins (depends on the wavenumber), but when \\(\\theta=0\\), the sum of max is \\(NP_{max}\\).\nThe signal is amplified by the number of hydrophones\nIn all other directions (\\(\\theta \\ne 0\\)) we have a lower gain (or even destructive interference)\nThis is called beamforming: summing up we obtain the part of the acoustic field that is coming from direction \\(\\theta=0\\)\nWhen signals arrive at the hydrophones at the same time, we obtain the same signal amplified (mid picture below)\nWhen signals arrive from an angle, they have a phase shift (\\(kd\\sin\\theta)\\) and we obtain a different signal\nIf there is no signal at \\(\\theta=0\\) we get something that is not amplified.\n\n\n\n\n\n\n\n\n\nNote also that at each hydrophone arrives both the signal and noise (e.g., white noise \\(n_i\\)).\nIf we have white noise, summing up uncorrelated noise means attenuating the noise\nWe have a boost for the coherent signal and attenuation of incoherent signals (noise)\n\nThis is useful if we want to know if signal is arriving from direction \\(\\theta=0\\)\n\nWhat if I am interested in a different direction?\nWe could rotate the receiver to the specific direction (e.g., mechanically scanning radars)\n\nNot practical underwater\n\nHowever, when we sample we can sum up all the data that I have received at the same time (priviledged direction \\(\\theta=0\\))\nI can also note that the phase shift at the next hydrophone is: \\(kd\\sin\\theta\\)\nThe wavafront has traveled \\(d\\sin\\theta\\) from one hydrophone to the next, in \\(\\frac{d\\sin\\theta}{c}\\) seconds\nIf I buffer all the data from all the hydrophones and then:\n\nsum the same time \\(\\theta=0\\)\nsum signals delayed by \\(i \\cdot \\frac{d\\sin\\bar{\\theta}}{c}\\), where \\(i\\) is the hydrophone number and \\(\\bar{\\theta}\\) is a specific direction\nthis corresponds to reading the signals at the same time but looking in the direction \\(\\bar{\\theta}\\)\n\nDelaying the signals before the sum, the intensity is maximised for different values of \\(\\theta\\).\nThis is equivalent to doing a phase shift at the receivers (delay in time is equivalent to phase shifts in frequency): summing signals that are in phase\n\ntime domain: time delay steering\nfrequency domain: phase delay steering\n\nThis is a signal processing operation that we can do very fast and in parallel (across multiple directions at once)\nSignals depending on the direction \\(\\theta\\) are called beams\nBeamforming can be steered to desired directions \\(\\theta\\) forming beams corresponding to the various steering directions\nIf there is a source at a specific direction, the beam corresponding to the source direction will have the highest intensity (the other would have lower intensity)\n\n\nArray of transmitters\n\nThe same principle apply for arrays of receivers and arrays of sources\nWith N sources aligned, in the far field it is equivalent to have a single source with a pressure is \\(N\\) times that of each single element (intensity \\(N^2\\))\nIf we delay the signal transmitted by each element by \\(i \\cdot \\frac{d\\sin\\bar{\\theta}}{c}\\) we can steer the generated wavefront\n\n&lt;td&gt; &lt;img src=\"./images/8.acoustic-systems/5.source-beamforming-1.png\" alt=\"5.source-beamforming\" style=\"width: 300px\"/&gt;&lt;/td&gt;\n\n\n\n\n\n\n\n\nDelaying in time is equivalent to a phase shift in frequency\nWe can do beamforming in time and in frequency\n\nNice library: arlpy\nand reference Basics of phased arrays",
    "crumbs": [
      "Acoustic systems"
    ]
  },
  {
    "objectID": "acoustic_systems.html#transducer-directivity-and-beam-pattern",
    "href": "acoustic_systems.html#transducer-directivity-and-beam-pattern",
    "title": "Acoustic systems",
    "section": "Transducer directivity and beam pattern",
    "text": "Transducer directivity and beam pattern\nThe beam patter provides information on how a given array distributes the signal in space. It is calculated using the signal strength as a function of spatial location for a given transmitter array.\n\n\n\n\n\n\n\n\nLine array: maximum directivity along the acoustic axis \\(\\theta=0\\)\n\n\n\nBeam pattern of a linear array. Figure from Bradley and Stern\n\nThese diagrams, called beam patterns provide a graphical representation of the value in dB of the received pressure as a function of the angle.\nNote how intensity decreases as we move away from the \\(\\theta=0\\)\nNote how the received pressure varies\n\nWhen 0 means we are summing signals in destructive interference (opposite phase)\nWhen the signal increase it never goes to the maximum of the main lobe\nMain lobe is where we have the global maximum\nSide lobes correspond to local maxima\nIn the sum we had the wavelength (through \\(k\\)) which makes it possible to calculate the minimum and maximum\nNote the cylindrical symmetry of the problem (every direction that is perpendicular to the array provides a maximum)\n\nLimiting to a plan case: left-right ambiguity\n\n\nDelaying and summing we can rotate the beam pattern towards the direction we desire\n\nThere is a slight deformation not a pure rotation (pure rotation approximately only between 0 and 45)\n\n\nDifferent geometric configuration give rise to different beampatterns\n\n\n\n\n\n\n\n\nDisc array: maximum directivity along the acoustic axis \\(\\theta=0\\)\n\n\n\nBeampattern of a disc array. Figure from Bradley and Stern\n\nMaximum is along the direction perpendicular to the disc",
    "crumbs": [
      "Acoustic systems"
    ]
  },
  {
    "objectID": "acoustic_systems.html#array-size-and-beamwidth",
    "href": "acoustic_systems.html#array-size-and-beamwidth",
    "title": "Acoustic systems",
    "section": "Array Size and Beamwidth",
    "text": "Array Size and Beamwidth\n\nArray of length \\(L\\)\nContinuous (each element is infinitesimaly close to the next)\nBeamwidth of the main lobe:\n\n\\[\n\\Delta\\theta = \\lambda/L\n\\]\n\n\n\n\n\n\n\n\nFigure adapted from J.M. Hovem, NTNU\n\n\n\n\nFormula is specific for a continuous array, but generalises for the following aspect:\n\nIn acoustics we cannot obtain similar effects to what we have with lasers which are very focused and narrow.\nTo reduce \\(\\Delta\\theta\\) (focusing), which means having higher resolution: - reduce \\(\\lambda\\) wave length (move to high frequency, which however attenuates quickly) - increase \\(L\\), the length of the array\nTradeoff between range/frequency/resolution\n\nThe Beamwidth of the main lobe formula makes it possible to approximate the expected resolution of a SONAR system",
    "crumbs": [
      "Acoustic systems"
    ]
  },
  {
    "objectID": "acoustic_systems.html#sonar-systems",
    "href": "acoustic_systems.html#sonar-systems",
    "title": "Acoustic systems",
    "section": "SONAR systems",
    "text": "SONAR systems\n\nAny system which uses acoustics to do something underwater\nSpecialised sonars for specific applications (e.g., ASW, echosounders, acoustic modems)\nIt is composed of:\n\nAt least one receiver: we talk about passive sonars\n\nreceiver listens from sound produces by others\n\nAt least one transmitted and one receiver: we talk about active sonars\n\nreceiver listens from reflections produced by the sound emitted by the source\n\n\n\n\n\n\n\n\n\n\n\nFigure adapted from J.M. Hovem, NTNU\n\n\n\n\nConsider the source as composed of multiple transmitters (an array) so that we can obtain an aperture \\(\\Delta\\theta\\)\nAssume that the SONAR transmits rectangular pulses with temporal width \\(T\\) (pulse width)\nThe bandwidth of the rectangular pulse \\(B\\approx\\frac{1}{T}\\)\nSuch a system (TX or RX) can:\n\nsteer its beams, and each beam has beamwidth \\(\\Delta\\theta\\)\nreceives from a sector that depends on the pulse width",
    "crumbs": [
      "Acoustic systems"
    ]
  },
  {
    "objectID": "acoustic_systems.html#range-resolution",
    "href": "acoustic_systems.html#range-resolution",
    "title": "Acoustic systems",
    "section": "Range Resolution",
    "text": "Range Resolution\n\nRectangular pulse is transmitted (see figure below right)\nHits something that scatters the signal back\nThe signal travels \\(2R\\)\nThe space for the pulse width to hit the target is \\(\\delta R\\) and is defined as \\[\\delta R = \\frac{cT}{2}\\]\nNote that we divide by two because the signal goes back and forth\n\n\n\n\n\n\n\n\n\n\n\n\nFigure adapted from J.M. Hovem, NTNU\n\n\n\n\nThe SONAR resolution cell depends on:\n\n\\(\\Delta\\theta\\) (the receiver beam)\n\\(\\delta R\\)\n\nTo have high resolution\n\nangular resolution: \\(\\Delta\\theta\\) (increase frequency or use longer arrays)\nrange resolution: \\(\\delta R\\) must be small and we can only reduce \\(T\\)\n\nsmall \\(T\\) means higher bandwidth \\(B\\approx\\frac{1}{T}\\)\ndirac delta function would be perfect as it has infinite bandwidth\nProblem: again I need high frequency\nTradeoff between resolution and range\nNote that we are now talking about Bandwidth: different frequencies in my bandwidth will be attenutated differently\nThe further away the sound comes the smaller the resolution: only low frequencies come back (this is true in terrestrial acoustics as well).\n\n\n\nFor non rectangular impulses - Specific formulas exist - Empirical rule: take the time width corresponding to maximum signal amplitude within -3dB as rectangular envelope - Good enough for a qualitative understanding\n\n\n\n\n\n\n\n\nFigure adapted from A. Caiti, Univ. of Pisa",
    "crumbs": [
      "Acoustic systems"
    ]
  },
  {
    "objectID": "acoustic_systems.html#ambient-noise-is-the-ocean",
    "href": "acoustic_systems.html#ambient-noise-is-the-ocean",
    "title": "Acoustic systems",
    "section": "Ambient Noise is the Ocean",
    "text": "Ambient Noise is the Ocean\n\nWe saw that together with signals we receive noise\nNoise: any disturbance, any unwanted signal that interferes with the signal carrying information\nIn ocean acoustics we not only have the typical noise any information engineer needs to deal with, electrical noise, but also with Acoustic Noise or Ambient Noise.\n\nAmbient Noise has spectral characteristics that are quite precise depending on what is causing it - Picture below (sound pressure vs frequency (log scale)) represents the typical spectral level of ambient noise, due to physical causes, and far away from the sonar system under analysis - Prevailing noise levels shown with the two solid black lines\nMain sources (numbers are approximate): - Earthquakes and explosions - Low frequency (up to 100Hz) - Wind noise in shallow waters (less than 40m) - Wind propagates sound in the water column (up to 100Hz) - Traffic noise - Shallow waters (&lt;500m) is slightly lower frequency - Deep waters (&gt;500m) - Heavy traffic is shown as dashed line - Marine traffic can get up to 1kHz. - Sea state - Note the presence, between 100Hz and 1kHz, of noise due to the state of sea: waves at the surface produce sound in the water column. In turns, waves are due to atmospheric effects.\n\nHeavy precipitations\n\nBetween 100 and 30kHz\n\nNote how moving up in frequency effects of ambient noise decreases\nMoving to higher frequencies, sound is attenuated (assumption is source in far field)\nFor frequency &gt; 10kHz noise is due to air and bubbles (e.g., white foam of waves: bubbles exploding and making noise at high frequency)",
    "crumbs": [
      "Acoustic systems"
    ]
  },
  {
    "objectID": "acoustic_systems.html#beaufort-scale-sea-state",
    "href": "acoustic_systems.html#beaufort-scale-sea-state",
    "title": "Acoustic systems",
    "section": "Beaufort Scale, Sea State",
    "text": "Beaufort Scale, Sea State\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeaufort wind scale\nMean Wind Speed\nLimits of wind speed\nWind descriptive terms\nProbable wave height\nProbable maximum wave height\nSeastate\nSea descriptive terms\n\n\n\n\n\nKnots\nKnots\n\nin metres (1)\nin metres (2)\n\n\n\n\n0\n0\n&lt;1\nCalm\n-\n-\n0\nCalm (glassy)\n\n\n1\n2\n1-3\nLight air\n0.1\n0.1\n1\nCalm (rippled)\n\n\n2\n5\n4-6\nLight breeze\n0.2\n0.3\n2\nSmooth (wavelets)\n\n\n3\n9\n7-10\nGentle breeze\n0.6\n1\n3\nSlight\n\n\n4\n13\n11-16\nModerate breeze\n1\n1.5\n3-4\nSlight - Moderate\n\n\n5\n19\n17-21\nFresh breeze\n2\n2.5\n4\nModerate\n\n\n6\n24\n22-27\nStrong breeze\n3\n4\n5\nRough\n\n\n7\n30\n28-33\nNear gale\n4\n5.5\n5-6\nRough-Very rough\n\n\n8\n37\n34-40\nGale\n5.5\n7.5\n6-7\nVery rough - High\n\n\n9\n44\n41-47\nStrong gale3\n7\n10\n7\nHigh\n\n\n10\n52\n48-55\nStorm\n9\n12.5\n8\nVery High\n\n\n11\n60\n56-63\nViolent storm\n11.5\n16\n8\nVery High\n\n\n12\n-\n64+\nHurricane\n14+\n-\n9\nPhenomenal\n\n\n\n\nSea state is an empirical scale from 0 (flat) to 9\nTable reports:\n\ndescription of the sea state\nvalue of the sea state\n(average) wave height (peak-to-peak)\nwind speed\nBeaufort scale\n\nTypically we use the Beaufort scale that empirically determines the wind speed from the sea state\nNote how multiple descriptions might match the same seastate number\n\n\n\n\n\n\n\nThe scale was devised in 1805 by the Irish hydrographer Francis Beaufort (later Rear Admiral), a Royal Navy officer, while serving on HMS Woolwich.",
    "crumbs": [
      "Acoustic systems"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus for “Underwater Systems”",
    "section": "",
    "text": "Instructors: - Andrea Munafo (andrea.munafo@unipi.it) - Riccardo Costanzi (riccardo.costanzi@unipi.it)",
    "crumbs": [
      "Syllabus for \"Underwater Systems\""
    ]
  },
  {
    "objectID": "syllabus.html#course-content",
    "href": "syllabus.html#course-content",
    "title": "Syllabus for “Underwater Systems”",
    "section": "Course content",
    "text": "Course content\nThe course discusses key properties of the ocean sea water, with the objective to serve as basis for the understanding of sound transmission in the oceans.\nThen it explains how this knowledge is applied in underwater instruments for positioning, signal transfer, mapping, measurements and ocean sampling.\nPrimarily, we will talk about Sensing, Communications and Autonomy - Effective autonomy can compensate for limits in sensing and communications. - Effective communications can compensate for limits in sensing and autonomy.\nIntelligence/Perceptiveness/Connectedness is part of a bigger picture where: - Smarter systems means more can be done with fewer systems. - Smarter systems means more can be done with less capable (lower cost) systems.\nSpecific topics inlcude:\n\n\n\n\n\nOcean acoustics\n\n\nThe acoustic channel\n\n\nRay tracing\n\n\nElements of Oceanography and Environmental Variability\n\n\nThe Wave Equations\n\n\n\n\n\n\nAcoustic Systems\n\n\nThe Sonar Equations\n\n\nSonar Practical Equations\n\n\nNetworked systems\n\n\nMaritime Navigation\n\n\n\n\n\n\nWeek 1: Introduction to Ocean Acoustics and the Acoustic Channel\n\nTuesday (3 hours): Introduction to Ocean Acoustics\n\nFundamentals of sound in the ocean\nPhysical principles of underwater acoustics\n\nWednesday (2 hours): The Acoustic Channel\n\nCharacteristics and properties of the acoustic channel\nChallenges and applications in ocean acoustics\n\n\n\n\nWeek 2: Ray Tracing and Oceanography Elements\n\nTuesday (3 hours): Ray Tracing in Ocean Acoustics\n\nPrinciples of ray tracing\nModeling sound propagation in the ocean\n\nWednesday (2 hours): Elements of Oceanography and Environmental Variability\n\nOceanographic features affecting sound propagation\nImpact of environmental variability on acoustics\n\n\n\n\nWeek 3: The Wave Equations\n\nTuesday (3 hours): Understanding the Wave Equation\n\nDerivation and analysis of the wave equation\nApplications in ocean acoustics\n\nWednesday (2 hours): Advanced Topics in Wave Equations\n\nNumerical solutions and simulations\nCase studies and practical examples\n\n\n\n\nWeek 4: Acoustic Systems and Sonar Equations\n\nTuesday (3 hours): Acoustic Systems in Oceanography\n\nTypes of acoustic systems\nDesign and operation principles\n\nWednesday (2 hours): The Sonar Equations\n\nFundamentals of sonar equations\nApplications in detection and ranging\n\n\n\n\nWeek 5: Practical Sonar Equations and Networked Systems\n\nTuesday (3 hours): Sonar Practical Equations\n\nPractical aspects and calculations\nPerformance analysis\n\nWednesday (2 hours): Introduction to Networked Systems\n\nConcepts of networked acoustic systems\nCommunication and data integration challenges\n\n\n\n\nWeek 6: Networked Systems (Contd.) and Maritime Navigation\n\nTuesday (3 hours): Advanced Networked Systems\n\nAdvanced techniques and latest trends\nCase studies and real-world applications\n\nWednesday (2 hours): Maritime Navigation\n\nRole of acoustics in navigation\nModern technologies and future trends\n\n\n\n\nWeek 7-9: Dynamic Models of Underwater Vehicles\n\nWeek 7:\n\nSession 1 (3 hours): Introduction to Dynamic Modeling\nSession 2 (2 hours): Basic Principles of Underwater Vehicle Dynamics. Students are grouped for final projects. Projects defined.\n\nWeek 8:\n\nSession 1 (3 hours): Advanced Dynamic Models and Simulation Techniques\nSession 2 (2 hours): Control Systems for Underwater Vehicles\n\nWeek 9:\n\nSession 1 (3 hours): Integration of Acoustic Systems with Vehicle Dynamics\nSession 2 (2 hours): Case Studies and Current Research in Vehicle Dynamics. Start of Final Projects\n\n\n\n\nWeek 10-12: Final Projects\n\nWeek 10:\n\nSession 1 (3 hours): Group Project Work\nSession 2 (2 hours): Group Report and Discussion\n\nWeek 11:\n\nSession 1 (3 hours): Group Project Work\nSession 2 (2 hours): Group Report and Discussion\n\nWeek 12:\n\nSession 1 (3 hours): Final Preparations for Project Presentations\nSession 2 (2 hours): Final Project Presentations and Discussions\n\n\n\n\nAdditional Notes:\n\nPractical Sessions: Incorporate practical exercises, case studies, and simulations across the course for a hands-on learning experience.\nGuest Lectures:\n\nFlorian Schultz, ATLAS Elektronik, “Acoustic Communications and Its Practical Applications” (May 2025)\nDavide Fenucci, National Oceanography Centre, “Autonomy and Navigation” (April/May 2025)\n\nAssessment:\n\nGroup Reports and discussions at periodic intervals\nFinal project related to designing or analyzing an acoustic system, a case study in ocean acoustics, or underwater robotics\nFinal oral examination to assess comprehensive understanding",
    "crumbs": [
      "Syllabus for \"Underwater Systems\""
    ]
  },
  {
    "objectID": "syllabus.html#learning-outcome",
    "href": "syllabus.html#learning-outcome",
    "title": "Syllabus for “Underwater Systems”",
    "section": "Learning outcome",
    "text": "Learning outcome\nAfter having completed the course the students shall have obtained a solid understanding of the processes in the world ocean as well as in design, contruction and working principle of various maritime systems.\nSpecific learning objectives are: - Knowledge of the world oceans, including depths, ocean currents, temperature conditions and salinity/seawater density. - Knowledge and understanding of design and operational conditions for the main underwater vehicles as ROVs and AUVs.\n- Know and understand various underwater positioning and navigational systems. Being able to write (group) reports about complex underwater operations, including time surveying of the mother ship. - Knowledge related to important issues that need to be considered during design, installation and operation of underwater systems, including robots.",
    "crumbs": [
      "Syllabus for \"Underwater Systems\""
    ]
  },
  {
    "objectID": "syllabus.html#recommended-previous-knowledge",
    "href": "syllabus.html#recommended-previous-knowledge",
    "title": "Syllabus for “Underwater Systems”",
    "section": "Recommended previous knowledge",
    "text": "Recommended previous knowledge\n\nRobotics",
    "crumbs": [
      "Syllabus for \"Underwater Systems\""
    ]
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "Syllabus for “Underwater Systems”",
    "section": "Course materials",
    "text": "Course materials\n\nJ.M. Hovem, Marine Acoustics, Peninsula Pub., 2013\nX. Lurton, Introduction to Underwater Acoustics, Praxis, 2002\nD.L. Bradley, R. Stern, Underwater Sound and the Marine Mammals Acoustic Environment, prepared for the US Marine Mammals Commission, 2008\nJ.M. Hovem, “Underwater Acoustics: Propagation, devices and systems”, J. Electroceramics, 19, 339 - 347, 2007\nF.B. Jensen, W.A. Kuperman, M.B. Porter, H. Schmidt, Computational Ocean Acoustics, Springer, 2011\nThe Ocean Acoustic Library: http://oalib.hlsresearch.com/ acoustic modeling, data processing software and data\n\nVarious text books, lecture notes and relevant available information on internet.\n\nsee notebook 12_References.ipynb for course structure.",
    "crumbs": [
      "Syllabus for \"Underwater Systems\""
    ]
  },
  {
    "objectID": "syllabus.html#frequently-asked-questions-faq",
    "href": "syllabus.html#frequently-asked-questions-faq",
    "title": "Syllabus for “Underwater Systems”",
    "section": "Frequently Asked Questions (FAQ)",
    "text": "Frequently Asked Questions (FAQ)\n\nsee notebook 00_FAQ.ipynb",
    "crumbs": [
      "Syllabus for \"Underwater Systems\""
    ]
  },
  {
    "objectID": "oceanographic_sensors.html#conductivity-temperature-and-depth",
    "href": "oceanographic_sensors.html#conductivity-temperature-and-depth",
    "title": "Oceanographic Sensors",
    "section": "Conductivity, Temperature and Depth",
    "text": "Conductivity, Temperature and Depth\n\nSalinity and Temperature as a function of Depth are commonly measured by sensor probes called CTD (Conductivity-Temperature-Depth)\nA CTD device’s primary function is to detect how the conductivity and temperature of the water column changes relative to depth.\nRemember that Conductivity is a proxy for Salinity, which is then calculated using non-linear regression equations\nTemperature: Thermometers\nDepth: pressure sensors (strain gauge that measure deformations, or quartz-based sensors that measure vibration frequency)\n\nThey have a settling time, typically between 0.2-0.6 s. This must be taken into account when installed as a payload on a robot.\n\nOften, CTDs are attached to a much larger metal frame called a rosette, which may hold water-sampling bottles that are used to collect water at different depths, as well as other sensors that can measure additional physical or chemical properties.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe CTD (standing for “Conductivity, Temperature, and Depth”) is a vital instrument when conducting scientific research on ships. Learn more about the CTD and how it functions in this video from The Hidden Ocean 2016: Chukchi Borderlands expedition. Video courtesy of Caitlin Bailey, GFOE, The Hidden Ocean 2016: Chukchi Borderlands, Oceaneering-DSSI. Available at https://oceanexplorer.noaa.gov/facts/ctd.html.\nKnowledge obtained from CTD devices can provide a more detailed understanding of the ocean water’s characteristic through the entire water column, which is crucial for understanding the physics involved. The physics in turn allow biologists to understand why the biology is present or not present at different depths and why the chemical makeup of the water changes over depth. The CTD is the key to understanding the physics, chemistry, and biology of the water column.\n\n\n\n\n\n\n\n\n\n\nLeft: Star-Oddi mini CTD Right: Deployment of a Remus AUV, University of Hawaii at Manoa\n\nSmaller CTDs have limited computations and memory. Need to be carefully programmed depending on the mission length.\nInstalling it on a robot can overcome some of these limitations.",
    "crumbs": [
      "Oceanographic Sensors"
    ]
  },
  {
    "objectID": "oceanographic_sensors.html#multi-parameters-probes",
    "href": "oceanographic_sensors.html#multi-parameters-probes",
    "title": "Oceanographic Sensors",
    "section": "Multi-parameters probes",
    "text": "Multi-parameters probes\n\nCTD plus water quality measurements\npH\nDissolverd Oxigen\nClorophyll\nTurbidity\nNitrate/Nitrogen\nAmmonium\nChloride\n…\n\nSome examples\n\n\n\n\n\n\n\nMulti-parameter probe on a robot\n\n\n\n\n\n\n\nThere are much more sensors!\nSee for example this great page from WHOI",
    "crumbs": [
      "Oceanographic Sensors"
    ]
  },
  {
    "objectID": "oceanographic_sensors.html#argo-floats",
    "href": "oceanographic_sensors.html#argo-floats",
    "title": "Oceanographic Sensors",
    "section": "Argo Floats",
    "text": "Argo Floats\n\nARGO material\nARGO presentation",
    "crumbs": [
      "Oceanographic Sensors"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html",
    "href": "getting_started_with_python_and_jupyter_notebook.html",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "",
    "text": "The purpose of this Jupyter Notebook is to get you started using Python and Jupyter Notebooks for routine engineering calculations. This introduction assumes this is your first exposure to Python or Jupyter notebooks.\nThis notebook composes information available here and here\nThe easiest way to use Jupyter notebooks is to use a cloud-based service such as Google Colaboratory. You will need continuous internet connectivity to access your work, but the advantages are there is no software to install or maintain.",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#installing-jupyterpython-on-your-laptop",
    "href": "getting_started_with_python_and_jupyter_notebook.html#installing-jupyterpython-on-your-laptop",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "Installing Jupyter/Python on your Laptop",
    "text": "Installing Jupyter/Python on your Laptop\nFor regular off-line use you should consider installing a Jupyter Notebook/Python environment directly on your laptop. This will provide you with reliable off-line access to a computational environment. This will also allow you to install additional code libraries to meet particular needs.\nChoosing this option will require an initial software installation and routine updates. For this course the recommended package is Anaconda available from Continuum Analytics. Downloading and installing the software is well documented and easy to follow. Allow about 10-30 minutes for the installation depending on your connection speed.\nAfter installing be sure to check for updates before proceeding further. With the Anaconda package this is done by executing the following two commands in a terminal window:\n&gt; conda update conda\n&gt; conda update anaconda\nAnaconda includes an ‘Anaconda Navigator’ application that simplifies startup of the notebook environment and manage the update process.",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#installing-the-course-environment",
    "href": "getting_started_with_python_and_jupyter_notebook.html#installing-the-course-environment",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "Installing the Course Environment",
    "text": "Installing the Course Environment\nInstrutions for the Anaconda Navigator are slightly different and are not covered in this notebook. We assume you use a terminal from hereon.\nIf you decide to use Anaconda, the first thing to do is to create a virtual environment for the course. This makes sure that you do not pollute your main OS python envinronment.\nYou can do this with:\nconda create --name underwater-systems python=3.10\nYou only need to run the previous command once.\nYou then just need to activate your environment:\nconda activate underwater-systems\ncreate a folder you want to use for this course. You can use your OS GUI or run:\nmkdir underwater-systems\nThis creates the folder underwater-systems in your current directory. Make sure you are in the correct folder before executing the previous commands.\nTo run the notebooks you need to install the following packages: fastcore pandas matplotlib control sympy numpy ffmpeg-python\nyou can do this running:\npython -m pip install fastcore pandas matplotlib numpy scipy ffmpeg-python notebook\nYou are ready to go!\nRun:\njupyter notebook\nto start your notebook session.",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#start-a-jupyter-notebook-session",
    "href": "getting_started_with_python_and_jupyter_notebook.html#start-a-jupyter-notebook-session",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "1. Start a Jupyter Notebook Session",
    "text": "1. Start a Jupyter Notebook Session\nIf you are using a cloud-based service a Jupyter session will be started when you log on.\nIf you have installed a Jupyter/Python distribution on your laptop then you can open a Jupyter session in one of two different ways:\n\nUse the Anaconda Navigator App, or\nOpen a terminal window on your laptop and execute the following statement at the command line:\n&gt; jupyter notebook\n\nEither way, once you have opened a session you should see a browser window.\nAt this point the browser displays a list of directories and files. You can navigate amoung the directories in the usual way by clicking on directory names or on the ‘breadcrumbs’ located just about the listing.\nJupyter notebooks are simply files in a directory with a .ipynb suffix.",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#simple-calculations-with-python",
    "href": "getting_started_with_python_and_jupyter_notebook.html#simple-calculations-with-python",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "2. Simple Calculations with Python",
    "text": "2. Simple Calculations with Python\nPython is an elegant and modern language for programming and problem solving that has found increasing use by engineers and scientists. In the next few cells we’ll demonstrate some basic Python functionality.\n\na = 12\nb = 2\n\nprint(a + b)\nprint(a**b)\nprint(a/b)\n\n14\n144\n6.0\n\n\n\nPython Libraries\nThe Python language has only very basic operations. Most math functions are in various math libraries. The numpy library is convenient library. This next cell shows how to import numpy with the prefix np, then use it to call a common mathematical function\n\nimport numpy as np\n\n# mathematical constants\nprint(np.pi)\nprint(np.e)\n\n# trignometric functions\nangle = np.pi/4\nprint(np.sin(angle))\nprint(np.cos(angle))\nprint(np.tan(angle))\n\n3.141592653589793\n2.718281828459045\n0.7071067811865475\n0.7071067811865476\n0.9999999999999999\n\n\n\n\nWorking with Lists\nLists are a versatile way of organizing your data in Python.\n\nxList = [1, 2, 3, 4]\nxList\n\n[1, 2, 3, 4]\n\n\nYou can join one list to another or concatentate them\n\n# Concatenation\nx = [1, 2, 3, 4];\ny = [5, 6, 7, 8];\n\nx + y\n\n[1, 2, 3, 4, 5, 6, 7, 8]\n\n\n\nnp.sum(x)\n\n10\n\n\nElement by element operation\n\nprint(np.add(x,y))\nprint(np.multiply(x,y))\nprint(np.dot(x,y))\n\n[ 6  8 10 12]\n[ 5 12 21 32]\n70\n\n\nA for loop is a means for iterating over the elements of a list. The colon marks the start of code that will be executed for each element of a list. Indenting has meaning in Python. In this case, everything in the indented block will be executed on each iteration of the for loop. This example also demonstrates string formatting.\n\nfor x in xList:\n    print(\"sin({0}) = {1:8.5f}\".format(x,np.sin(x)))\n\nsin(1) =  0.84147\nsin(2) =  0.90930\nsin(3) =  0.14112\nsin(4) = -0.75680\n\n\n\n\nNumPy arrays\nNote that while you can do calculations on the lists, NumPy has a special object to represent math vectors or matrices called array.\nThis is NumPy’s main object and it is a homogeneous multidimensional array. It is a table of elements (usually numbers), all of the same type, indexed by a tuple of non-negative integers. In NumPy dimensions are called axes.\nNumPy arrays are much more powerful.\nCreating an array:\n\na = np.array([2, 3, 4])\n\narray transforms sequences of sequences into two-dimensional arrays, sequences of sequences of sequences into three-dimensional arrays, and so on.\n\nb = np.array([(1.5, 2, 3), (4, 5, 6)])\nprint(b)\n\n[[1.5 2.  3. ]\n [4.  5.  6. ]]\n\n\nThe type of the array can also be explicitly specified at creation time:\n\nc = np.array([[1, 2], [3, 4]], dtype=complex)\nprint(c)\n\n[[1.+0.j 2.+0.j]\n [3.+0.j 4.+0.j]]\n\n\nOften, the elements of an array are originally unknown, but its size is known. Hence, NumPy offers several functions to create arrays with initial placeholder content. These minimize the necessity of growing arrays, an expensive operation.\n\nprint(np.zeros((3, 4)))\n\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]]\n\n\n\nnp.ones((2, 3, 4), dtype=np.int16)\n\narray([[[1, 1, 1, 1],\n        [1, 1, 1, 1],\n        [1, 1, 1, 1]],\n\n       [[1, 1, 1, 1],\n        [1, 1, 1, 1],\n        [1, 1, 1, 1]]], dtype=int16)\n\n\nArithmetic operators on arrays apply elementwise. A new array is created and filled with the result.\n\na = np.array([20, 30, 40, 50])\nb = np.arange(4)\nprint(a)\nprint(b)\n\n[20 30 40 50]\n[0 1 2 3]\n\n\n\nc = a - b\nprint(c)\n\n[20 29 38 47]\n\n\n\nb**2\n\narray([0, 1, 4, 9])\n\n\n\n10 * np.sin(a)\n\narray([ 9.12945251, -9.88031624,  7.4511316 , -2.62374854])\n\n\n\na &lt; 35\n\narray([ True,  True, False, False])\n\n\nImportant Unlike in many matrix languages, the product operator * operates elementwise in NumPy arrays. The matrix product can be performed using the @ operator (in python &gt;=3.5) or the dot function or method:\n\nA = np.array([[1, 1],\n              [0, 1]])\n\nB = np.array([[2, 0],\n              [3, 4]])\n\n\nA * B     # elementwise product\n\narray([[2, 0],\n       [0, 4]])\n\n\n\nA @ B     # matrix product\n\narray([[5, 4],\n       [3, 4]])\n\n\n\nA.dot(B)  # another matrix product\n\narray([[5, 4],\n       [3, 4]])\n\n\n\n\nWorking with Dictionaries\nDictionaries are useful for storing and retrieving data as key-value pairs.\n\nmw = {'CH4': 16.04, 'H2O': 18.02, 'O2':32.00, 'CO2': 44.01}\nmw\n\n{'CH4': 16.04, 'H2O': 18.02, 'O2': 32.0, 'CO2': 44.01}\n\n\nWe can retrieve a value from a dictionary:\n\nmw['CH4']=5\nmw\n\n{'CH4': 5, 'H2O': 18.02, 'O2': 32.0, 'CO2': 44.01}\n\n\nA for loop is a useful means of interating over all key-value pairs of a dictionary.\n\nfor values in mw.keys():\n    print(\"Value {:&lt;s} is {}\".format(values, mw[values]))\n\nValue CH4 is 16.04\nValue H2O is 18.02\nValue O2 is 32.0\nValue CO2 is 44.01\n\n\nDictionaries can be sorted by key or by value\n\nfor values in sorted(mw):\n    print(\" {:&lt;8s}  {}\".format(values, mw[values]))\n\n CH4       16.04\n CO2       44.01\n H2O       18.02\n O2        32.0\n\n\n\nfor values in sorted(mw, key = mw.get):\n    print(\" {:&lt;8s}  {}\".format(values, mw[values]))\n\n CH4       16.04\n H2O       18.02\n O2        32.0\n CO2       44.01\n\n\n\n\nPlotting with Matplotlib\nImporting the matplotlib.pyplot library gives IPython notebooks plotting functionality very similar to Matlab’s. Here are some examples using functions from the\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0,10)\ny = np.sin(x)\nz = np.cos(x)\n\nplt.plot(x,y,'b',x,z,'r')\nplt.xlabel('Radians');\nplt.ylabel('Value');\nplt.title('Plotting Demonstration')\nplt.legend(['Sin','Cos'])\nplt.grid()\n\n\n\n\n\n\n\n\n\nplt.plot(y,z)\nplt.axis('equal')\n\n(-1.09972447591003,\n 1.0979832896606587,\n -1.0992804688576738,\n 1.0999657366122702)\n\n\n\n\n\n\n\n\n\n\nplt.subplot(2,1,1)\nplt.plot(x,y)\nplt.title('Sin(x)')\n\nplt.subplot(2,1,2)\nplt.plot(x,z)\nplt.title('Cos(x)')\n\nText(0.5, 1.0, 'Cos(x)')",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#where-to-learn-more",
    "href": "getting_started_with_python_and_jupyter_notebook.html#where-to-learn-more",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "Where to Learn More",
    "text": "Where to Learn More\nPython offers a full range of programming language features, and there is a seemingly endless range of packages for scientific and engineering computations. Here are some suggestions on places you can go for more information on programming for engineering applications in Python.\n\nIntroduction to Python for Science\nThis excellent introduction to python is aimed at undergraduates in science with no programming experience. It is free and available at the following link.\n\nIntroduction to Python for Science\n\n\n\nTutorial Introduction to Python for Science and Engineering\nThe following text is available on Amazon. Resources for this book are available on github.\n\nA Primer on Scientific Programming with Python (Fourth Edition) by Hans Petter Langtangen. Resources for this book are available on github.\n\npycse is a package of python functions, examples, and document prepared by John Kitchin at Carnegie Mellon University.\n\npycse - Python Computations in Science and Engineering by John Kitchin at Carnegie Mellon. This is a link into the the github repository for pycse, click on the Raw button to download the .pdf file.\n\nAnd there is plenty more! Google it!",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#python-basics",
    "href": "getting_started_with_python_and_jupyter_notebook.html#python-basics",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "Python Basics",
    "text": "Python Basics\nThis second part of the notebook is to describe some more Python concepts that will be used during the class.\n\nVariables\n\n#A variable stores a piece of data and gives it a name\nanswer = 42\n\n#answer contained an integer because we gave it an integer!\n\nis_it_thursday = True\nis_it_wednesday = False\n\n#these both are 'booleans' or true/false values\n\npi_approx = 3.1415\n\n#This will be a floating point number, or a number containing digits after the decimal point\n\nmy_name = \"Andrea\"\n#This is a string datatype, the name coming from a string of characters\n\n#Data doesn't have to be a singular unit\n\n#p.s., we can print all of these with a print command. For Example:\nprint(answer)\nprint(pi_approx)\n\n42\n3.1415\n\n\n\n\nMore Complicated Data Types\n\n#What if we want to store many integers? We need a list!\nprices = [10, 20, 30, 40, 50]\n\n#This is a way to define a list in place. We can also make an empty list and add to it.\ncolors = []\n\ncolors.append(\"Green\")\ncolors.append(\"Blue\")\ncolors.append(\"Red\")\n\nprint(colors)\n\n#We can also add unlike data to a list\nprices.append(\"Sixty\")\n\n#As an exercise, look up lists in python and find out how to add in the middle of a list!\n\nprint(prices)\n#We can access a specific element of a list too:\n\nprint(colors[0])\nprint(colors[2])\n\n#Notice here how the first element of the list is index 0, not 1! \n#Languages like MATLAB are 1 indexed, be careful!\n\n#In addition to lists, there are tuples\n#Tuples behave very similarly to lists except that you can't change them \n# after you make them\n\n#An empty Tuple isn't very useful:\nempty_tuple = ()\n\n#Nor is a tuple with just one value:\none_tuple = (\"first\",)\n\n#But tuples with many values are useful:\nrosa_parks_info = (\"Rosa\", \"Parks\", 1913, \"February\", 4)\n\n#You can access tuples just like lists\nprint(rosa_parks_info[0] + \" \" + rosa_parks_info[1])\n\n# You cannot modify existing tuples, but you can make new tuples that extend \n# the information.\n# I expect Tuples to come up less than lists. So we'll just leave it at that.\n\n['Green', 'Blue', 'Red']\n[10, 20, 30, 40, 50, 'Sixty']\nGreen\nRed\nRosa Parks\n\n\n\n\nUsing variables\n\nfloat1 = 5.75\nfloat2 = 2.25\n#Addition, subtraction, multiplication, division are as you expect\n\nprint(float1 + float2)\nprint(float1 - float2)\nprint(float1 * float2)\nprint(float1 / float2)\n\n#Here's an interesting one that showed up in the first homework in 2017. Modulus: \nprint(5 % 2)\n\n8.0\n3.5\n12.9375\n2.5555555555555554\n1\n\n\n\n\nImporting in Python\n\n#Just about every standard math function on a calculator has a python equivalent pre made.\n#however, they are from the 'math' package in python. Let's add that package!\nimport math\nprint(math.log(float1))\nprint(math.exp(float2))\nprint(math.pow(2,5))\n# There is a quicker way to write exponents if you want:\nprint(2.0**5.0)\n\n#Like in MATLAB, you can expand the math to entire lists\nlist3 = [1, 2, 3, 4, 5]\nprint(2 * list3)\n\n1.749199854809259\n9.487735836358526\n32.0\n32.0\n[1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n\n\n\n# We can plot easily in Python like in matlab, just import the relevant package!\nimport matplotlib.pyplot as plt\n\nx_vals = [-2, -1, 0, 1, 2]\ny_vals = [-4, -2, 0, 2, 4]\nplt.plot(x_vals, y_vals)\n\n\n\n\n\n\n\n\n\n\nLoops\n\n#Repeat code until a conditional statement ends the loop\n\n#Let's try printing a list\nfib = [1, 1, 2, 3, 5, 8]\n\n#While loops are the basic type\ni = 0\nwhile(i &lt; len(fib)):\n    print(fib[i])\n    i = i + 1\n    \n#In matlab, to do the same thing you would have the conditional as: counter &lt; (length(fib) + 1)\n#This is because matlab starts indexing at 1, and python starts at 0.\n    \n#The above type of loop is so common that the 'for' loop is the way to write it faster.\n\nprint(\"Let's try that again\")\n#This is most similar to for loops in matlab\nfor i in range(0, len(fib)) :\n    print(fib[i])\n\nprint(\"One more time:\")\n#Or you can do so even neater\nfor e in fib:\n    print(e)\n\n1\n1\n2\n3\n5\n8\nLet's try that again\n1\n1\n2\n3\n5\n8\nOne more time:\n1\n1\n2\n3\n5\n8\n\n\n\n\nFunctions\nA function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\ndef my_function():\n    print(\"Hello from a function\")\n\nTo call a function, use the function name followed by parenthesis:\n\nmy_function()\n\nHello from a function\n\n\nInformation can be passed into functions as arguments.\nArguments are specified after the function name, inside the parentheses. You can add as many arguments as you want, just separate them with a comma.\nThe following example has a function with one argument (fname). When the function is called, we pass along a first name, which is used inside the function to print the full name:\n\ndef my_function(fname):\n    print(fname + \" Refsnes\")\n\nmy_function(\"Emil\")\nmy_function(\"Tobias\")\nmy_function(\"Linus\")\n\nEmil Refsnes\nTobias Refsnes\nLinus Refsnes\n\n\nYou can send any data types of argument to a function (string, number, list, dictionary etc.), and it will be treated as the same data type inside the function.\nE.g. if you send a List as an argument, it will still be a List when it reaches the function:\n\ndef my_function(food):\n    for x in food:\n        print(x)\n\n\nfruits = [\"apple\", \"banana\", \"cherry\"]\n\nmy_function(fruits)\n\napple\nbanana\ncherry\n\n\nTo let a function return a value, use the return statement:\n\ndef my_function(x):\n    return 5 * x\n\nprint(my_function(3))\nprint(my_function(5))\nprint(my_function(9))\n\n15\n25\n45\n\n\n\n\nClasses\nA class is a user-defined blueprint or prototype from which objects are created. Classes provide a means of bundling data and functionality together. Creating a new class creates a new type of object, allowing new instances of that type to be made. Each class instance can have attributes attached to it for maintaining its state. Class instances can also have methods (defined by their class) for modifying their state.\nTo understand the need for creating a class let’s consider an example, let’s say you wanted to track the number of dogs that may have different attributes like breed, age. If a list is used, the first element could be the dog’s breed while the second element could represent its age. Let’s suppose there are 100 different dogs, then how would you know which element is supposed to be which? What if you wanted to add other properties to these dogs? This lacks organization and it’s why we need classes.\nClass creates a user-defined data structure, which holds its own data members and member functions, which can be accessed and used by creating an instance of that class. A class is like a blueprint for an object.\nIt’s not hard to define Python class. To do so, you’ll need the class keyword:\nclass ClassName:     # Statement-1     .     .     .     # Statement-N\nFor example\n\nclass Example:    \n    variable = 123\n\nIf you run the above code in a Python environment, you’ll find you can call Example.variable to return an integer value.\n\nExample.variable\n\n123\n\n\nThis is an example of a class for data-only objects, but it’s equally easy to define a class that returns a function object by adding the def keyword to your code:\n\nclass Example:\n    def b(self):\n        return \"this is an example class\"\n\n\nExample.b # we are accessing the function...this is probably not what we want to do..\n\n&lt;function __main__.Example.b(self)&gt;\n\n\nWe need a few more concepts:\n\n\nSome more class concepts\nAn Object is an instance of a Class. A class is like a blueprint while an instance is a copy of the class with actual values. It’s not an idea anymore, it’s an actual dog, like a dog of breed pug who’s seven years old. You can have many dogs to create many different instances, but without the class as a guide, you would be lost, not knowing what information is required. An object consists of :\n\nState: It is represented by the attributes of an object. It also reflects the properties of an object.\nBehavior: It is represented by the methods of an object. It also reflects the response of an object to other objects.\nIdentity: It gives a unique name to an object and enables one object to interact with other objects.\n\n\n\nDeclaring Objects (Also called instantiating a class)\nWhen an object of a class is created, the class is said to be instantiated. All the instances share the attributes and the behavior of the class. But the values of those attributes, i.e. the state are unique for each object. A single class may have any number of instances.\nExample:\n\n\n\n\n\n\nclass Dog:\n     \n    # A simple class\n    # attribute\n    attr1 = \"mammal\"\n    attr2 = \"dog\"\n \n    # A sample method \n    def fun(self):\n        print(\"I'm a\", self.attr1)\n        print(\"I'm a\", self.attr2)\n\n# Object instantiation\nRodger = Dog()\n \n# Accessing class attributes\n# and method through objects\nprint(Rodger.attr1)\nRodger.fun()\n\nmammal\nI'm a mammal\nI'm a dog\n\n\n\n\nSelf\nClass methods must have an extra first parameter in the method definition. We do not give a value for this parameter when we call the method, Python provides it.\nIf we have a method that takes no arguments, then we still have to have one argument.\nWhen we call a method of this object as myobject.method(arg1, arg2), this is automatically converted by Python into MyClass.method(myobject, arg1, arg2).\nNote that this means that inside the function method (in our example) we now have access to the instance of the class! so we can access its variables, etc.\n\n\n__init__ method\nThe init method is similar to constructors in C++, it constructs the object and can be used to initialise the object’s state.\nLike methods, a constructor also contains a collection of statements (i.e. instructions) that are executed when the object is created.\nThe __init__ method runs as soon as an object of a class is instantiated. The method is useful to do any initialization you want to do with your object.\n\n# A Sample class with init method\nclass Person:\n\n    # init method or constructor\n    def __init__(self, name):\n        self.name = name\n\n    # Sample Method\n    def say_hi(self):\n        print('Hello, my name is', self.name)\n\np = Person('Nikhil') # as soon as we do this, the __init__ method is called.\np.say_hi()\n\nHello, my name is Nikhil\n\n\n\n\nClass and Instance Variables\n\nInstance variables are used to store data that is unique to each instance of the class. Instance variables are variables whose value is assigned inside the __init__ method or inside a class method (a method with the argument self)\nClass variables are for attributes and methods shared by all instances of the class. Class variables are variables whose value is assigned directly in the class.\n\n\n# Class for Dog\nclass Dog:\n   \n    # Class Variable\n    animal = 'dog'            \n   \n    # The init method or constructor\n    def __init__(self, breed, color):\n     \n        # Instance Variable    \n        self.breed = breed\n        self.color = color\n    \n# Objects of Dog class\nRodger = Dog(\"Pug\", \"brown\")\nBuzo = Dog(\"Bulldog\", \"black\")\n \nprint('Rodger details:')  \nprint('Rodger is a', Rodger.animal)\nprint('Breed: ', Rodger.breed)\nprint('Color: ', Rodger.color)\n \nprint('\\nBuzo details:')  \nprint('Buzo is a', Buzo.animal)\nprint('Breed: ', Buzo.breed)\nprint('Color: ', Buzo.color)\n \n# Class variables can be accessed using class\n# name also\nprint(\"\\nAccessing class variable using class name\")\nprint(Dog.animal)\n\nRodger details:\nRodger is a dog\nBreed:  Pug\nColor:  brown\n\nBuzo details:\nBuzo is a dog\nBreed:  Bulldog\nColor:  black\n\nAccessing class variable using class name\ndog\n\n\n\n\nAdditional Resources\n\nCode Academy\nOfficial Python Reference\nReal Python\n\nGoogle Colab - An Introduction to Google Colab, McGraw Center for Teaching and Learning - Getting Started with Google Colab - Colab Walkthrough, Stanford University - Google Colab Tutorial for Data Scientists, Datacamp.com",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html",
    "href": "JUPYTER-BOOK-INTEGRATION.html",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "This document provides a detailed overview of the modifications and enhancements made to integrate and optimize Jupyter Book within the existing project repository. The enhancements primarily focus on improving the visual appeal of the Jupyter Book PDF output and ensuring efficient workflow.\n\n\nTo enhance the visual appeal of the Jupyter Book, custom CSS styles have been implemented. These styles affect the layout, typography, and overall aesthetic of both the HTML and PDF versions generated by Jupyter Book.\n\n\n\nTypography: Customized fonts and line spacing for improved readability.\nColor Scheme: A carefully selected color palette that is consistent across all pages.\nCode Styling: Enhanced styling for code blocks and inline code for better distinction from regular text.\nNavigation Menu: A revamped navigation menu with intuitive design for ease of navigation.\n\nThe custom styles can be found in the _static/custom_styles.css file. To modify these styles, edit this file and rebuild the book using Jupyter Book commands.\n\n\n\n\nThe build_jupyterbook_with_images.py script has been developed to streamline the process of including images in the PDF version of the Jupyter Book. This script automates the copying of image files to the correct directory and triggers the Jupyter Book build process.\n\n\n\nPlace the script in the bin directory at the root of your Jupyter Book project.\nRun the script using the command:\npython bin/build_jupyterbook_with_images.py [notebooks_dir]\n\nThe script prompts for confirmation before proceeding with the operations, ensuring user control over the process.\n\n\n\n\nA common issue encountered during PDF generation (pyppeteer.errors.TimeoutError) has been addressed by modifying the pdf.py file in the Jupyter Book or pyppeteer environment.\n\n\nThe line in pdf.py responsible for page navigation has been altered to:\nawait page.goto(f\"file:///{html_file}\", {\"timeout\": 0, \"waitUntil\": [\"networkidle2\"]})\nThis change eliminates the timeout restriction, allowing for the complete loading of pages, thereby resolving the timeout issue during PDF creation.\n\n\n\n\nIf you encounter the error\nVersionConflict(dist, req).with_context(dependent_req) pkg_resources.ContextualVersionConflict: (mdit-py-plugins 0.4.0 (lib/python3.10/site-packages), Requirement.parse('mdit-py-plugins~=0.3.1'), {'myst-parser'})\nThis error is a dependency conflict, specifically with the mdit-py-plugins package. The core of the issue is that your environment has mdit-py-plugins version 0.4.0 installed, but myst-parser, a dependency for Jupyter Book, requires a version close to 0.3.1 (~=0.3.1 indicates a version compatible with 0.3.1 but less than 0.4.0).\nTo resolve this issue, you need to downgrade mdit-py-plugins to a version compatible with myst-parser. Here’s how you can do it:\n\nActivate your environment: Ensure you’re working in the correct environment where Jupyter Book is installed.\nsource activate underwatersystems\nDowngrade mdit-py-plugins: Use pip to install a version of mdit-py-plugins that is compatible with myst-parser.\npip install \"mdit-py-plugins~=0.3.1\"\nThis command will uninstall the current version of mdit-py-plugins and install a version that is compatible with your current setup.\nVerify the installation: After downgrading, it’s a good practice to check if the correct versions are installed and if there are any other conflicting dependencies.\npip list\nLook through the list to confirm that mdit-py-plugins is now the correct version and there are no other conflicting packages.\nRetry building your Jupyter Book: Once the dependencies are sorted out, try rebuilding your Jupyter Book.\npython bin/build_jupyterbook_with_images.py\nCheck for further dependency conflicts: If you encounter additional dependency issues, you might need to repeat a similar process—identifying the conflict and adjusting package versions accordingly.\n\n\n\n\nWhen converting Jupyter Notebooks to PDF, especially through Jupyter Book, it is often necessary to control the pagination by inserting page breaks. This can be achieved through raw HTML or LaTeX commands, depending on the method used for PDF generation.\n\n\n\nInserting a Page Break: In your Jupyter Notebook, add a new cell and change its type to “Raw”. In this cell, input the following HTML code:\n&lt;div style=\"page-break-after: always;\"&gt;&lt;/div&gt;\nEffect in PDF: This tag will instruct the PDF renderer (when using HTML-based conversion like pdfhtml in Jupyter Book) to insert a page break at that point in the document.\n\n\n\n\n\nInserting a LaTeX Page Break: Add a new “Raw” cell in your notebook and input the following LaTeX command:\n\\newpage\nEffect in PDF: This command will cause a new page to start at that point when converting the notebook to PDF using LaTeX-based methods.\n\n\n\n\n\nCompatibility: The method chosen for inserting page breaks should align with the conversion tool used (HTML vs. LaTeX).\nNotebook Interface: These commands are only functional in the PDF output and will not affect the appearance of the notebook in the Jupyter interface.\nCustom Styles: Ensure that any custom CSS or LaTeX styling in your Jupyter Book configuration does not override these page break commands.\n\nBy following these instructions, you can effectively manage the layout and pagination of your Jupyter Book’s PDF output, enhancing the readability and professionalism of the document.\n\n\n\n\nThese enhancements aim to provide a more aesthetically pleasing and user-friendly experience when working with Jupyter Books in this project. For any queries or further modifications, feel free to update this document accordingly."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#custom-styling-for-jupyter-book",
    "href": "JUPYTER-BOOK-INTEGRATION.html#custom-styling-for-jupyter-book",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "To enhance the visual appeal of the Jupyter Book, custom CSS styles have been implemented. These styles affect the layout, typography, and overall aesthetic of both the HTML and PDF versions generated by Jupyter Book.\n\n\n\nTypography: Customized fonts and line spacing for improved readability.\nColor Scheme: A carefully selected color palette that is consistent across all pages.\nCode Styling: Enhanced styling for code blocks and inline code for better distinction from regular text.\nNavigation Menu: A revamped navigation menu with intuitive design for ease of navigation.\n\nThe custom styles can be found in the _static/custom_styles.css file. To modify these styles, edit this file and rebuild the book using Jupyter Book commands."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#script-for-image-inclusion-and-book-building",
    "href": "JUPYTER-BOOK-INTEGRATION.html#script-for-image-inclusion-and-book-building",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "The build_jupyterbook_with_images.py script has been developed to streamline the process of including images in the PDF version of the Jupyter Book. This script automates the copying of image files to the correct directory and triggers the Jupyter Book build process.\n\n\n\nPlace the script in the bin directory at the root of your Jupyter Book project.\nRun the script using the command:\npython bin/build_jupyterbook_with_images.py [notebooks_dir]\n\nThe script prompts for confirmation before proceeding with the operations, ensuring user control over the process."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#fix-for-pyppeteer.errors.timeouterror",
    "href": "JUPYTER-BOOK-INTEGRATION.html#fix-for-pyppeteer.errors.timeouterror",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "A common issue encountered during PDF generation (pyppeteer.errors.TimeoutError) has been addressed by modifying the pdf.py file in the Jupyter Book or pyppeteer environment.\n\n\nThe line in pdf.py responsible for page navigation has been altered to:\nawait page.goto(f\"file:///{html_file}\", {\"timeout\": 0, \"waitUntil\": [\"networkidle2\"]})\nThis change eliminates the timeout restriction, allowing for the complete loading of pages, thereby resolving the timeout issue during PDF creation."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#fix-for",
    "href": "JUPYTER-BOOK-INTEGRATION.html#fix-for",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "If you encounter the error\nVersionConflict(dist, req).with_context(dependent_req) pkg_resources.ContextualVersionConflict: (mdit-py-plugins 0.4.0 (lib/python3.10/site-packages), Requirement.parse('mdit-py-plugins~=0.3.1'), {'myst-parser'})\nThis error is a dependency conflict, specifically with the mdit-py-plugins package. The core of the issue is that your environment has mdit-py-plugins version 0.4.0 installed, but myst-parser, a dependency for Jupyter Book, requires a version close to 0.3.1 (~=0.3.1 indicates a version compatible with 0.3.1 but less than 0.4.0).\nTo resolve this issue, you need to downgrade mdit-py-plugins to a version compatible with myst-parser. Here’s how you can do it:\n\nActivate your environment: Ensure you’re working in the correct environment where Jupyter Book is installed.\nsource activate underwatersystems\nDowngrade mdit-py-plugins: Use pip to install a version of mdit-py-plugins that is compatible with myst-parser.\npip install \"mdit-py-plugins~=0.3.1\"\nThis command will uninstall the current version of mdit-py-plugins and install a version that is compatible with your current setup.\nVerify the installation: After downgrading, it’s a good practice to check if the correct versions are installed and if there are any other conflicting dependencies.\npip list\nLook through the list to confirm that mdit-py-plugins is now the correct version and there are no other conflicting packages.\nRetry building your Jupyter Book: Once the dependencies are sorted out, try rebuilding your Jupyter Book.\npython bin/build_jupyterbook_with_images.py\nCheck for further dependency conflicts: If you encounter additional dependency issues, you might need to repeat a similar process—identifying the conflict and adjusting package versions accordingly."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#specifying-page-breaks-in-jupyter-notebooks-for-pdf-output",
    "href": "JUPYTER-BOOK-INTEGRATION.html#specifying-page-breaks-in-jupyter-notebooks-for-pdf-output",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "When converting Jupyter Notebooks to PDF, especially through Jupyter Book, it is often necessary to control the pagination by inserting page breaks. This can be achieved through raw HTML or LaTeX commands, depending on the method used for PDF generation.\n\n\n\nInserting a Page Break: In your Jupyter Notebook, add a new cell and change its type to “Raw”. In this cell, input the following HTML code:\n&lt;div style=\"page-break-after: always;\"&gt;&lt;/div&gt;\nEffect in PDF: This tag will instruct the PDF renderer (when using HTML-based conversion like pdfhtml in Jupyter Book) to insert a page break at that point in the document.\n\n\n\n\n\nInserting a LaTeX Page Break: Add a new “Raw” cell in your notebook and input the following LaTeX command:\n\\newpage\nEffect in PDF: This command will cause a new page to start at that point when converting the notebook to PDF using LaTeX-based methods.\n\n\n\n\n\nCompatibility: The method chosen for inserting page breaks should align with the conversion tool used (HTML vs. LaTeX).\nNotebook Interface: These commands are only functional in the PDF output and will not affect the appearance of the notebook in the Jupyter interface.\nCustom Styles: Ensure that any custom CSS or LaTeX styling in your Jupyter Book configuration does not override these page break commands.\n\nBy following these instructions, you can effectively manage the layout and pagination of your Jupyter Book’s PDF output, enhancing the readability and professionalism of the document."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#conclusion",
    "href": "JUPYTER-BOOK-INTEGRATION.html#conclusion",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "These enhancements aim to provide a more aesthetically pleasing and user-friendly experience when working with Jupyter Books in this project. For any queries or further modifications, feel free to update this document accordingly."
  },
  {
    "objectID": "ocean_acoustics.html",
    "href": "ocean_acoustics.html",
    "title": "Ocean Acoustics",
    "section": "",
    "text": "This notebook covers the following topics:",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#history-of-ocean-acoustics",
    "href": "ocean_acoustics.html#history-of-ocean-acoustics",
    "title": "Ocean Acoustics",
    "section": "History of Ocean Acoustics",
    "text": "History of Ocean Acoustics\n\nIn 1490 Leonardo da Vinci first proposed detecting ships by listening to the noise they radiate into water.\n\n“If you cause your ship to stop and place the head of a long tube in the water and place the other extremity to your ear, you will hear ships at great distances.” From Leonardo Da Vinci’s Notebook.\n\nThe first successful measurements of the speed of sound in water was made in 1826.\nUsing a long tube to listen underwater, as suggested by da Vinci, Colladon and Sturm recorded how fast the sound of a submerged bell traveled across Lake Geneva.",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#the-first-recorded-attempt-to-determine-the-speed-of-sound-in-water",
    "href": "ocean_acoustics.html#the-first-recorded-attempt-to-determine-the-speed-of-sound-in-water",
    "title": "Ocean Acoustics",
    "section": "The First Recorded Attempt to Determine the Speed of Sound in Water",
    "text": "The First Recorded Attempt to Determine the Speed of Sound in Water\n\nIn 1826 on Lake Geneva, Switzerland, physicist Jean-Daniel Colladon and mathematician Charles-Francois Sturm made the first recorded attempt to determine the speed of sound in water.\nThey struck an underwater bell simultaneously with ignition of gunpowder on the first boat.\nThe sound of the bell and flash from the gunpowder were observed 10 miles away on the second boat.\nThe time between the gunpowder flash and the sound reaching the second boat was used to calculate the speed of sound in water.\nColladon and Sturm measured the water temperature in the lake to be 8° centigrade.\nAt this temperature, they determined the speed of sound in fresh water to be 1435 meters per second, which differs from the currently accepted value by only 3 meters per second.\nTheir published results also reported earlier measurements in sea water made in 1820 near Marseilles by physicist François Sulpice Beudant.\nThe value they determined was remarkably accurate.\nWWI and the advent of the submarine drove the development of sonar and the science of ocean acoustic/acoustical oceanography.\nMaurice Ewing (see also Marie Tharp and Lamont Geological Observatory) was convinced that it would be possible to propagate sound over hundredsd possibly thousands of kilometers through the ocean if both source and receiver were appropriately placed.\nIn 1945 he propagated sound from a small explosion over a distance of more than 3000 km from Eleuthera in the Bahamas to Dakar in West Africa.\n\n\n\n\n\n\n\n\n\nThe sound propagation took place in a ubiquitous permanent sound channel of the deep ocean.\nEwing called the channel the SOFAR (SOund Fixing And Ranging) channel.\nFirst application was downed-at-sea airmen: From his inflated rubber boat, the airman should drop small cartridges over the side set to explode on the axis of the SOFAR channel situated at about 1200 m depth in the North Atlantic.\n\n\n\n\n From Applied Underwater Acoustics.\n\n\n\n\nToday, acoustics is used to detect and locate objects and targets; to measure the characteristics of the environment or the velocity and location of moving underwater objects; and to transmit signals.",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#understanding-ocean-acoustics",
    "href": "ocean_acoustics.html#understanding-ocean-acoustics",
    "title": "Ocean Acoustics",
    "section": "Understanding Ocean Acoustics",
    "text": "Understanding Ocean Acoustics\n\nSound as a Pressure Wave\n\nOcean acoustics is the study of sound and its behavior in the sea.\nWhen underwater objects vibrate, they create sound-pressure waves that alternately compress and decompress the water molecules as the sound wave travels through the sea.\nSound waves radiate in all directions away from the source like ripples on the surface of a pond.\nThe compressions and decompressions associated with sound waves are detected as changes in pressure by the structures in our ears and most man-made sound receptors such as a hydrophone, or underwater microphone.\n\nThe basic components of a sound wave are frequency, wavelength and amplitude.\n\n\nWaves\n\nA wave is a self-propagating disturbance in a medium.\n\nThe wavefront of a wave field is the set (locus) of all points having the same phase\n\nIntuitively: Points reached by the perturbation at the same time\n\nIn an isotropic medium, which has the same properties in all directions, wavefronts are spherical:\n\nFor example, if we consider a sound wave emanating from a point source, the wavefront at any given instant would be a spherical surface centered on the source. All the points on the surface of the sphere would be reached by the wave at the same instant and would have the same phase. As the wave propagates outward from the source, the wavefront continues to expand and move further away from the source.\n\nWaves carry energy, momentum, information, but not matter!\n\n\n\nAcoustic waves in the ocean\n\nHydrostatic pressure is the pressure exerted by a stationary fluid (i.e., water in our case), at a particular point within the fluid (e.g., at a particular depth). It is the pressure that is created by the weight of the fluid above the point in question (\\(P = \\rho gh)\\).\nAcoustic pressure (or sound pressure) is the local pressure deviation from the ambient or average hydrostatic pressure caused by a sound wave\nAcoustic waves in water (and more specifially in salt water) are pressure waves\n\nCalled compressional waves\nPerturbation of the local pressure (of equilibrium) of the medium\n\n\n\n\nCompressional waves\n\nCompressional waves, also known as longitudinal waves or primary (P) waves, are a type of mechanical wave that propagate through a medium by causing compressions and rarefactions in the medium (think of the medium as composed of elementary elements)\nIn compressional waves, the particles in the medium vibrate parallel to the direction of wave propagation, creating regions of high pressure and high particle density (compressions) and regions of low pressure and low particle density (rarefactions).\nThe compression and dilation is transmitted to the neighbouring elements and the wave propagates\n\n\n\n\n\n\n\nFigure from University of Alicante, Spain (https://web.ua.es/en/urs/disclosure/seismic-wave-propagation.html)\n\nThe wave can be thought as created by the Y-Z plane pressing on the particles of the medium\nThis is a planar wave: wavefronts are planes\n\n\n\nSome comments\n\nSound is often illustrated with a sine wave but is actually a pressure wave\n\nThe peak in the sine wave indicating compaction of the medium and the trough indicating rarefaction (spreading out—thinning) of the medium.\n\nThe speed of sound depends on the distance between molecules and the strength of the intermolecular interactions.\nConsequently sound speed increases with density and temperature.\n\n\nIn a gas, the molecules are widely spaced with very low intermolecular forces. As a result, the speed of sound tends to be slower in gasses than liquids or solids. The speed of sound tends to be highest in solids: the molecules are relatively close together and the bonds and structure between them are stable.\n\n\n\nCharacteristics of Sound Waves\n\nSound waves are characterized by their amplitude, intensity, frequency, speed, wavelength, and phase.\nIf the pressure perturbation, wrt the equilibrium, is sinusoidal, then the pressure variation is also sinusoidal (in time and space):\n\n\\[\np(x, t) = Asin(kx-\\omega t + \\phi)\n\\]\nwhere - \\(p(x, t)\\) is the value of the wave at position \\(x\\) and time \\(t\\) - \\(A\\) is the amplitude of the wave, which determines its maximum displacement from its equilibrium position - \\(k\\) is the wave number, which is related to the wavelength of the wave by the equation \\(k = 2\\pi/\\lambda\\) (spatial frequency of the wave given a point in time). - \\(x\\) is the position along the wave - \\(w\\) is called radian frquenecy, the angular frequency of the wave, which is related to its frequency by the equation \\(\\omega = 2\\pi f\\) (temporal frequency of the wave given a point in space). - \\(\\phi\\) is the phase of the wave\n\nNote: the argument of the sin has two terms: one dependant from time (Angular frequency), and one from space (Wave number)\n\n\n\nAngular Frequency\n\nThe angular frequency, denoted by the symbol \\(\\omega\\), is a measure of how rapidly a wave oscillates in time.\nAlso called Radian Frequency\nIt is defined as the rate of change of the phase of the wave with respect to time and is related to the frequency of the wave through the equation:\n\n\\[\\omega = \\frac{2\\pi c}{\\lambda} = 2\\pi f\\]\n\nThe speed of sound in a medium is related to its frequency and wavelength through the equation: \\(c = f\\lambda\\)\n\n\n\nWave Number\n\nThe wave number, denoted by the symbol \\(k\\), is a measure of how rapidly a wave oscillates in space.\nIt is defined as the spatial frequency of a wave and is related to the wavelength of the wave through the equation:\n\n\\[k = \\frac{2\\pi}{\\lambda} = \\frac{\\omega}{c}\\]\n\nThe wave number is inversely proportional to the wavelength: waves with shorter wavelengths have larger wave numbers, while waves with longer wavelengths have smaller wave numbers.\nThe wave number is influenced by the properties of the medium and can affect the behavior of the wave as it propagates through the medium.\n\n\n\nWaves in phasor form\nThe equation for a sinusoidal wave can be written in phasor form as:\n\\[y(x,t) = A\\sin(kx - \\omega t + \\phi) = \\operatorname{Re}(Y e^{j(kx - \\omega t)})\\]\nwhere \\(\\operatorname{Re}()\\) denotes the real part of the expression, and \\(Y\\) is the phasor amplitude given by:\n\\[Y = A e^{j\\phi}\\]\nThe phasor amplitude \\(Y\\) is a complex number that captures both the amplitude and phase information of the wave in a single quantity. The real part of the product \\(Y e^{j(kx - \\omega t)}\\) gives the actual value of the wave at position \\(x\\) and time \\(t\\).\nTo obtain the phasor amplitude \\(Y\\), we first express the original equation in complex exponential form, which is given by:\n\\[y(x,t) = A\\sin(kx - \\omega t + \\phi) = \\frac{A}{2j}(e^{j(kx - \\omega t + \\phi)} - e^{-j(kx - \\omega t + \\phi)})\\]\nWe can recover the time domain function, \\(y(x, t)\\), by taking the real part of this rotating vector.\n\\[y(x,t) = \\operatorname{Re}\\left(\\frac{A}{2}e^{j(kx - \\omega t + \\phi)} - \\frac{A}{2}e^{-j(kx - \\omega t + \\phi)}\\right)\\]\nNow we can see that the expression in parentheses is a phasor amplitude \\(Y\\), which has a magnitude of \\(A/2\\) and a phase angle of \\(\\phi\\), multiplied by a complex exponential term that depends on \\(x\\) and \\(t\\).\nBy expressing the wave in phasor form, we can more easily manipulate its amplitude and phase properties, and we can use complex arithmetic to analyze the wave’s behavior.\nLet’s see some of this in Python\n\nWe can think of the sine wave as a change both in time and space.\nIf we plot the changes at various locations, each time snapshot will be a sine wave that changes in space.\nSee the following figure with a fix point at \\(x=2.5\\) showing as a red dot.\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nplt.style.use('seaborn-v0_8')\n# %matplotlib inline\n\n\nfig = plt.figure(figsize = (8,8))\n\ntimes = np.arange(5)\n\nn = len(times)\nx = np.linspace(0, 20, 201)\ny = np.sin(x)\n\nfor t in times:\n    plt.subplot(n, 1, t+1)\n    y = np.sin(x + t)\n    plt.plot(x, y, 'b')\n    plt.plot(x[25], y [25], 'ro')\n    plt.ylim(-1.1, 1.1)\n    plt.ylabel('y')\n    plt.title(f't = {t}')\n\nplt.xlabel('location (x)')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nOf course, you can see the changes over time at specific location as well, you can plot this by yourself.\n\n\nSuperposition of waves\n\nWhen two or more waves are present in the same medium, the resulting disturbance at any point is the algebraic sum of the individual disturbances caused by each wave.\nThe waves pass through each other without being disturbed.\nThe net displacement of the medium at any point in space or time, is simply the sum of the individual wave displacements.\nThis is true of waves which are finite in length (wave pulses) or which are continuous sine waves.\nWhen two waves of the same frequency and amplitude are in phase (i.e., their crests and troughs coincide), their amplitudes add up, resulting in a wave with twice the amplitude. This is called constructive interference.\nWhen two waves of the same frequency and amplitude are out of phase (i.e., their crests and troughs do not coincide), their amplitudes cancel out, resulting in zero amplitude. This is called destructive interference.\nFundamental concept in wave physics and enables us to predict the behavior of complex wave systems, such as interference patterns\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\n\n# Wave parameters\nA = 0.5  # Amplitude\nk = 2 * np.pi / 10  # Wave number\nomega = 2 * np.pi / 2  # Angular frequency\n\n# Time and space parameters\nt = np.linspace(0, 10, 200)  # Time vector\nx = np.linspace(0, 20, 400)  # Space vector\nX, T = np.meshgrid(x, t)\n\n# Individual wave functions\ny1 = A * np.sin(k * X - omega * T)\ny2 = A * np.sin(-k * X - omega * T)\n\n# Resulting wave function (superposition of individual waves)\ny = y1 + y2\n\n# Plot individual waves and resulting wave\nfig, ax = plt.subplots()\nax.set_xlim(0, 20)\nax.set_ylim(-1, 1)\nline1, = ax.plot([], [], lw=2, label='Wave 1')\nline2, = ax.plot([], [], lw=2, label='Wave 2')\nline3, = ax.plot([], [], lw=2, label='Resulting wave')\nax.legend()\n\ndef init():\n    line1.set_data([], [])\n    line2.set_data([], [])\n    line3.set_data([], [])\n    return line1, line2, line3\n\ndef animate(i):\n    line1.set_data(x, y1[i, :])\n    line2.set_data(x, y2[i, :])\n    line3.set_data(x, y[i, :])\n    return line1, line2, line3\n\nani = animation.FuncAnimation(fig, animate, frames=len(t), init_func=init, blit=True)\nplt.close()  # Prevents duplicate display of animation\n\nUncomment the next cell to show the animation (it does not render correctly in quarto).\n\n# ## Display animation\n# from IPython.display import HTML\n# HTML(ani.to_jshtml())\n\n\n\nWave characteristics in one slide\n\nA single wave has different characteristics:\n\n\n\n\n\n\n\n\n\n\n\n\nAmplitude (A), is used to describe the difference between the maximum values to the baseline value. Amplitude describes the height of the sound pressure wave or the “loudness” of a sound and is often measured using the decibel (dB) scale. Small variations in amplitude (“short” pressure waves) produce weak or quiet sounds, while large variations (“tall” pressure waves) produce strong or loud sounds.\nPeriod (T), A sine wave is a periodic signal, which means it repeats itself after certain time. The period of a wave is time it takes to finish the complete cycle, in the figure, we can see that the period can be measured from the two adjacent peaks.\nWavelength (\\(\\lambda\\)), measures the distance between two successive crests or troughs of a wave.\nFrequency (f) describes the number of waves that pass a fixed place in a given amount of time. Frequency can be measured by how many cycles pass within 1 second. Therefore, the unit of frequency is cycles/second, or more commonly used Hertz (abbreviated Hz).\n\n\\[T = \\frac{1}{f}\\]\nLet’s go back to our representation of a sine wave:\n\\[ y(t) = Asin(\\omega{t}+\\phi)\\]\nwhere \\(A\\) is the amplitude of the wave, \\(\\omega\\) is the angular frequency, which specifies how many cycles occur in a second, in radians per second. \\(\\phi\\) is the phase of the signal. If \\(T\\) is the period of the wave, and \\(f\\) is the frequency of the wave, then \\(\\omega\\) has the following relationship to them:\n\\[\\omega = \\frac{2\\pi}{T} = 2\\pi{f}\\]\n\n\nAcoustic Rays\n\nAn acoustic ray is a line that represents the path traveled by sound waves as they propagate through a medium.\nIt is a trajectory that shows the direction of propagation of sound waves in a particular medium, such as air, water, or solid materials.\nGiven a wavefront, the ray associated to the wavefront is perpendicular to the wavefront in every point.\nConnecting the rays (perpendicular to the wavefronts in every point) we obtain a trajectory that is called ray path.\nThese are the same concepts we find in optics.\nAcoustic Rays will be useful to obtain an intuitive understanding of acoustic propagation\nWe will see when this approximation is valid using the wave equation",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#ocean-acoustics-quantities-and-jargon",
    "href": "ocean_acoustics.html#ocean-acoustics-quantities-and-jargon",
    "title": "Ocean Acoustics",
    "section": "Ocean acoustics: quantities and jargon",
    "text": "Ocean acoustics: quantities and jargon\n\nAcoustic Intensity\n\nAcoustic intensity is the power per unit area carried by a sound wave.\nIt is typically measured in units of watts per square meter (W/m²)\nAcoustic Intensity is proportional to the square of the RMS (Root Mean Square) pressure\n\n\\[ I = \\frac{1}{\\rho c}p_{rms}^2\\]\nwhere: - \\(\\rho\\) is the water density - \\(c\\) is the speed of sound: speed of propagation of the pertubation - \\(Z=\\rho c\\) is called acoustic impedence\n\n\nAcoustic Impedence\n\nProperty of a medium and describes how much resistance the medium offers to the propagation of a sound wave. - It is a measure of the ratio of sound pressure to the particle velocity of the medium.\nClose analogy with electrical impedance\n\nwhere the RMS pressure is analogous to voltage and the acoustic impedance is analogous to the electric resistance R.\n\nWhy RMS pressure? If we have a sinusoidal wave, the pressure will oscillate between a positive and negative number with zero mean. It has however a RMS value: \\[ rms = \\sqrt{\\frac{1}{n}\\sum_{i}{x^2_i}} \\]\n\n\n\nDecibel\n\nIn the analysis of sound propagation, it is customary to use the decibel (dB) notation to represent the level of various quantities relative to a chosen reference value of the quantity.\nThis is a convenient way to handle the wide dynamic range involved in acoustic problems.\nIt also simplifies many system calculations by replacing multiplications with additions of decibel quantities.\nDecibels (dB) are a logarithmic unit that express the ratio between two quantities, usually some form of power or intensity.\nIn the case of sound, decibels are often used to express the relative loudness of a sound compared to some reference level.\n\n\nDefinition\n\nThe decibel is 1/10 of a bel, which is a logarithmic unit of a power or an energy ratio.\nThe decibel (dB) corresponds to 10 times the base-10 logarithm of the ratio of two powers or energies.\n\nFor example:\n\\[\n\\text{Power Level} = \\text{WL}_{dB} = 10\\log_{10} \\frac{\\text{W}_1}{\\text{W}_2}\n\\]\nwhere the unit is Watt.\n\nIf \\(\\text{WL}_{dB}\\) is 10 dB, W1 is 10 times higher than W2.\nIf \\(\\text{W}_1\\) is two times larger than \\(\\text{W}_2\\), \\(\\text{WL}_{dB}\\) = 3 dB.\n\n\n\n\nAcoustic intensity levels\nThe intensity level \\(\\text{IL}\\) in \\(dB\\) in an acoustic field may be expressed by:\n\\[\n\\text{IL}_{dB} = 10\\log_{10} \\frac{\\text{I}_1}{\\text{I}_2}\n\\]\nWhere \\(I_1\\) and \\({I_2}\\) are acoustic intensities: power per unit area\n\nSince the acoustic intensity is proportional to the square of the effective acoustic pressure (unit: Pa)\nThe acoustic Sound Pressure Level (SPL) in dB may be expressed by:\n\n\\[\n\\text{SPL} = 20\\log_{10} \\frac{p_1}{p_2}\n\\]\n\nReference Quantities\n\nAll quantities with subscript 2 are considered as reference quantities.\nThere are several units used to specify reference pressure in acoustics.\nIn air acoustics the reference quantity is \\(20\\mu\\)Pa (equivalent to the reference intensity of \\(10^{-12} W/m^2\\)). This is used so that \\(0\\)dB corresponds to the hearing threshold of an average person (\\(20 \\mu\\)Pa at 1m).\nIn underwater acoustics the reference quantity is \\(1\\mu\\)Pa (equivalent to the reference intensity of \\(6.67\\cdot10^{-19} W/m^2\\))\nSometimes the reference quantity is also \\(1\\mu\\)bar (\\(10^5\\mu\\)Pa).\nIn underwater acoustics is important to specify the reference quantity which is being used.\n\nFor example: - Sound pressure level \\(\\text{SPL}=210\\)dB re \\(1\\mu\\)Pa. - This means that the acoustic pressure \\(p_1==10^{210/20}10^{-6} = 0.316\\cdot10^5\\) Pa.\n\n10**(210/20)*1e-6\n\n31622.776601683792\n\n\n\n\n\nTransmission Loss\n\nSound Pressure Level is also called Transmission Loss (\\(\\text{TL}\\)):\n\n\\[\n\\text{TL}_{dB} = 10\\log_{10} \\frac{I}{I_0} = 20\\log_{10} \\frac{p}{p_0}\n\\]\n\nratio between the received intensity level (\\(I\\)) and the source intensity (\\(I_0\\)) in dB.\nIt is the decrease in sound intensity as sound travels through a medium\nLoss occurs due to the absorption, reflection, and scattering of sound waves by the medium through which it travels.\nIt is a relative metric (wrt the source intensity).\nArguably the most important quantity with which we interprect acoustic propagation\n\\(\\text{TL}\\) does not make it possible to know how loud is the source, it only tells us how much we lose through propagation",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#source-level-and-reference-intensity",
    "href": "ocean_acoustics.html#source-level-and-reference-intensity",
    "title": "Ocean Acoustics",
    "section": "Source Level and Reference Intensity",
    "text": "Source Level and Reference Intensity\n\nSource Level\n\\(\\text{SL}\\), is the ratio between the intensity of the source @ 1m, from the source position and a reference intensity, in dB. - Note: we never measure intensity. Sensors measure pressure, and for this reason we work with pressures (and hence with \\(20\\log\\)).\n\n\nReference intensity\nBecause of its large range, sound amplitude is often described in logarithmic units, decibels (dB).\nSome small pressure is used as a reference pressure, and any other sound pressure is described as a level with respect to that reference pressure.\n\nResearchers studying sound in water and air typically use a different reference pressure\nIn ocean acoustics, the reference intensity is the intensity of a plane wave with RMS pressure of \\(1\\mu\\)Pa\nAir acoustics uses \\(20 \\mu\\)Pa as reference intensity: 0dB corresponds to the hearing threshold for a normal human listener for a sound frequency of 1,000 Hz.\nThese two references are, therefore, 26 dB apart (20 log 20 = 26)\nThis means that \\(20\\) dB underwater and in air correspond to different intensities!\nIf I have a \\(20\\) dB Sound Pressure Level, underwater corresponds to \\(10 * 1 \\mu\\)Pa.\nIf I have a \\(20\\) dB Sound Pressure Level, in air, corresponds to \\(10 \\cdot 20\\mu\\)Pa.\ndB is not a unit of measurement! and we need a reference.\n\n\n20*np.log10(10), 20*np.log10((10*20)/20)\n\n(20.0, 20.0)",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#features-of-oceanography",
    "href": "ocean_acoustics.html#features-of-oceanography",
    "title": "Ocean Acoustics",
    "section": "Features of Oceanography",
    "text": "Features of Oceanography\nOceanography is the study of the world’s oceans and their physical, chemical, and biological processes. It is an interdisciplinary science that combines elements of physics, chemistry, geology, biology, and meteorology to understand the complex interactions that occur within the marine environment.\nKey features include\n\nOcean Circulation: The ocean is in constant motion, with currents flowing at different depths and speeds. These currents are driven by a variety of factors, including wind, temperature, and salinity differences, and play a crucial role in the distribution of heat and nutrients throughout the ocean.\nWaves and Tides: Waves and tides are also important features of the ocean, affecting both the physical and biological aspects of the marine environment.\nOcean Chemistry: The chemical composition of the ocean is constantly changing, as it receives inputs from rivers, the atmosphere, and submarine vents. Oceanographers study how these inputs affect the ocean’s pH, salinity, and nutrient levels, and how these changes impact marine life and global climate.\nMarine Biology: The ocean is home to an incredibly diverse array of life, from microscopic plankton to massive whales. Oceanographers study the distribution and behavior of these organisms, as well as the complex interactions that occur within marine ecosystems.\nCoastal Processes: The interactions between the ocean and the land are also an important focus of oceanography, as they affect both the physical and human environments. Coastal processes include erosion, sediment transport, and the formation of beaches and estuaries.\n\n\nSound Speed Profiles (SSP)\n\nIn ocean acoustics, sound speed profile refers to the variation of the speed of sound in seawater as a function of depth, pressure, temperature, and salinity\nThe main factor affecting the propagation of acoustic waves in the ocean is the speed of sound\nIt has a nominal value of 1500 m/s in temperate and equatorial oceans\nSmall variations in the speed of sound have a profound effect on acoustic propagation in the ocean.\nThe speed of sound at any point in the ocean (non-linearly) depends on the local temperature, salinity, and hydrostatic pressure (or depth).\nIn a horizontally stratified ocean, the temperature and salinity are independent of horizontal range: they only vary with depth.\n\nSound speed only vary with depth\n\nThis is roughly true in the deep oceans (away from features such as eddies or fronts).\n\n\n\n\n\nTemperature, salinity, and sound speed profiles, Tonga Trench, South Pacific Ocean, September 2012 (Applied Underwater Acoustics).\n\n\n Tonga Trench: it is the deepest trench in the Southern hemisphere and the second deepest on Earth after the Mariana Trench.\n\n\n\n\nOver most of the ocean depth the salinity is essentially uniform\n\nClose to 34.85 parts per thousand\n\nVariations in the sound speed profile are driven by the temperature and the pressure.\n\n\n\n\nSound speed profile, Tonga Trench, South Pacific Ocean, September 2012 (Applied Underwater Acoustics).",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#chen-millero-empirical-equation",
    "href": "ocean_acoustics.html#chen-millero-empirical-equation",
    "title": "Ocean Acoustics",
    "section": "Chen-Millero Empirical Equation",
    "text": "Chen-Millero Empirical Equation\n\nSound speed depends on salinity, temperature and depth\nSound speed equation identified based on multiple measurements of salinity, temperature and depth done across the seas and the oceans\n\n\\[\nc = 1449.2 + 4.6T - 0.055T^2 + 0.000229T^3 + (1.34-0.01T)(S-35) + 0.016Z\n\\]\nwhere - \\(c\\) \\(m/s\\), sound speed - \\(T\\) \\(^oC\\), temperature - \\(S\\) \\(psu\\), salinity (parts per thousand) - \\(Z\\) \\(m\\), depth\nIt is an empirical equation (UNESCO certified)\n\nComments\n\nSound is faster with temperature (Warmer waters means sound is faster)\nSound is faster with depth (linearly)\nSound is also faster with salinity\nIn the same geographical place, sound speed varies as we go down in water column.\n\n\n\nA typical profile\n\n\n\n\n\n\n\nVery close to the surface: - Depth is small (\\(Z \\approx 0\\)). - Temperature and salinity drive the speed. - Temperature is strongly influenced by solar radiation. Sound speed depends from hourly variations.\nClose to the surface: - Seasonal variations in temperature (winter vs summer) - drops in temperature drive drops in speed - seasonal thermocline (i.e., seasonal temperature gradient).\nFor ex. in the Mediterranean Sea, temperature is approx constant in the first 10m, then it start decreasing. At what depth exactly depends on local conditions.\nBetween 200/300m - 500m - Temperature decreases more or less in the same way everywhere - Atmospheric influence is not important anymore - Specific depth depends on geographic location - This is called main thermocline\nBelow 1000m - Temperature does not vary anymore (deep isothermal layer) - Depth drives change in sound speed.\nSee also Technical Guides - Speed of sound in sea water\n\n\nMunk Profiles\n\nA canonical model of the sound speed profile in the deep ocean has been developed by Munk\nAssumes specific properties of the ocean (i.e., exponential stratification: density of seawater exponentially increases with depth)\nThere is not a single Munk profile but they are representative of a behaviour\n\nsee also: Munk, W. H., Sound channel in an exponentially stratified ocean, with application to SOFAR, J. Acoust. Soc. Am., 55, pp. 220e226 (1974).\n\n# z is in km\nz_1 = 1.2  # z1 is the depth of the sound channel axis\nc_1 = 1500 # c1 is the speed of sound at the axis\nB = 1.3    # km\n\nepsilon = 0.0074\n\nz_vector = np.linspace(0, 5, 60)\nc_z = []\nfor z in z_vector:\n    eta = 2*(z-z_1)/B    \n    c_z.append(c_1*(1 + epsilon*(eta+np.e**-eta-1)))\n\n    \nconjugate_speed = c_z[np.where(c_z&gt;c_z[0])[0][0]]\nconjugate_depth = z_vector[np.where(c_z&gt;c_z[0])[0][0]]\n    \nplt.figure(figsize=(5, 6))\nplt.plot([min(c_z), max(c_z)], [z_1, z_1], color='black', linestyle='--')\nplt.plot([c_z[0], c_z[0]], [z_vector[0], z_vector[-1]], color='black', linestyle='--')\n\nplt.plot([conjugate_speed-10, conjugate_speed+10], [conjugate_depth, conjugate_depth], color='black', linestyle='--')\nplt.text( 1540, 1, 'sound channel axis')\nplt.text( 1540, conjugate_depth, 'conjugate depth')\nplt.text( 1510, conjugate_depth+0.5, 'depth excess')\n\nplt.plot(c_z, z_vector)   \nplt.gca().invert_yaxis()\nplt.xlabel('sound speed (m/s)')\nplt.ylabel('depth (km)')\n\nText(0, 0.5, 'depth (km)')\n\n\n\n\n\n\n\n\n\nComments: - At the conjugate depth, sometimes referred to as the critical depth, the sound speed is equal to that at the sea surface, and in the region labeled “depth excess,” it is greater than the speed of sound at the sea surface. - Any profile showing a depth excess supports convergence zone propagation, whereby steep rays follow deep, upward refracted paths and regions of high intensity known as convergence zones, or caustics are formed near the surface at regular intervals in range - Typically, the range interval between convergence zones in the Atlantic Ocean is of the order of 60 km.",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#influence-of-temperature-salinity-and-depth-on-the-ssp",
    "href": "ocean_acoustics.html#influence-of-temperature-salinity-and-depth-on-the-ssp",
    "title": "Ocean Acoustics",
    "section": "Influence of Temperature, Salinity and Depth on the SSP",
    "text": "Influence of Temperature, Salinity and Depth on the SSP\n\n\n\n\n\n\n\n\n\n\nTemperature - \\(\\text{T}\\) is a typical profile. - The shallower part migth have daily or seasonal variations. - Main thermocline when temperature decreases. - At deeper depths, is constant between 1 and 3 degrees. - Typical profile is representative of the behaviour.\nSalinity - \\(\\text{S}\\) is a typical profile - Minimum at a certain depth (around 1000m) - At deep depths, it is almost constant\nSpeed corrections in the Chen-Millero equations due to each separate contribution are reported in the middle graph above: - The speed correction \\(\\Delta C_T\\) follows closely the temperature profile. - Change in speed is about \\(60-70\\) m/s - \\(\\Delta C_P\\) is the change in speed due to change in depth - \\(\\Delta C_S\\) is the change in speed due to change in salinity. Salinity only contributes a few m/s.\n\nAt shallow depths, sound speed mostly depends on temperature\nAt deep depths, sound speed mostly depends on depth.\n\n(see right most plot).\n\nTemperature at sea surface\n\nMonthly average\n\n\n\n\n\n\n\nSea Surface Temperature, NASA Earth Oservatory. Satellite measurements.\n\n\n\n\n\n\nMaps based on observations by the Moderate Resolution Imaging Spectroradiometer (MODIS) on NASA’s Aqua satellite.\nThe satellite measures the temperature of the top millimeter of the ocean surface.\nIn this map, the coolest waters appear in blue (approximately -2 degrees Celsius), and the warmest temperatures appear in pink-yellow (35 degrees Celsius).\n\nThe most obvious pattern shown in the time series is the year-round difference in sea surface temperatures between equatorial regions and the poles. Various warm and cool currents stand out even in monthly averages of sea surface temperature. A band of warm waters snakes up the East Coast of the United States and veers across the North Atlantic the Gulf Stream.\nData is available from the NASA website\n\n\nSeasonal Average\n\n\n\n\n\n\n\nNotable features - Humboldt currents - Gulf stream\nData from NOAA and its interactive website",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#temperature-vs-depth",
    "href": "ocean_acoustics.html#temperature-vs-depth",
    "title": "Ocean Acoustics",
    "section": "Temperature vs depth",
    "text": "Temperature vs depth\n\n\n\n\n\n\n\n\n\n\n\nDepths are indicatives (they might change depending on latitude/longitudes)\nNote the difference between high latitudes and mid-latitudes\nFirst layer: Mixed layer where temperature depends on the thermal exchange with the atmosphere\n\npresence of seasonal thermoclines (right picture)\n\nMain permanent thermocline\nIsothermal deep layer\nTropics have less seasonal difference, and have a much steeper permanent thermocline due to warmer waters at the surface (see also Montly and seasonal average plots above).\nAt High latitudes, surface water is 1 or 2 degrees (e.g. due to ice meltings and salty waters), and there is no (or almost no) thermocline.",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#depth-and-temperature-distribution-across-the-atlantic",
    "href": "ocean_acoustics.html#depth-and-temperature-distribution-across-the-atlantic",
    "title": "Ocean Acoustics",
    "section": "Depth and Temperature Distribution across the Atlantic",
    "text": "Depth and Temperature Distribution across the Atlantic\n\nWater physical properties (temperatude, salinity, etc) changes with depth and latitude/longitude\nThe picture below shows what happens when we travel across the Atlantic\nData from EWOCE\nNote how the main thermocline moves deeper as we travel from high latitudes to mid-latitudes, to the equator\nSSP would still resemble a Munk profile but their key points would be different\nNote also the difference between same latitudes in the North and South Atlantic due to presence of the Gulf Stream in the North Altantic.\nSee also Metoffice | The Atlantic Meridional Overturning Circulation",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#measuring-temperature",
    "href": "ocean_acoustics.html#measuring-temperature",
    "title": "Ocean Acoustics",
    "section": "Measuring Temperature",
    "text": "Measuring Temperature\n\nRather than being measured directly, the sound speed profile is commonly computed from temperature and salinity data recovered from a conductivity, temperature and depth (CTD) probe or from temperature data acquired with a bathy-thermograph (BT)\nIn the case of the latter, the salinity, which is not returned by the BT, is often estimated for the purpose of computing the sound speed profile from archival salinity data\nA direct measure of the sound speed profile may be obtained using a sound velocity sensor (SVX) based on the “sing-around” principle. An ultrasonic pulse is transmitted over a fixed path between a source and a receiver. When the pulse arrives at the receiver, it triggers the transmission of another pulse from the projector. The repetition frequency of the pulses is mainly determined by the travel time over the path length, which is controlled by the speed of sound in the fluid (seawater in the case of ocean profiling) between the source and receiver.",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#salinity",
    "href": "ocean_acoustics.html#salinity",
    "title": "Ocean Acoustics",
    "section": "Salinity",
    "text": "Salinity\nDefinition: “Total material amount in grams dissolved within 1kg of seawater”\n\nDissolved: pass through a 0.2\\(\\mu m\\) filter\nAdimensional quantity: grams over kilos, which is equivalent to say “parts per thousands” (ppt)\nOperative definition: we can use it to measure salinity. Measuring salinity using the definition is not really practical…\nAlternative: Practical Salinity Scale (psu),\n\nThe most practical method currently used is through electrical conductivity.\nThis is an indirect method which needs an accurate relationship between the conductivity \\(C\\) and the salinity \\(S\\) as a function of temperature \\(T\\) and pressure \\(p\\).\nThe salinity determined in this way is called the practical salinity\n\nIt is not exactly equivalent to measuring salinity in parts per thousands.\nElectrical conductivity is easy to measure\n\n\nTo reduce measurement errors, we measure the relative conductivity \\(R\\): - The seawater conductivity \\(C(S,T)\\) relative to the conductivity \\(C(35,15)\\) of a standard saline solution at \\(15^o\\)C containing \\(32.4356 g\\) Potassium chloride (KCl, or potassium salt) in a mass of \\(1\\) kg (ppt) at 1 atm pressure (1 atm = 101325 Pa).\n\nRelative conductivity: \\[R=\\frac{C(S,T)}{C(35,15)}\\]\n\nThe relationship between the salinity \\(S(T)\\) and the relative conductivity \\(R=R(S,T)\\):\n\\[\nS(T) = S(15) + \\Delta S(T)\n,\\;\\;\nR=\\frac{C(S,T)}{C(35,15)}\n\\]\n\\[\nS(15) = 0.008 − 0.1692R^{1/2} + 25.3851 R + 14.0941 R^{3/2} − 7.0261 R^2 + 2.7081R^{5/2}\n\\]\n\\[\nΔS(T) = \\frac{(T−15)}{1+0.0162(T−15)} + 0.0005 − 0.0056 R^{1/2} − 0.0066 R − 0.0375 R^{3/2} + 0.0636 R^2 − 0.0144 R^{5/2}\n\\]\nfor \\(2\\le S \\le42\\). If \\(R=1\\) we have \\(S=35\\).\n\nSalinity Sensors\nSalinity sensors measure the electrical conductivity of seawater, which is proportional to its salinity.\n\nPlatinum Electrode Conductivity Sensor\n\nMeasure the electrical conductivity of seawater.\nThe sensor consists of two platinum electrodes that are immersed in the seawater.\nAn alternating current is passed through the electrodes, and the electrical resistance of the seawater between the electrodes is measured.\nThe electrical conductivity of the seawater is proportional to the concentration of dissolved salts in the water, including sodium, chloride, and other ions.\nPlatinum electrode conductivity sensors have the advantage of being relatively simple and robust\nProvide accurate salinity measurements over a wide range of temperatures and salinities.\n\nConductivity, \\(C\\), is found as:\n\\[\nC = G \\cdot k_c\n\\]\nwhere \\(G\\) is the conductance, and \\(k_c\\) is the cell constant.\n\nConductance is defined as the reciprocal of resistance. When resistance is measured in ohms, conductance is measured using the SI unit, siemens (water samples are commonly measured in microsiemens, or µS - Siemens is a large unit).\n\nThe cell constant is determined for a probe as:\n\\[\nk_c = d/A\n\\]\nwhere \\(d\\) is the distance between the two electrodes, and \\(A\\) is the area of the electrode surface.\n\nA potential difference is applied to the two probe electrodes in the salinity sensor.\nThe resulting current is proportional to the conductivity of the solution.\nThis current is converted into a voltage.\n\n\n\n\n\n\n\n\n\n\n\n\n\nElectrodeless Conductivity Sensor (Inductive)\n\nUse inductive coils.\nThe sensor consists of two coils which are incorporated next to one another in a polymer or ceramic body, and forming a current transformer.\nThe coupling between the two coils of a transformer depends on the conductivity of the medium (in our case sea water)\n\nThe sensor is designed so part of the liquid media forms a closed conductive current path passing through the coils. Current is applied to the primary coil (generating coil), which induces an alternating voltage in the liquid loop. In liquids which conduct electricity, this causes a current flow captured by the second coil (receiving coil), which is proportional to the conductivity of the sample solution.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSalinity at sea surface\n\n\n\n\n\n\n\n\n\nGlobal map of monthly sea surface salinity, May 2022. From https://salinity.oceansciences.org/data-maps.htm\n\n\n\n\nOn average, sea surface salinity is about 35 PSS.\nOver the globe, sea surface salinity varies from 32 to 37 PSS.\nSalinity variations are caused by precipitation, evaporation, runoff, and ice freezing and melting.\nSeawater’s density – mass per volume – is governed by temperature, salinity, and depth.\n\nAlong with temperature, salinity is a major factor in contributing to changes in the density of seawater and therefore ocean circulation.\n\nOcean circulation below the wind-driven surface (tens to hundreds of meters in depth) is driven by changes in seawater density.\n\n\n\n\n\n\n\n\nNASA Salinity Ocean Sciences, https://salinity.oceansciences.org/overview.htm.\n\n\n\n\n\n\n\nSalinity vs Depth\n\n\n\n\n\n\n\n\nHigh Laitudes: low salinity at the surface\nLow Latitudes: high salinity at the surface\nHalocline: salinity gradient\n\n\n\nTemperature, Salinity and Density\n\n\n\n\n\n\n\n\nDensity of Ocean is determined by temperature, the quantity of dissolved salts (also known as salinity), and the pressure to which a parcel of seawater is exposed\nThe density of seawater can be increased by reducing its temperature, increasing its salinity, or increasing the pressure\nPressure has the least impact on density as water is fairly incompressible, so pressure effects are not very significant except at extreme depths\nTemperature and salinity are the primary factors determining density, and of these, temperature has the greatest impact\nDensity is lowest at the surface, where the water is the warmest. As depth increases, there is a region of rapidly increasing density with increasing depth\nDensity changes are important for robotics: buoyancy!\nAffects vehicle balancing\n\n\n\nSea surface density",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "ocean_acoustics.html#back-to-sound-speed",
    "href": "ocean_acoustics.html#back-to-sound-speed",
    "title": "Ocean Acoustics",
    "section": "Back to Sound Speed",
    "text": "Back to Sound Speed\n\n\n\n\n\n\n\n\nTypical value: 1500 m/s\n\nPolar regions: sound speed is usually only increasing with depth.\n\nTemperature more or less constant (already low), and sound speed increases with depth\n\nSurface duct profile\n\nSurface waters has temperature lower (a few degrees) than that 5-10m below (e.g., summer nights cooling thin surface layers after very hot days)\nSound speed slower than that of lower layers.",
    "crumbs": [
      "Ocean Acoustics"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html",
    "href": "sonar_practical_applications.html",
    "title": "SONAR Practical Applications",
    "section": "",
    "text": "Specific devices: - Multi-beam echosounders: used for bathymetric measurements - Side-scan sonars: sea-bed morphology",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#multi-beam-echosounders-an-example",
    "href": "sonar_practical_applications.html#multi-beam-echosounders-an-example",
    "title": "SONAR Practical Applications",
    "section": "Multi-beam echosounders: an example",
    "text": "Multi-beam echosounders: an example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFly through the reconstructed Digital Terrain Model (CODEMAP Cruise, NOC)\n\n\n\n\n\n(a,c) ship-board EM120 downward-looking multibeam echosounder (MBES) (resolution 50 m), (b,d) sideways-looking AUV mounted MBES (b) resolution 0.5 m; (d) resolution 5 m and (e) ROV front-mounted MBES (resolution 0.4 m). Whittard Canyon Acesta Wall (a,b,e) and Whittard Canyon Coral Wall (c,d). Figure from K. Roberts et al, New approaches to high-resolution mapping of marine vertical structures, 2017, Nature Scientific Reports",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#side-scan-sonars-an-example",
    "href": "sonar_practical_applications.html#side-scan-sonars-an-example",
    "title": "SONAR Practical Applications",
    "section": "Side Scan Sonars: an example",
    "text": "Side Scan Sonars: an example\n\nComparable to photographic images\nRelatively easy to intuitively read them (although can be very complicated when looking for specific details)\n\n\n\n\n\n\n\n\nFigure: Side-scan sonar image of schooner Typo, which collided with steamer W.P. Ketcham in October of 1899. The schooner, which was carrying a cargo of coal, was rammed in the stern. The sonar image shows the bow and upright foremast, cargo hatches across Typo’s deck, and the broken stern with a pile of spilled coal. Image Source: Michigan Technological University Great Lakes Research Center. Image courtesy of the Michigan Technological University Great Lakes Research Center. Downloaded from NOAA’s website",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#multi-beam-echosounders",
    "href": "sonar_practical_applications.html#multi-beam-echosounders",
    "title": "SONAR Practical Applications",
    "section": "Multi-beam echosounders",
    "text": "Multi-beam echosounders\n\nBathymetric measurements done reading the time-of-flight of the tranmistted signal (two-way travel time)\nTypically mounted on the keel of the ship\nOne transducer that tranmists and one that received. Typically collocated (Active Monostatic Sonar)\n\n\nA single-beam echosounder\n\nDistance is measured by multiplying half the time from the signal’s outgoing pulse to its return by the speed of sound in the water.\nMeasurements are repeated periodically to measure the depth of the seabed measuring the time of flight\n\n\n\n\n\n\n\n\n\nMultibeam echosounders do the same thing (there is the beam perpendicular to the seabed), but emits a number of other beams that insonify neighbouring areas and calculate the time of flight of all the beams\nKnowing the angle of each beam we can calculate the depth\n\n\n\n\n\n\n\n\n\n\n\n\nFigures: Scanning with Multibeam Bathymetry. Credit: Wessex Archaeology (Left), Hydro International (Right)\n\nMBES Represented a step change in measuring the ocean\nThe purpose of a large-scale bathymetric survey is to produce accurate depth measurements for many neighboring points on the sea floor such that an accurate picture of the geography of the bottom can be established.\nTo do this efficiently, two things are required of the sonar used:\n\nit must produce accurate depth measurements that correspond to well-defined locations on the sea floor (that is, specific latitudes and longitudes);\nand it must be able to make large numbers of these measurements in a reasonable amount of time.\n\n\nSingle beams echosounders fall short in both areas.\n\n\nEcho Location Questions – Where is the Bottom?\n\nEcho sounder is to measure the range to the ocean floor accurately.\nIn a bathymetric survey, a sonar is most useful if it measures the range to a specific location on the bottom, ideally at a point directly below the vessel doing the survey.\nUsing the single-beam echo sounder you might assume that the time of the first echo from a ping determines the range to the bottom directly below the survey vessel.\n\nSometime that is the case and the earliest echo is from directly below the sonar, because that is where the ping first encounters the bottom. For example for ideal, flat bottoms.\n\n\nHowever…\n\n\n\n\n\n\n\nFigure from Multibeam Sonar Theory of Operation\n\nIn this case, a bottom feature behind the vessel is closer to the sonar than the bottom directly below.\nPings from the single-beam echo sounder, which spread out spherically from the sonar, equally in all directions, strike the bottom first at this point\nOperators on the survey vessel do not know that the first return echo is not from the bottom directly below\nWe can partially deal with this problem introducing some directivity\nIn this case, the bulk of the acoustic energy in the ping is focused within a narrow solid angle (beam)\nThe ping ensonifies only a small patch of the bottom, and the first returned echo can be assumed to come from this area\n\n\n\n\n\n\n\n\n\nSingle beam: further problems\n\nUnstabilised beams: the hull of the ship (and hence the sonar) moves with waves. The magnitude of this problem depends on the severity of the weather, but it can be quite large. Roll and pitch angles of tens of degrees in moderately heavy seas are not uncommon in the open ocean.\nBeams are made narrower by making the transducer face larger.\n\nFor example, a circular 12 kHz transducer with a 30°beam width has a diameter of roughly 25 cm, but requires a diameter of roughly 295 cm for a 2.5°beam.\nThe larger the transducer the higher the cost to manufacture.\n\n\n\n# Using the relationship we saw for an array (delta_theta = lambda/L)\ndelta_theta = (1500/12000)/(30*3.14/180) # 30deg\nprint(delta_theta)\n\n0.23885350318471338\n\n\n\n# Using the relationship we saw for an array (delta_theta = lambda/L)\n(1500/12000)/(2.5*3.14/180) # 2.5deg\n\n2.8662420382165603\n\n\n\n\nA further comment\n\nThe solid angle size of the beam determines how accurately a narrow beam sonar can determine the location of depths on the bottom.\nAn observer recording an echo from such a sonar can determine only that the bottom is located somewhere within that angle at the computed range.\nThe size of the beam solid angle determines the resolution of a sonar.\nThe term resolution may apply to the angle itself, or to the physical size of the area on the bottom the beam ensonifies.\nWhen resolution applies to the size of the ensonified area, it is not fixed and it depends on depth.\nThe deeper a ping goes, the larger an area its fixed solid angle will intersect.\nThe area of the ensonified bottom is proportional to the beam solid angle and to the square of the depth.\n\n\n\n\n\n\n\n\n\n\n\nSurvey Speed\n\nWith single beam echosounder nautical charts very highly approximated using sparse measurements: extremely high errors\n\ninappropriate instrument for large-scale bathymetric survey work\n\nWith multi-beam echosounders this problem is reduced: we measure a swathe of seabed. Interpolation is still needed by we have much more measurements (typically less than 1m)\nHighly accurate and deep coverage of the sea bed\nMultibeams are only available since 1990s\n\n\n\n\n\n\n\n\n\n\n\n\n\nGPS is also available since the 1990s (accuracy of a few meters).\nBefore we used radio beacons, which at sea had a 100m accuracy.\nBefore Multibeams and GPS we had the uncertainty of the interpolatin and of the navigation\nMore in general multibeams require knowledge of sound speed profile and ship motion (roll, pitch and heave)\nCan be installed on ship or smaller versions are available for ROV/AUVs/UxVs",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#mbes-operating-principle",
    "href": "sonar_practical_applications.html#mbes-operating-principle",
    "title": "SONAR Practical Applications",
    "section": "MBES, Operating Principle",
    "text": "MBES, Operating Principle\n\nThe Mills Cross Technique\n\nRemember that given an array, the true beam pattern can be seen by rotating the figure about the axis of the line array\n\n\n\n\n\n\n\n\n\nA projector line array transmits sound preferentially in all directions perpendicular to the axis of the array, ensonifying a strip of the ocean bottom\n\n\n\n\n\n\n\n\n\nA hydrophone array aligned parallel to the projector array receives echoes from all locations along a similar strip of the ocean floor.\nIf you want to accurately locate echoes on the ocean floor, this is not very useful.\nThe projector array will cause echoes all along the ensonified strip, and the hydrophone array will pick up echoes from a similar strip.\nThere will be no way of telling where the echoes are occurring along these strips\nIf the projector and hydrophone arrays are perpendicular to each other, the strip of the ocean floor ensonified by the projectors will intersect with the strip of the ocean floor observed by the hydrophones\nThis occurs in only a small area with dimensions that correspond approximately to the projector and hydrophone array beamwidths\nEchoes occur along the entire ensonified area,\nSound may be received from the entire observed area,\nHowever only a small part of the bottom is both ensonified by the projector array and observed by the hydrophone array beam, i.e., where the two strips overlap.\nThis is called, Mills Cross arrangement (named after a pioneering radio astronomy instrument built in New South Wales, Australia)\n\n\n\n\n\n\n\n\n\nWe can now leverage beamforming\nBeam steering can be used to observe echoes generated from multiple angles with the hydrophone array\nDifferent angles observe parallel strips of the bottom, which will intersect with the ensonified area in a series of small patches\nMultiple steered beams can be used to receive the echoes from discrete locations all along the ensonified area, allowing the sonar to determine ranges to a strip of locations with each ping.\n\n\n\n\n\n\n\n\n\n\nSince we know the beam steering angle\nFor each patch we measure the two way travel time\nWe calculate the depth of the sea bed from the sea surface\n\nComments: - With a Multibeam, sound speed plays a bigger role than with the single beam echosounder (where we only go straight) - When we transmit with a slant angle, if the sound speep profile is not constant with depth (and it is not), we have refraction\n\n\n\n\n\n\n\n\n\nIt is important to know the sound speed profile and keep into account how rays might bend (e.g., impact on footprint on the seabed)\nThis is important in MBES and not in single beam echosounder (where we are insterested only in the ship-to-bottom straight path)\n\n\n\nMBES and backscattering\n\nWorks measuring the backscatter\nWavelength must be comparable to the bottom roughness\nSince we want to measure bathymetry everywhere, even when it is centimeters\nFrequency needs to be high enough\n\nIf bottom roughness is \\(\\sigma = 10cm\\), then wavelength should be \\(\\lambda\\approx10cm\\)\n\\[\\lambda = \\frac{c}{f} = \\frac{1500}{f} \\Rightarrow 0.1 = \\frac{1500}{f} \\]\n\\[ f = \\frac{1500}{0.1} = 15kHz \\]\n\n\\(\\sigma\\) can be easily smaller than \\(10cm\\) (e.g., clay) and MBES frequencies can often go &gt;100kHz\nLimits to their range\nDecreasing frequency to increase range MBES constraint their maximum resolution\nRemember that \\(\\Delta \\theta\\) (amplitude of the beam) depends on the frequency and we have a larger patch on the seabed (and the resolution decreases accordingly)\n\n\n\n\n\n\n\n\n\n\nSome MBES can use multiple frequencies simultaneously.\nAll the previous limitations still hold, using multiple frequencies can reduce the amount of noise encountered.\nRather than not having some (high frequency) depths, these data points can be filled in using lower frequency data (although with a larger footprint and thus showing less detail).\nThe final data density is defined by the number of beams (depths) and the ping rate, or the number of swathes that the MBES can measure per second.\nThe ping rate depends on the water depth, and can be as high as 60 pings per second in shallow water.\n\n\n\nWater Column Data\n\nA traditional MBES measures a single depth per beam per ping.\nIn general, the ‘first depth strong enough to be detected’ will result in the depth displayed.\nLess strong depths that may be closer to the multibeam are not detected.\nAlso, a strong reflector close to the transducer may give a depth rather than the weaker bottom below it.\nModern MBES systems reads water column data.\nThe water column of each beam is divided into a number of ‘bins’.\nThe MBES now looks for a return within each bin for each beam for each ping.\nMBES to measure multiple reflections and thus create 3D images of objects in the water column (or to see the bottom through, for example, vegetation).\nMany beams, multi-frequency and a high ping rate make the amount of data gathered enormous.\nTime spent processing is not negligible\n\n\n\n\n\n\n\n\n\n\n\nTransmitted signals\n\nWhere in the past the transmitted signal was a ‘continuous wave’ (CW),\nToday MBES often also transmit what is called an FM or CHIRP (Compressed High Intensity Radar Pulse) signal. - Main advantage of the CHIRP is a longer range with better range resolution.\nFor a CW type MBES, the range resolution is defined by the pulse length of the signal,\nFor a CHIRP type MBES the range resolution is defined by the bandwidth of the signal,\nThis makes it possible to transmit longer pulses and therefore to have more power in water.\n\n\n\nMovement of source and receiver\n\nMovement is always present\nMBES has always an angle (roll, pitch and heave in particular) with respect to the sea surface\nMeasure movement of the ship and use it during the calculation of the depth\nMBES are complex and cost much more than single beam echosounder (1k-1M USD)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourtesy of Ocean Exploration Trust/ Nautilus Live.",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#mbes-on-a-robot",
    "href": "sonar_practical_applications.html#mbes-on-a-robot",
    "title": "SONAR Practical Applications",
    "section": "MBES on a Robot",
    "text": "MBES on a Robot\n\n\n\n\n\n\n\n\n\nSmall size, high frequency systems can be installed on AUVs\nNavigating close to the seabed, high resolution bathymetry can be obtained also in deep water\n\n\n\n\n\n\n\n\n\n\nSome examples\n\nWhittard Canyon\n\n\n\n\n\n\n\nCourtesy of The National Oceanography Centre, CODEMAP project.\n\n\n\n\n\n\n\nPianosa, Archaeological site\n\n30m Depth\nSurvey from a ship\nReason MBES 445 kHz\nColors are due to image processing only (e.g., shadows are artefacts from the Graphical Rendering)\nTop-Left part of the area is Posidonia (30m is the typical growth limit)\n\nPosidonia produces high scattering through its length, and this implies that measured time is more uncertain (see zommed area)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure: A multibeam-sonar image of the underwater archaeological site near the island of Pianosa, off the west coast of Italy. The site contains approximately 100 amphorae of different origins and epochs",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#side-scan-sonars",
    "href": "sonar_practical_applications.html#side-scan-sonars",
    "title": "SONAR Practical Applications",
    "section": "Side-Scan Sonars",
    "text": "Side-Scan Sonars\n\nSidescan sonars are primarily designed to provide “acoustic images” of the seafloor, with high resolution\nA sidescan sonar system consists of a recording device, an underwater sensor (a towfish with a transducer on the port and starboard side, respectively), and a tow cable to connect the two\nSide-scan sonar does not (with the exception of interferometrics) have the capacity to incorporate information about the bottom topography,\nIf the bottom is not flat it requires additional bathymetric data on which to base processing corrections.\nWithout taking these factors into account, the intensity of the backscatter return is significantly affected by bathymetric variation, to the point that it is of limited usefulness for quantitative analysis.\nTraditional analysis of SSS is primarily image-based, using the constructed sonograph for visual interpretation.\nRecords the backscatter signal from the bottom\nLeverage Tx beamforming\n\nWide beam on the across track direction\nNarrow beam on the along track direction\n\nMeasures the return signal\n\nProportional (there is propagation loss) to the backscatter intensity\nReturn signals have a temporal sequencing (first return from the closest point of the bottom, etc.)\n\nFor each Tx we have a return signal as a function of time and with an intensity that is proportional to the received intensity\n\nPixel color is correlated to the backscatter amplitude (e.g., black no signal, white high backscatter, etc)\nPixel are aligned on a strip\nAligning strips form an image of the bottom\n\nFrequency of operations: 100-700 kHz (typically between 300-400 kHz)\n\n100 kHz: low resolution\n700 kHz: high resolution\n\nFor this reason, side scans where towed systems rather than being installed on the ship’s keel\n\nNeed to have the system close to the bottom\n\n\n\n\n\n\n\n\n\n\n\n\nTwo transmit/receive arrays positioned on the side of the body of the tow fish (side scan)\n\n\nSide scan parameters and beam pattern\n\n\n\n\n\n\n\n\n\n\n\n\nSidelobes look behind the main transmit direction\nRange: The maximum distance from the transducers that the SONAR signal can detect usable signals.\nSlant range: The straight-line distance from the tow fish to an object at any given location\nRange delay: The distance (or range) that the sonar device is told to wait after pinging before it starts recording acoustic returns. The most common use for range delay is to not record the water column – i.e. the time for the ping to reach the seafloor in a straight line (first return)\n\n\n\nMain beam\n\n\n\n\n\n\n\n\nThe main signal moves within the angles of the main beam (remember the 3dB rule we used)\nNote the shadow part after the object: waves do not progate through it and no backscatter signals are received for a while\n\n\n\nSide Scan Sonars on an AUV\n\n\n\n\n\n\n\n\n\nNeed for careful attitude of the vehicle\nAttitude compensation possible to correct data",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#side-scan-sonar-imagery",
    "href": "sonar_practical_applications.html#side-scan-sonar-imagery",
    "title": "SONAR Practical Applications",
    "section": "Side Scan Sonar Imagery",
    "text": "Side Scan Sonar Imagery\n\n\n\n\n\n\n\n\n\nside lobes might pick up bottom and surface returns\npresence of fish (in the middle of the water column) generates volume scattering. Returns might come in-between bottom returns. Generate shadows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat are we looking at?\n\n\n\n\n\n\n\n\n\nWaterfall: A term used to describe a display that puts the newest data at the top and scrolls the data down like a waterfall\nWater column: The water length between the sensor and the seafloor.\nSwath: The total side-to-side coverage of the SONAR signal on each sweep of the seabed\nNadir: no return area from the water column\nNote the transmit signal as first few pings of the image (strong yellow intensity at the centre), which is also received\n\n\n\n\n\n\n\n\n\nA more complex example\n\n\n\n\n\n\n\n\nFigure: Courtesy of Hydroid, 2010\n\nSurface and bottom returns might be due to sidelobes\n\nThey tend do be constantly present in the image\n\nHigh backscatter lines (close to nadir) due to surface and bottom returns (left and right).\n\nThe difference in intensity between left and right channel might indicate that there is a left-right slope (we are farther away from the bottom) or a rolled vehicle.\nSurface or bottom returns (their order) depend on which one is the closest\n\nNote the presence of fish (volume scattering)\n\nshadows make it possible to say that it is fish\n\n\nGiven the specific geometric mounting of the sidescan sonar - We do not see very well right below the sonar - Shadows are compressed and small - And far away from it - Shadows of objects at the edge are cut off - Ideal range is mid-range\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImpact of object location in the sonar range\n\nSome object in two different side scan areas\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNear Nadir: high backscatter, short shadow\n\n\nSweet Area: high backscatter, longer shadow\n\n\n\n\nLooking at the sweet area is easier to see: a cylindrical weight, a cable and something attached to it.\n\n\n\n\n\n\n\n\n\n\n\nFlat sand bottom and Flat mud bottom\n\n\n\n\n\n\n\n\n\n\n\n\nNote: - difference in texture between the two types of bottom - color change in the right image. This is due to change of gain of the received signal (no natural surface would produce this change in reflectivity)\n\n\nLarge and small sand ridges\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYellow lines are due to acoustic interference from another device",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#objects",
    "href": "sonar_practical_applications.html#objects",
    "title": "SONAR Practical Applications",
    "section": "Objects",
    "text": "Objects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTop image: Bottom object, sweet area (note how clearly is visible and how regular it is - possibly manmade)\nMiddle image: Bottom object, near nadir (limited shadow - difficult to detect)\nBottom image: Object with clear shadows: weight, cable and buoy\n\nSomething that reflets in the water column (visible in the nadir region)\nNote the long shadow. This is a buoy with a cable (which also produces backscatter)\n\n\n\nVehicle turns\n\n\n\n\n\n\n\n\n\nvehicle turns means rolling, and returns from the bottom are not straight anymore.\n\n\n\nMan made debries near rocks and kelps\n\n\n\n\n\n\n\n\n\n\n\n\n\nMuddy bottom with rocks\nObjects in the water column with long shadows: kelp\nMan made debries also present",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#advanced-systems",
    "href": "sonar_practical_applications.html#advanced-systems",
    "title": "SONAR Practical Applications",
    "section": "Advanced Systems",
    "text": "Advanced Systems\n\nWe can combine SSS and multibeam (e.g, install on the same vehicle)\nCareful with frequency choice or through time division (mission scheduling)\nSome SSS can operate at multiple frequencies\n\nLower frequency (longer range) is used for identification: “I saw something”\nHigher frequency (shorter range) is used for classification: “I know what it is”\nTypically done through two different mission phases\n\nInterferometric SSS\n\nUse not one, but two RX arrays per side are used to measure the phase difference of the received signal and determine the bathymetry.\nOnly one TX ping.\nGeometry of the receivers well known (e.g., location on the vehicle).\n\n\n\nSynthetic Aperture Sonar (SAS)\n\nNewer development (10-15Y)\nSimple concept but difficult to engineer\nThe same point is ensonified by a number of different pings from different locations\nIdentifing the time of arrivals of each point\n\n\n\n\n\n\n\n\n\n\n\n\n\nBackscatter from a single ping, at time \\(t_1\\): \\[\nb_{1} = b_{true} + n_1\n\\]\nHaving multiple pings: \\[\nb_{HD} = b_{1} + b_{2} + b_{3}\n\\]\nSince the point is the same,\n\\[\nb_{HD} = 3b_{true} + n_1 + n_2 + n_3\n\\]\nif the noise has zero mean, we have a gain in the true backscatter value and a decrease (we are averaging) of the noise associated to different ping.\nThe identification of the reception times (\\(t_1\\), \\(t_2\\), \\(t_3\\)) is critical. If I use wrong times, I am summing up backscatters from different points of the bottom and results are wrong.\nThe association of time to spatial coordinates is difficult and depends on the vehicle navigation. In this case the relative navigation across the pings is important and we often talk of micronavigation.\nOnly a minor numer of systems are able to do it (e.g., Kongsberg).\nCalled Synthetic Aperture, because it is equivalent to build an antenna of sidescan sonars (receivers)\nTerminology - Length of antenna: aperture - Length of array of sidescans is synthetic because it is built through digital processing\n\n\n\n\n\n\n\n\n\n\n\n\n\nSSS 384kHz (left) and SAS 300 kHz (middle)\n\n\n\n\n\n\n\n\nInverted colorscale for left SSS image: shadows are white\nSSS is high frequency of SAS but has lower resolution\nRoman Dolias\nOff the coast of Isola d’Elba\n60m depth",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#sonars-and-navigation",
    "href": "sonar_practical_applications.html#sonars-and-navigation",
    "title": "SONAR Practical Applications",
    "section": "Sonars and Navigation",
    "text": "Sonars and Navigation\n\nSide Scan Sonar is often payload for Self Localisation and Mapping (SLAM)\nMulti-beam is often payload for Terrain-based navigation and can be useful for SLAM as well.",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#terrain-aided-navigation",
    "href": "sonar_practical_applications.html#terrain-aided-navigation",
    "title": "SONAR Practical Applications",
    "section": "Terrain-aided Navigation",
    "text": "Terrain-aided Navigation\n\n\n\n\n\n\n\n\n\nDYNOPO Cruise, NOC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSalavasidis et al, “Terrain‐aided navigation for long‐range AUVs in dynamic under‐mapped environments”, Journal of Field Robotics",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#sub-bottom-profilers",
    "href": "sonar_practical_applications.html#sub-bottom-profilers",
    "title": "SONAR Practical Applications",
    "section": "Sub-bottom profilers",
    "text": "Sub-bottom profilers\n\nSo far we have focused on exploring the surface of the bottom\nOften we would like to understand what is behing the surface (e.g., oil and gas exploration)\nTo produce maps not only of the surface of the bottom but also of the layers underneath we use sub-bottom profilers\nSimilar to echosounders (ping right below) but at lower frequencies\nTypical frequency: 1kHz-7kHz (most often 3.5kHz)\nNormal incident reflections from seabed and substrata\nFrequencies are low enough that some of the energy is transmitted through the seabed\n\nWe receive as many pulses back as the number of interfaces (change in the medium)\n\nThis is when some energy is reflected back to the receiver\n\n\nColoring pixels based on the backscattering strength of received pulses we obtain layering maps similar to what is shown below\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSediments are soft and we have lower reflections\nHard bottoms have higher reflections\nLow frequency and hence low resolution\n\nFigure: from www.geoviewing.com and Lurton 2002",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#ocean-bottom-seismometers-obs",
    "href": "sonar_practical_applications.html#ocean-bottom-seismometers-obs",
    "title": "SONAR Practical Applications",
    "section": "Ocean bottom seismometers (OBS)",
    "text": "Ocean bottom seismometers (OBS)\n\nWhen OBS sensors are deployed on the sea bottom and locked on the bottom, it is possible to investigate the structure of the bottom in more details\nThis makes it possible to read S-Waves as well as P-Waves and to obtain directionality\nRefractions arrive at the different sensors in different ways\n\nIs the equivalent of seismic tomography\nNot acoustics but seismic because it uses elastic waves.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure: from geology.gsapubs.org and seismo.berkeley.edu\n\nDeploying OBS is complex, they need to lock to the bottom\nUsage of robots attempted for:\n\nDeploying sensors\nDirectly use the robots as OBS\nDepending on the type of bottom robots might struggle to leave the bottom to come back",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#seismic-exploration",
    "href": "sonar_practical_applications.html#seismic-exploration",
    "title": "SONAR Practical Applications",
    "section": "Seismic exploration",
    "text": "Seismic exploration\n\nSeismic reflection\nMore deep than sub-bottom profilers, less deep than OBS\nPerform a seismic tomography but using linear arrays\nThis makes it possible to read P-Waves only (loss of directionality)\n\n\n\n\n\n\n\n\n\nSources with frequency &lt; 200Hz\nLarge aperture arrays &gt; 1km\nWavelength is long so large apertures are needed (\\(\\Delta\\theta = \\frac{\\lambda}{L}\\))",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#seismic-sources",
    "href": "sonar_practical_applications.html#seismic-sources",
    "title": "SONAR Practical Applications",
    "section": "Seismic Sources",
    "text": "Seismic Sources\n\nExplosives (TNT): 10Hz-1kHz\nAir-guns: &lt; 100Hz\nAir-guns array: &lt; 100Hz\nWater-guns: 50Hz-1kHz\nSparkers: 100Hz-3kHz\nSource Levels are very high, and given that they have low frequency, signals are mostly geometrically attenuated and propagate for extremely long ranges.\nAcoustic and environmental assessments are mandatory to avoid affecting marine life (e.g., marine mammals)\n\nSonar equations are used for this, together with tables that codify marine mammals pain levels, etc.",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#receiving-arrays",
    "href": "sonar_practical_applications.html#receiving-arrays",
    "title": "SONAR Practical Applications",
    "section": "Receiving Arrays",
    "text": "Receiving Arrays\n\n\n\n\n\n\n\n\nElectronics and hydrophones are immersed in oil to balance pressure",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "sonar_practical_applications.html#air-guns",
    "href": "sonar_practical_applications.html#air-guns",
    "title": "SONAR Practical Applications",
    "section": "Air-Guns",
    "text": "Air-Guns\n\n\n\n\n\n\n\n\nLarge and complex systems, large ships needed to deploy\nTx signals: sequence of signals (Figure Airgun Waveform, dashed line) that have multiple peaks\n\nSignals might not be simple to signal process (due to multiple peaks)\nWe would like to have a delta function\n\nArrays of airguns can be used to coordinate their firing and attenuate the problem above\n\nFirst peak is obtained as constructive interference of the signals\nOther peaks are obtained as destructive interference and hence attenuated\nSee Figure Airgun Waveform, blue line and the blue line in the Airgun Spectrum where the low frequency spectrum is much cleaner (no resonant frequencies)",
    "crumbs": [
      "SONAR Practical Applications"
    ]
  },
  {
    "objectID": "ros.html",
    "href": "ros.html",
    "title": "Robot Operating System (ROS)",
    "section": "",
    "text": "Adapted from Adam Buynak.9, The Ohio State University\nFoundational aspects:",
    "crumbs": [
      "Robot Operating System (ROS)"
    ]
  },
  {
    "objectID": "ros.html#introduction-to-ros",
    "href": "ros.html#introduction-to-ros",
    "title": "Robot Operating System (ROS)",
    "section": "Introduction to ROS",
    "text": "Introduction to ROS\n\nA Standard Framework for Robotics Software\nThe Robot Operating System is a flexible framework for developing robotic systems. This framework comes with a wide variety of tools, libraries, and conventions to simplify the process of creating complex, robust robotic behavior. – ros.org\nPrevious Practices: - Slow growth restricted by need to regularly recreate technologies into a custom solution for each robot - Every hardware solution was custom designed - Every software solution was rewritten from scratch to match - Very little code ‘carried forward’ into future projects\n\n\n\n\n\n\n\nSlide from 2006 Proposal Pitch Deck at Stanford to begin developing a standard robotics framework. Credit: Keenan Wyrobeck & Eric Berger.",
    "crumbs": [
      "Robot Operating System (ROS)"
    ]
  },
  {
    "objectID": "ros.html#building-any-mechatronic-robotic-system-is-hard.-plain-and-simple.",
    "href": "ros.html#building-any-mechatronic-robotic-system-is-hard.-plain-and-simple.",
    "title": "Robot Operating System (ROS)",
    "section": "Building any mechatronic / robotic system is hard. Plain and simple.",
    "text": "Building any mechatronic / robotic system is hard. Plain and simple.\nTesla builds self-driving cars with two mechanical outputs: 1 – the powertrain motor driving the wheels 2 – the direction of the front wheels (turning left/right)\nThey invest billions of dollars each year optimizing… - computer vision - environment input sensors - control systems - user interface - self-driving algorithms - motor control\n\nTesla: USD 2,984 on R&D per car\nIndustry Average: USD 1000 on R&D per car\nTesla’s self-driving car is a robot\nAutomotive engineers have the convenience of a standard, 4-wheeled vehicle to implement code.\nRobots come in many different forms, motor types, control schemas, etc.\nEach subsystem requires development time.\n\nThis could be… - various mechanical joints (revolute, prismatic, etc) - integrating multiple OEMs - smaller/larger, weaker/stronger, slower/faster\n\nROS fundamentally enables collaboration of novices and experts to rapidly develop complex systems.",
    "crumbs": [
      "Robot Operating System (ROS)"
    ]
  },
  {
    "objectID": "ros.html#a-typical-mobile-robot-software-stack",
    "href": "ros.html#a-typical-mobile-robot-software-stack",
    "title": "Robot Operating System (ROS)",
    "section": "A Typical Mobile Robot Software Stack",
    "text": "A Typical Mobile Robot Software Stack\n\n\n\n\n\n\n\n\nDon’t rebuild the wheel.\nLeverage the existing capabilities in ROS.\nFocus your time on new features.\nContribute new developments to the ROS community.",
    "crumbs": [
      "Robot Operating System (ROS)"
    ]
  },
  {
    "objectID": "ros.html#nodes-topics-and-messages",
    "href": "ros.html#nodes-topics-and-messages",
    "title": "Robot Operating System (ROS)",
    "section": "Nodes, Topics and Messages",
    "text": "Nodes, Topics and Messages\n\nNodes\n\n\n\n\n\n\n\n\n\nTopics\n\n\n\n\n\n\n\n\n\nMessages\n\n\n\n\n\n\n\n\n\nServices",
    "crumbs": [
      "Robot Operating System (ROS)"
    ]
  },
  {
    "objectID": "ros.html#message-formats",
    "href": "ros.html#message-formats",
    "title": "Robot Operating System (ROS)",
    "section": "Message Formats",
    "text": "Message Formats\n\n\n\n\n\n\n\nList shown is non-comprehensive!\n\nStandard Messages\n\n\n\n\n\n\n\nList shown is non-comprehensive!",
    "crumbs": [
      "Robot Operating System (ROS)"
    ]
  },
  {
    "objectID": "ros.html#communication-interfaces",
    "href": "ros.html#communication-interfaces",
    "title": "Robot Operating System (ROS)",
    "section": "Communication Interfaces",
    "text": "Communication Interfaces\nROS nodes may communication using three methods: - Topics, Services, Actions",
    "crumbs": [
      "Robot Operating System (ROS)"
    ]
  },
  {
    "objectID": "the_acoustic_channel.html",
    "href": "the_acoustic_channel.html",
    "title": "The Acoustic Channel",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport copy",
    "crumbs": [
      "The Acoustic Channel"
    ]
  },
  {
    "objectID": "the_acoustic_channel.html#absorption-or-intrinsic-attenuation",
    "href": "the_acoustic_channel.html#absorption-or-intrinsic-attenuation",
    "title": "The Acoustic Channel",
    "section": "Absorption or Intrinsic Attenuation",
    "text": "Absorption or Intrinsic Attenuation\n\n\n\n\n\n\n\n\nFrom Springer Handbook of Acoustics\n\n\n\nPhasor form of the intrinsic attenuation: \\[\nA = A_oe^{-\\alpha x}\n\\]\n\nAttenuation depends on frequency\n\n\\(1\\) Hz signal, is attenuated by approx \\(0.001\\) per km (1 dB attenuation after 1000km, equator is 40K km)\n\\(1\\) kHz signal, is attenuated by approx \\(1\\) dB per km\n\\(100\\) kHz signal, is attenuated by \\(100\\) dB after \\(1\\) km\nLow frequencies are not intrinsically attenuated very much (geometric attenuation counts more)\nHigh frequencies are highly intrinsically attenuated (counts much more than geometric attenuation)\nLow frequency signals (which have low bitrate or low resolution) can propagate very far\nHigh frequency signals (which have higher bitrate or high resolution) can propagate only for small distances.\n\nPointwise linear: at different frequencies different mechanisms affect attenuation\n\ne.g., heat produced by friction between water particles and hence energy is transformed into heat",
    "crumbs": [
      "The Acoustic Channel"
    ]
  },
  {
    "objectID": "the_acoustic_channel.html#phasor-notation-for-absorption",
    "href": "the_acoustic_channel.html#phasor-notation-for-absorption",
    "title": "The Acoustic Channel",
    "section": "Phasor Notation for absorption",
    "text": "Phasor Notation for absorption\n\nUsed in scientific papers (e.g., considering a complex sound speed)\nIncluding an imaginary term in the sound speed makes it possible to mathematically model the intrinsic attenuation\nPressure (at fixed angular frequency \\(\\omega\\)) including perturbation and attenuation:\n\n\\[\np(x) = Ae^{ikx}e^{-\\alpha x} = Ae^{ikx(1+i\\delta)}\n\\]\nwhere \\(\\delta = \\frac{\\alpha}{k} = \\frac{\\alpha c}{\\omega}\\)\n\nRemember that \\(k=\\frac{\\omega}{c}\\)\nIf we consider no attenuation:\n\n\\[\np(x) = Ae^{ikx}\n\\]\n\nif \\(c = c_r - ic_i\\): sound speed is composed of a real term (the actual sound speed) and of an imaginary term\n\n\\[\n\\Large p(x) = Ae^{i\\omega x \\frac{c_r + ic_i}{c_r^2+c_i^2}} \\approx Ae^{ikx}e^{-\\frac{\\omega x}{c_r^2}c_i}\n\\]\nwhere \\(c_i=\\frac{\\alpha}{\\omega}c_r^2\\)\n\nUsing a complex sound speed we have recovered the generic form of the pressure which included the attenuation (see equation above)\nPhasor notation makes it possible to model the intrinsic attenuation, adding an imaginary term (which depends on the intrinsic attenuation) to the speed of sound.",
    "crumbs": [
      "The Acoustic Channel"
    ]
  },
  {
    "objectID": "the_acoustic_channel.html#geometrical-spreading",
    "href": "the_acoustic_channel.html#geometrical-spreading",
    "title": "The Acoustic Channel",
    "section": "Geometrical Spreading",
    "text": "Geometrical Spreading\n\n\n\n\n\n\n\n\nFrom Computational Ocean Acoustics\n\n\n\n\nGeometrical spreading is an additional source of attenuation\nNote that when we have multiple sources of attenutation and they are represented in dB, we cannot sum them in dB and need to be converted back to a linear scale (and then back to dB)\n\nTypically one of the mechanism is much higher and we can safely consider that\nGeometrical attenuation is prevalent in low frequency regimes\nIntrinsic attenuation is prevalent in high frequency regimes",
    "crumbs": [
      "The Acoustic Channel"
    ]
  },
  {
    "objectID": "the_acoustic_channel.html#combined-spreading-loss-geometric-absorption",
    "href": "the_acoustic_channel.html#combined-spreading-loss-geometric-absorption",
    "title": "The Acoustic Channel",
    "section": "Combined Spreading Loss: Geometric + Absorption",
    "text": "Combined Spreading Loss: Geometric + Absorption\n\nSound will propagate spherically near the source. At some range H, the spherical wave hits the sea floor, from here on, sound propagates cylindrically.\n\n\n\n\n\n\n\n\n\nFrom Jasco Underwater Acoustics: Noise and the Effects on Marine Mammals Pocket Handbook.\n\n\n\n\n\\(RL\\), Received Level\nCylindrical attenuation: \\(RL\\) decreases \\(10\\)dB/decade\nSpherical attenuation: \\(RL\\) decreases \\(20\\)dB/decade\nCombined curve: starts spherical and then goes cylindrical (e.g., shallow waters)\nAt \\(100\\) kHz: \\(&gt;40\\) m, intrinsic attenuation starts to prevail\nAt \\(10\\) kHz: \\(&gt;40\\) m, intrinsic attenuation starts to prevail",
    "crumbs": [
      "The Acoustic Channel"
    ]
  },
  {
    "objectID": "the_acoustic_channel.html#additional-loss-factors-interference",
    "href": "the_acoustic_channel.html#additional-loss-factors-interference",
    "title": "The Acoustic Channel",
    "section": "Additional Loss Factors: Interference",
    "text": "Additional Loss Factors: Interference\n\nMost sources of interest in the deep ocean are closer to the surface than to the bottom\nIn this case, the direct path and the surface reflected path are the two main short-range paths\nWhen these two paths interfere, they produce a spatial distribution of sound often referred to as a Lloyd mirror pattern\nThis loss depends on the geometry between source and received\nDoes not depend on the property of the medium\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource (and Receivers) are close to the surface\nSource is a point source placed near a smooth, perfectly reflecting sea surface\nDistance between Source and Receiver is much larger than the distance between Source and sea surface\nIsotropic medium (sound speed is the same in every direction)\nWhat is the pressure \\(p(r,z)\\) at the receiver’s location when the source at depth \\(z_s\\) transmits an harmonic signal \\(e^{i\\omega t}\\) (i.e., \\(\\omega\\) is known) with outward propagating spherical waves (\\(e^{-ikr}\\))?\n\nLet’s follow each path (we suppress the time dependence \\(e^{-i\\omega t}\\) for simplicity).\n\nDirect: \\[\nR_1 = \\sqrt{r^2 + (z_r-z_s)^2}\n\\]\n\n\\[\np_1(r,z) = \\frac{e^{ikR_1}}{R_1}\n\\]\n\nNote that this is spherical spreading (we are describing pressures not intensities, which are the square of the pressure)\nReflected path:\n\nWe can imagine that is a straight path from the source specular reflection (\\(-z_s\\)) around the ocean surface to the receiver\n\n\n\\[\nR_2 = \\sqrt{r^2 + (z_r+z_s)^2}\n\\]\n\\[\np_2(r,z) = -\\frac{e^{ikR_2}}{R_2}\n\\]\n\nSince pressures are additive:\n\n\\[\np(r,z) = p_1(r,z) + p_2(r,z) = \\frac{e^{ikR_1}}{R_1} -\\frac{e^{ikR_2}}{R_2}\n\\]\n\nNote that the wavefront \\(p_2\\) changes phase (180 deg) when it is reflected off the sea surface to satisfy the pressure-release boundary condition (\\(p = 0\\)) at the sea surface.\nLet’s call \\(R\\) the distance between the 0 depth point along the source-ocean line (origin) and the receiver\nLet’s consider the angle \\(\\phi\\) between \\(R\\) and the \\(x\\)-axis\n\n\n\n\n\n\n\n\n\n\n\n\nThe previous equation is a complex interference pattern.\nWe can simplify it, assuming \\(R &gt;&gt; z_s\\):\n\\[\nR_1 \\approx R-z_s\\sin(\\phi)\n\\]\n\\[\nR_2\\approx R+z_s\\sin(\\phi)\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\\[\np(r,z) \\approx \\frac{1}{R} \\Big [ e^{ik(R-z_s\\sin(\\phi))} -  e^{ik(R+z_s\\sin(\\phi)) } \\Big ] =\n\\frac{e^{ikR}}{R} \\Big [ e^{-ik(z_s\\sin(\\phi))} -  e^{ik(z_s\\sin(\\phi))} \\Big ]\n\\]\nWe next replace the two exponentials by a trigonometric function to obtain:\n\\[\np(r,z) = \\frac{-2i}{R}sin(kz_s \\sin(\\phi))e^{ikR}\n\\]\nwhich means that the amplitude variation takes the simple form:\n\\[\n|p| = \\frac{2}{R}|sin(kz_s\\sin(\\phi))|\n\\]\nand the maximum:\n\\[\n|p_{max}| = \\frac{2}{R}\\;\\; \\text{for}\\;\\;\\sin(\\phi)=(2m-1)\\frac{\\pi}{2}\\frac{1}{kz_s}\\;\\; m=1,2,...M\n\\]\n\nNote that when \\(\\sin(\\phi)=(2m-1)\\frac{\\pi}{2}\\frac{1}{kz_s}\\), then \\(\\sin(kz_s\\sin(\\phi))\\) is a multiple of \\(\\pi/2\\) and hence a maximum.\nSince, \\(\\sin(\\phi)=(2m-1)\\frac{\\pi}{2kz_s}\\) and \\(\\sin(\\phi)\\in [-1, 1 ]\\) (or we would have a complex number and we are only interested in real numbers), this limits the maximum \\(m\\) and hence the number of Lloyd-mirror beams \\(M\\) is finite and can be obtained from:\n\n\\[\n(2M-1)\\frac{\\pi}{2kz_s} \\le 1 \\Rightarrow M= \\Big \\lfloor \\frac{2z_s}{\\lambda}+\\frac{1}{2} \\Big \\rfloor\n\\]\nwhere \\(\\lambda\\) is the acoustic wavelength.\n\nThe number \\(M\\) tells us what are the directions \\(\\phi\\) where we have a maximum (see Depth-Range Contour Figure below). In effect, we are calculating for which values of \\(\\phi\\) the harmonic waves are arriving in phase or in opposition of phase.\nthe number of beams is directly protional to the distance of the source from the surface in terms of wavelengths.\n\nIn underwater acoustics, the dependence of sound pressure on distance at a fixed depth \\(z_r\\) is of great importance.\nWhen \\(r&gt;&gt;z_r\\):\n\nSubstituting \\(\\sin(\\phi) = z_r/R\\) in $ |p| = |sin(kz_s())| $ and considering large ranges (\\(r &gt;&gt; z_r;\\;\\; \\sin(\\phi) \\approx \\phi)\\); \\(r \\approx R\\)) we obtain:\n\n\\[\n|p| \\approx \\frac{2kz_sz_r}{r^2}\n\\]\n\nThis is a farfield decay.\nWhen \\(r\\) is large enough w.r.t. \\(z_s\\) we do not have directions \\(\\theta\\) where we have interference (constructive or distructive).\n\nA pressure amplitude decay proportional to \\(r^2\\) (intensity \\(\\propto\\) to \\(r^4\\)) is equivalent to a transmission loss of:\n\\[\nTL = 40\\log(r)\n\\]\nwhich is twice the loss associated with spherical spreading.\nNote, that this strong farfield field decay is entirely an interference effect!\n\nDepending on where we are in space, the harmonic wave travelling along the two paths can arrive in phase (constructive interference) or out of phase (destructive interference).\nWaves sum up\n\\(e^{kx}\\) determines the phase of the wave and how they interfere at the receiver\nAs we move in space we vary \\(r\\) and we change \\(\\theta\\).\n\n\nExample\nLet’s consider a \\(150\\) Hz source, placed \\(25\\) m below the sea surface in a homogeneous water column of infinite extent and with a sound speed of \\(1500\\) m/s. The acoustic wavelength is \\(\\lambda=10\\) m.\nReceiver is \\(200\\) m deep.\n\\[\np(r, z)= \\frac{e^{ikR_1}}{R_1} -\\frac{e^{ikR_2}}{R_2}\n\\]\nWe can now plot the TL field.\n\nf = 150   # source frequency (Hz)\nc = 1500  # sound speed (m/s)\nλ = c/f   # wavelength lambda (10m in our example)\n\nz_s = 25  # source depth (m)\nz_r = 200 # receiver depth (m)\n\nomega = 2*np.pi*f # angular frequency\nk = 2*np.pi/λ     # wavenumber\n\nrange_v = range(1,5000,10) # horizontal range (receiver)\n\n# apply the equations seen above\np = []   # pressure\nfor r in range_v:\n    R1 = np.sqrt(r**2+(z_r-z_s)**2)\n    R2 = np.sqrt(r**2+(z_r+z_s)**2)\n    p.append(1/R1*np.exp(1j*k*R1)-1/R2*np.exp(1j*k*R2))\n\n##\n## Plot results\nplt.figure(figsize=(10,6))\n\n# 1. plot the pressure computed from the exact field solution\n# Note the oscillating field structure with five peaks and a farfield decay proportional to 40 log r .\nplt.plot(range_v, -20*np.log10(np.abs(p)), \n         color='k', linestyle='-', linewidth=3, label='20log(|p|)')\n\n# 2. plot the 20*log10(r) behaviour\nplt.plot(range_v, 20*np.log10(range_v),\n         color='k', linestyle='--', linewidth=2, label='20log(r)')\n\n# 3. plot the 40*log10(r) behaviour corresponding to farfield decay. \n# Plotted with an offset to make it simpler to compare with the exact pressure field.\nplt.plot(range_v, 40*np.log10(range_v)-75, \n         color='k', linestyle=':', linewidth=2, label='40log(r)')\n\nplt.legend()\n# set axis limits and invert y axis\nplt.xlim(min(range_v), max(range_v))\nplt.ylim(40, 90)\nplt.gca().invert_yaxis()\n\n# add labels\nplt.title('f:150 Hz, Source depth: 25m, Receiver depth: 200m')\nplt.ylabel(\"Transmission Loss (dB)\");\nplt.xlabel(\"Range (m)\");\n\n\n\n\n\n\n\n\n\n\\(TL=10\\log\\frac{I}{I_0}=20\\log\\frac{p}{p_0}\\), always negative (or less than 1 in linear scale)\n\\(TL\\) represented as a positive value in dB (we invert its sign and the \\(y\\) axis when we plot it)\nMinimum of \\(TL\\) corresponds to maximum of pressure \\(p\\).\nFor large enough \\(r\\) there are no more maxima, and we are in the far field decay which is proportional to \\(40\\log(r)\\)\n\\(20\\log(r)\\) (dashed line) is the ideal gemetrical spherical attenuation.\nFor large enough \\(r\\), the attenuation due to interference is higher than gemetrical spherical attenuation (happens at about \\(8\\) km in this example)\nThe attenuation due to interence adds to the intrinsic and gemetrical attenuation.\nWe can still use a dominant attenuation.\n\nAnd if we vary the receiver horizontal range \\(r\\) and its depth \\(z_r\\):\n\nf = 150   # source frequency (Hz)\nc = 1500  # sound speed (m/s)\nl = 10    # wavelength lambda\n\nz_s = 25  # source depth (m)\n\nomega = 2*np.pi*f # angular frequency\nk = 2*np.pi/l     # wavenumber\n\nrange_v = range(1, 500, 1)       # horizontal range (receiver)\nrange_z_r = np.arange(1, 500, 1) # receiver depth (m)\n\np = np.zeros(shape=(len(range_z_r), len(range_v)), dtype=complex) # pressure\nfor id_zr, z_r in enumerate(range_z_r):         \n    # apply the equations seen above\n    for id_r, r in enumerate(range_v):\n        R1 = np.sqrt(r**2+(z_r-z_s)**2)\n        R2 = np.sqrt(r**2+(z_r+z_s)**2)\n        p[id_zr, id_r] = 1/R1*np.exp(1j*k*R1)-1/R2*np.exp(1j*k*R2)\n\n\n##\n## Plot\nplt.figure(figsize=(10,6))\nplt.matplotlib.pyplot.contourf(range_v, range_z_r, -20*np.log10(np.abs(p)),\n                              levels=[25, 30, 35, 40, 45, 50, 55])\nplt.gca().invert_yaxis()\n\n# add labels\nplt.title('TL, f:150 Hz, Source depth: 25m')\nplt.ylabel(\"Depth (m)\");\nplt.xlabel(\"Range (m)\");\n\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\nNote the \\(\\theta\\) directions corresponding to the pressure maximum\nThe \\(\\theta\\) directions are finite\nInterference patterns vary depending on frequency (depend on \\(k\\))\n\nIf we increase the frequency to \\(f=300\\) Hz\n\nf = 300   # source frequency (Hz)\nc = 1500  # sound speed (m/s)\nλ = c/f   # wavelength lambda\n\nz_s = 25  # source depth (m)\n\nomega = 2*np.pi*f # angular frequency\nk = 2*np.pi/λ     # wavenumber\n\nrange_v = range(1, 500, 1)       # horizontal range (receiver)\nrange_z_r = np.arange(1, 500, 1) # receiver depth (m)\n\np = np.zeros(shape=(len(range_z_r), len(range_v)), dtype=complex) # pressure\nfor id_zr, z_r in enumerate(range_z_r):         \n    # apply the equations seen above\n    for id_r, r in enumerate(range_v):\n        R1 = np.sqrt(r**2+(z_r-z_s)**2)\n        R2 = np.sqrt(r**2+(z_r+z_s)**2)\n        p[id_zr, id_r] = 1/R1*np.exp(1j*k*R1)-1/R2*np.exp(1j*k*R2)\n\n\n##\n## Plot\nplt.figure(figsize=(10,6))\nplt.matplotlib.pyplot.contourf(range_v, range_z_r, -20*np.log10(np.abs(p)),\n                              levels=[25, 30, 35, 40, 45, 50, 55])\nplt.gca().invert_yaxis()\n\n# add labels\nplt.title('TL, f:1500 Hz, Source depth: 25m')\nplt.ylabel(\"Depth (m)\");\nplt.xlabel(\"Range (m)\");\n\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTransmission Loss in water\n\n\n\n\n\n\n\n\n\n\n\nSimulation of Transmission Loss (dB) in the Mediterranean Sea; salinity: 38psu. EU FP7 UAN Project.\n\n\nSimulation of Transmission Loss (dB) in the Baltic Sea; salinity: 7psu. EU FP7 UAN Project.\n\n\n\n\nAttenuations due to intrinsic attenuation and geometric attenuation.\nNo interference.\nAt the same distance (range), the higher the frequency, the higher the loss (intrinsic attenuation).\nAt the same frequency, the higher the distance, the higher the loss (geometric attenuation).\nDifference between the two plots due to difference in salinity.\nSalinity is dramatically different (Mediterranean 38psu; Baltic 7psu).\nSalinity has a high impact on attenuation.\nConsider for example:\n\n5km and 15kHz: around 5dB of difference;\n15km and 20kHz: around 8dB of difference.",
    "crumbs": [
      "The Acoustic Channel"
    ]
  },
  {
    "objectID": "underwater_navigation.html#a-taxonomy-of-underwater-navigation-systems",
    "href": "underwater_navigation.html#a-taxonomy-of-underwater-navigation-systems",
    "title": "Underwater Navigation",
    "section": "A taxonomy of underwater navigation systems",
    "text": "A taxonomy of underwater navigation systems\n\n\n\n\n\n\n\nFigure: from Paull et al, JOE, 2014\n\nNote those sensors that are used for terrestrial navigation\nOptic sensors are used for short range navigation\nMagnetic sensors\n\nMagnetic sensors can be used for ‘terreain-based’ navigation where we measure local deviation of the Earth magnetic field\nUse to locally orient (e.g., pipeline following)\n\nAcoustic modems\n\ncooperative localisation (e.g., network of robots)\nwith surface ship",
    "crumbs": [
      "Underwater Navigation"
    ]
  },
  {
    "objectID": "underwater_navigation.html#geophysical-navigation",
    "href": "underwater_navigation.html#geophysical-navigation",
    "title": "Underwater Navigation",
    "section": "Geophysical Navigation",
    "text": "Geophysical Navigation\n\nUse a map of geophysical bottom properties as aided sensor in navigation\nCompare the map value of your estimated position with the measured one (e.g., bathymetry)\nRequires appropriate on-board sensors (e.g., multi-beam)\nAssumptions:\n\nthe map needs to be enough informative\nthe environment is considered invariant\nCan be done also with magnetometers\n\n\n\nGeophysical navigation: terrain-aided\n\n\n\n\n\n\n\n\n\nDYNOPO Cruise, NOC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSalavasidis et al, “Terrain‐aided navigation for long‐range AUVs in dynamic under‐mapped environments”, Journal of Field Robotics",
    "crumbs": [
      "Underwater Navigation"
    ]
  },
  {
    "objectID": "underwater_navigation.html#self-localisation-and-mapping-slam",
    "href": "underwater_navigation.html#self-localisation-and-mapping-slam",
    "title": "Underwater Navigation",
    "section": "Self Localisation And Mapping (SLAM)",
    "text": "Self Localisation And Mapping (SLAM)\n\nSLAM is a popular and powerful tool in robotics\nUnderwater landmark definition and recognition is much more challenging\n\nOptics works at very close range only (can be done when performing inspections)\nSide-scan sonar imagery might differ depending on the relative position of the vehicle and of the objects (think of the difference between the sweep area and near nadir areas)\n\nSome recent attempts to use SLAM in specific environments\nAn alternative is using acoustic beacons deployed by vehicles as landmarks of opportunity",
    "crumbs": [
      "Underwater Navigation"
    ]
  },
  {
    "objectID": "underwater_navigation.html#base-line-systems",
    "href": "underwater_navigation.html#base-line-systems",
    "title": "Underwater Navigation",
    "section": "Base-Line Systems",
    "text": "Base-Line Systems\n\nLong-base line (LBL)\n\n\n\n\n\n\n\n\n\n\nShort-base line (SBL)\n\n\n\n\n\n\n\n\n\n\nUltra short base line (USBL)\n\n\n\n\n\n\n\n\nFigures: From Paull et all, JOE, 2014\n\nVehicle localises itself with respect to acoustic beacons\nBeacons transmit signals regularly (scheduled times)\nSynchronised clocks of beacons and vehicle\n\nNot necessarily easy to achieve, especially for long missions\nUsage of atomic clocks to limit clock drifts (temperature control)\n\nAssumes vehicle does not move too much between transmissions\nInverted systems when the vehicle transmits and beacons localise the vehicle\nDifference betwen One-Way Travel Time (OWTT) and Two-Way Travel Time (TWTT)\nLBL requires deployment and calibration which is not trivial\nSBL alleviates some of this issue deploying transponders from the ship directly\nUSBL uses similar concept. Having multiple hydrophones close together form an antenna and obtain to determine the bearing from the vehicle\nLocalisation obtained measuring the range from a set of transponders which are in known locations\nRange calculated as Time-of-Arrival of acoustic signals\nSpeed of sound is required and ray path corrections might be needed\n\nThink of surface ship and vehicle at 400m (there is a thermocline)\n\nThe distance between two transponders is the base-line\n\n\n\nLong-base line systems\n\nBase-line length: 500m - 5000m\nFrequency: 10-40 kHz\n2 Way ToA or TDoA (no need of clock synchronisation)\nDifferent frequencies can be used to identify transponders and have parallel transmissions\nTransponders are usually moored at the bottom\nGeo-referentiation of the transponders through a calibration procedure from ship\n\nLong baseline navigation (LBL) is a method of determining the position of a underwater vehicle or diver using a series of acoustic transponders that are strategically placed on the ocean floor. The transponders emit a unique acoustic signal that can be detected by a transceiver on the underwater vehicle or diver. By measuring the time it takes for the signal to travel from the transponder to the transceiver, and knowing the speed of sound in water, the distance between the transponder and the transceiver can be calculated. By measuring the distance to multiple transponders, the position of the underwater vehicle or diver can be determined using trilateration. LBL is commonly used in oceanographic research, underwater exploration, and commercial diving operations.\n\n\nHyperbolic and Spherical Navigation\n\nHyperbolic navigation and spherical navigation are both methods of determining the position of a vehicle or diver using acoustic signals, however they differ in the way they process the information.\nSpherical navigation, also known as time-of-arrival (TOA) navigation, relies on measuring the time of arrival (TOA) of a signal at a single receiver. By measuring the TOA at a single receiver, the distance between the vehicle or diver and the receiver can be determined using the speed of sound in water. The position of the vehicle or diver can be determined by using a process called multilateration, which involves measuring the distance to multiple emitters.\nHyperbolic navigation, also known as time-difference-of-arrival (TDOA) navigation, relies on measuring the time difference of arrival (TDOA) of a signal at two or more receivers. By measuring the TDOA at multiple receivers, the position of the vehicle or diver can be determined using hyperbolic lines of position (LOPs).\n\n\n\nLocalisation precision\n\nLocalisation precision depends on vehicle location with respect to the transducers\nBingham’s rule of thumb for Horizontal Dilution of Precisionn (HDoP) for spherical navigation (IROS, 2009)\n\nRule is exact when doing trilateration, 3 transponders and gaussian noise\nGaussian noise is rarely true\n\nHDoP is the error in the horizontal position compared to the measurement error \\[\nHDoP \\approx 2\\frac{D}{BL}\n\\]\n\nwhere \\[\nHDoP = \\frac{\\Delta(Horizontal position)}{\\Delta(Measurement)}\n\\]\nWhere - \\(D\\) is the distance of the vehicle from the baricenter of the transponder configuration (e.g., transponders form an equilateral triangle: baricentre of triangle D=0) - \\(BL\\) is the length of the baseline\nWe can reduce \\(HDoP\\) either with the vehicle in the baricentre or with long baselines\n\nHyperbolic navigation uses time difference of arrival at multiple receivers to calculate position where as Spherical navigation uses time of arrival at a single receiver and uses multilateration to calculate position.\n\n\n\nIssues\n\nWhen we enlarge the baseline we have refraction: Snell’s law must be accounted for.\n\nRequires computation (Casalino et al, J.ISR 2011)\n\nOutliers due to multipath\nMissing data due to environmental fluctations\n\nTypical performance - Accuracy: 0.1% - 2% of the acoustic path - The higher the frequency, the greater the accuracy, the shorter the baseline (attenuation)\n\nPrecision: standard deviation between 0.2m -10m (Kinsey et al, MCMC 2006)\n\nThe longer the baseline, the higher the standard deviation (e.g., higher multipath, larger environmental variations, etc.)\n\n\n\n\nReversed LBL\n\nTransponders are on the surface and hence with GPS\n\nNo need for calibration\n\nPosition available to a centre station, not to the vehicle\n\nBuoys need a radio antenna as well to communicate its measurements\nNavigation is refined after the mission\nRequires clock synchronisation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure: From Alcocer, 2006 (Left), Caiti, 2001 (Right)\n\n0.5m accuracy - points are close to the truevalue (green dot)\n1m Precision\n\n\n\nShort Base Line (SBL)\n\nBaseline 20-100m\nInstalled on ship hull or fixed structures\nCalibration in dry-dock\nEasy integration with on-board GPS\n\nCompensation of ship motion needed\n\nRarely used today\nStill some applications for special systems and cases\n\nWHOI under-ice monitoring of AUVs\n\nPerformance includes with transponders separation\nSame characteristics of LBL\n\n\n\nUltra Short Base Line (USBL)\n\nBaseline: &lt;0.1m\nInstalled on ship hull of deployed from side (portable)\nRange and bearings interrogating transponders on the vehicle\nIt is an array! Beamforming / Phase information\nEasy integration with on-board GPS, easy of deployment, no calibration needed for portable systems\n\nCompensation of ship motion needed\n\nThe ship knows the vehicle position, the vehicle does not\n\nUSBL with communication capabilities to send back the position\nUSBL main transponder installed on the vehicle (inverted USBL)\n\n\n\n\nExample - Sonardyne SCOUT\n\n\n\n\n\n\n\n\n\nFrequency: 35-55kHz\nOperating range: 500m\nAccuracy: 2.7% of slant range",
    "crumbs": [
      "Underwater Navigation"
    ]
  },
  {
    "objectID": "underwater_navigation.html#hipap-kongsberg",
    "href": "underwater_navigation.html#hipap-kongsberg",
    "title": "Underwater Navigation",
    "section": "HiPAP (Kongsberg)",
    "text": "HiPAP (Kongsberg)\n\nDeveloped as part of the Hugin AUV programme in the mid-90s\nHigh performance, transferred to almost all Kongsberg positioning systems\nSometime called Super LBL\n240/280 elements to form a bulb array\n\n\n\n\n\n\n\n\n\n\n\n\n\nHiPAP High Precision Acoustic Positioning\n\nCymbal Acoustic Protocol\n\n\n\n\n\n\n\n\nFigure: examples of time-frequency plots of Cymbal signals for navigation and communication. High intensity signals are from HiPAP, followed by weaker replies from a remote transponder (cNode)\n\n\nMeasurement compensation\nPositions calculated from the raw measurements are influenced by variable sound velocity through the water column. The variable sound velocity causes an error in both range measurements and the angular measurements. By use of a sound profile, the system can correct these errors.\n\n\n\n\n\n\n\n\nThe sound velocity values may be measured by a probe and transferred to the system. If the depth of the target (transponder) is known either by depth sensor in the transponder or by an ROV depth sensor, these data can be transferred to the system and they will be used in the compensation. The range calculation is compensated for the error caused by different sound velocities in the water column, and for the extra propagation path caused by the ray bending. The angular measurements are compensated for the ray bending. The compensation is used in all positioning modes.\nFrom HiPAP High Precision Acoustic Positioning Product description.\n\nNo reply problems - how can we explain it?\n\n\n\nHiPAP 500 Technical Specifications\n\n\n\n\n\n\n\n\n\nAngle accuracy depends on Signal to Noise Ratio\nNote how reported performance are based on a number of assumptions\nAssumptions are not always reported in the datasheet\nHiPAP is also an acoustic modem\nThink of HiPAP-AUV operations\n\nAUV can send messages to the command and control\nCommand and control can send messages to vehicle\nQuality of data collected (rare and compressed images of collected data sent to C2)",
    "crumbs": [
      "Underwater Navigation"
    ]
  },
  {
    "objectID": "underwater_navigation.html#network-based-localisation-and-navigation",
    "href": "underwater_navigation.html#network-based-localisation-and-navigation",
    "title": "Underwater Navigation",
    "section": "Network-based Localisation and Navigation",
    "text": "Network-based Localisation and Navigation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFenucci et al, Ad hoc Acoustic Network Aided Localization for micro-AUVs, 2022\n\nComments\n\nMoving calculations at application level dramatically improves flexibility\nAutonomy and Navigation can be explicitly linked\nUsage of different MAC (Medium Access Control) leads to different performance",
    "crumbs": [
      "Underwater Navigation"
    ]
  },
  {
    "objectID": "underwater_navigation.html#underwater-communications",
    "href": "underwater_navigation.html#underwater-communications",
    "title": "Underwater Navigation",
    "section": "Underwater Communications",
    "text": "Underwater Communications\n\nUnderwater Acoustic Communications are difficult due to:\n\nLimited bandwidth as range increases\n\nLonger range require lower frequencies\nLarger bandwidth would achieve higher resolution\nNarrow bandwidth means less information we can transmit (lower bitrate)\nUsual resolution-range trade-off\n\nChannel dependent performance (source-receiver geometry, environment)\n\nE.g., shadow zones\n\n\nMost Systems\n\nDirect-Sequence Spread Spectrum (which enhanced SNR - same method as GPS)\nEstimation of the channel transfer function\n\nEffectively the Transmission Loss (TL) at the various frequencies\nDepends on the environment\nTypically each acoustic message starts with a preamble (same bits)\n\nDistortion of this known message due to TF of the channel\nContinuous channel estimation\n\n\n\nSome technology is available in US only\n\nWHOI, Teledyne Benthos\n\nToday acoustic modems tend to be coupled with USBL\n\n\n\n\n\n\n\n\n\n\nNote the very limited bitrate\nNominal performance vs operational performance (bitrate, range)\nRobots need to be careful about information that they transmit (careful selection of data)\n\n\nWhat can you theoretically achieve\n\n\n\n\n\n\n\n\n\nSource power and optimal power to have 20dB SNR (lower SNR means lower performance)\nThe plot tells that (for ex.) at 1km, max capacity is 100 kbps. We cannot go faster than this.\nCommercial modems are below this limit but even the optical case is still very limited\n\nWe cannot enlarge the bandwidth to have better capacity (bandwidth is limited by all the factors that we have studies already - e.g., range less than desired)\n\n\nFrom Caiti, Munafo, Crisostomi, Physical Characterisation of Acoustic Communication Channel Properties, 2010",
    "crumbs": [
      "Underwater Navigation"
    ]
  },
  {
    "objectID": "underwater_navigation.html#robustness",
    "href": "underwater_navigation.html#robustness",
    "title": "Underwater Navigation",
    "section": "Robustness",
    "text": "Robustness\n\nEven with degraded performance, some equipment proven reliable in repeated field tests\nWHOI, Evologics, Teledyne Benthos, Tritech, LinkQuest\nEvologics modems have ranging and USBL capabilities\nThese capabilities open up a series of possibilities for localization, even with AUV teams",
    "crumbs": [
      "Underwater Navigation"
    ]
  },
  {
    "objectID": "underwater_navigation.html#doppler-velocity-logger",
    "href": "underwater_navigation.html#doppler-velocity-logger",
    "title": "Underwater Navigation",
    "section": "Doppler Velocity logger",
    "text": "Doppler Velocity logger\n\nA Doppler velocity logger (DVL) uses the Doppler effect to measure the velocity of a moving object.\nThe Doppler effect is a change in frequency or wavelength of a wave caused by the motion of the source or the observer.\nA DVL typically works by emitting a high-frequency sound wave (acoustic pulses) and measuring the frequency shift of the returning echoes.\nThe frequency shift, also known as the Doppler shift, is directly proportional to the velocity of the object. By measuring the Doppler shift of multiple echoes and using trigonometric calculations, the DVL can determine the velocity of the object in multiple dimensions (e.g. forward and lateral velocity, or velocity relative to the bottom).\nUsed to measure the velocity of an object in water by emitting acoustic pulses and measuring the Doppler shift of the echoes that reflect off the seafloor or other objects in the water.\nDVLs are commonly used in a variety of applications such as underwater navigation, oceanography, hydrographic surveying, and underwater mapping.\nA DVL is an acoustic sensor that estimates velocity relative to the sea bottom.\nAchieved by sending a long pulse along a minimum of three acoustic beams, each pointing in a different direction.\nTypically, this produces estimates of velocity converted into an XYZ coordinate frame of reference – the DVL’s frame of reference.\nTogether with a heading estimate, these velocity estimates may be integrated over the ping interval to estimate a step-by-step change of position - i.e. displacement = velocity × time step.\nMeasurement of velocity relative to the seabed from doppler shift of acoustic echos\nEmission of very high frequency signals (200 KHz – MHz)\nOriginally designed as a system to measure the sea current from backscatter of particles in the water column\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;td&gt;\n        &lt;img src=\"./images/11.underwater-navigation/13.dvl-3.png\" alt=\"13.dvl-3\" style=\"width: 650px\"/&gt;           \n    &lt;/td&gt; \n\n\n\n\n\n\n\n\n\nDoppler Equation\n\nThe Doppler shift is directly related to the velocity of an object.\nThe Doppler shift is the change in frequency or wavelength of a wave caused by the motion of the source or the observer. When an object is moving towards a stationary observer, the frequency of the waves emitted by the object will appear to be higher (known as a blue shift) than it actually is. Conversely, when an object is moving away from a stationary observer, the frequency of the waves emitted by the object will appear to be lower (known as a red shift) than it actually is.\n\nIn the case of a Doppler velocity logger (DVL), the instrument emits a high-frequency sound wave and measures the frequency shift of the returning echoes. The DVL then uses the measured frequency shift, also known as the Doppler shift, to calculate the velocity of the object.\nThe Doppler velocity logger (DVL) measures the velocity of an object by comparing the frequency of the emitted wave and the frequency of the wave that is reflected back from the moving object. The difference in these frequencies is directly proportional to the velocity of the object.\nThe relationship between the Doppler shift and the velocity of an object is given by the Doppler equation, which relates the velocity of the object to the ratio of the frequency of the emitted wave to the frequency of the reflected wave. The equation takes into account the speed of sound in the medium and the angle between the object’s velocity vector and the line connecting the object to the observer.\n\n\n\n\n\n\n\n\nThe general form of the Doppler equation:\n\\[\nf = \\frac{c\\pm V_r}{c\\pm V_s}f_0\n\\]\nC = propagation speed of waves in the medium;\nVr = speed of the receiver relative to the medium, +c if the receiver is moving towards the source, -c if the receiver is moving away.\nVc = speed of the source relative to the medium, +c if the source is moving away -c if the source is moving towards the receiver.",
    "crumbs": [
      "Underwater Navigation"
    ]
  },
  {
    "objectID": "underwater_navigation.html#acoustic-doppler-current-profiler-adcp",
    "href": "underwater_navigation.html#acoustic-doppler-current-profiler-adcp",
    "title": "Underwater Navigation",
    "section": "Acoustic Doppler Current Profiler (ADCP)",
    "text": "Acoustic Doppler Current Profiler (ADCP)\n\nOperated from surface or moored at the bottom\n\n\n\n\n\n\n\n\n\nFigure from [ADCP | WHOI]9https://www.whoi.edu/what-we-do/explore/instruments/instruments-sensors-samplers/acoustic-doppler-current-profiler-adcp/)\nAn Acoustic Doppler Current Profiler (ADCP) is a type of instrument that uses the Doppler effect to measure the velocity of water currents at different depths. It operates by emitting a series of high-frequency sound pulses, which travel through the water and are reflected back by particles or scatterers in the water. The ADCP then measures the Doppler shift of the returning echoes, which is directly proportional to the velocity of the water current.\nThe operating principle of an ADCP can be broken down into several steps:\n\nTransmitting: The ADCP emits a series of high-frequency sound pulses, which travel through the water and are reflected back by particles or scatterers in the water.\nReceiving: The ADCP receives the echoes of the sound pulses, which have been reflected back by the particles or scatterers in the water.\nDoppler shift measurement: The ADCP measures the Doppler shift of the returning echoes, which is directly proportional to the velocity of the water current. The ADCP uses the Doppler equation to determine the velocity of the water current.\nBeamforming: The ADCP uses a beamforming algorithm to determine the direction of the water current. This is done by emitting the sound pulses in different directions and measuring the Doppler shift of the returning echoes in each direction.\nProfiling: The ADCP uses the measured velocities and directions of the water current to profile the current at different depths. This is done by emitting the sound pulses at different depths and measuring the Doppler shift of the returning echoes at each depth.\nData processing: The ADCP processes the data and generates a current velocity profile, which shows the velocity of the water current at different depths\n\nIn summary, an Acoustic Doppler Current Profiler (ADCP) uses the Doppler effect to measure the velocity of water currents at different depths by emitting a series of high-frequency sound pulses, measuring the Doppler shift of the returning echoes, and using the data to profile the current at different depths.\n\n\n\n\n\n\n\n\n&lt;td&gt;\n        &lt;img src=\"./images/11.underwater-navigation/fig2-hires.jpg\" alt=\"fig1-hires\" style=\"width: 450px\"/&gt;           \n    &lt;/td&gt;",
    "crumbs": [
      "Underwater Navigation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#objectives",
    "href": "the_wave_equation.html#objectives",
    "title": "The Wave Equation",
    "section": "Objectives",
    "text": "Objectives\n\nGive a formal definition of acoustic propagation.\nDefine the (Linear) Wave Equation\nIntroduce numerical methods to solve it.",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#the-wave-equation-in-a-fluid",
    "href": "the_wave_equation.html#the-wave-equation-in-a-fluid",
    "title": "The Wave Equation",
    "section": "The wave equation in a fluid",
    "text": "The wave equation in a fluid\n\nLongitudinal waves due to pressure variations\nThe perturbation that propagates in the medium is the wave (mass does not propagate)\n\n\n\n\n\n\n\n\n\n\n\nFigure from Dan Russel Acoustics and Vibration Animations\n\nThe medium under consideration is treated as consisting of numerous small volumes, referred to as particles. This approach allows us to analyze the medium’s behavior in detail.\nEach of these volumes, or particles, possesses mass and exhibits both kinetic and potential energy, key properties for understanding their dynamics.\nFor analysis, we establish a coordinate system defined by the axes \\(x, y, z\\). This system serves as a framework for describing the positions and movements of the particles.\nThe orientation of each particle is aligned with this coordinate system, ensuring a standardized approach to describing their positions and movements.\n\nRegarding the motion of these particles: - The term displacement is denoted by \\(\\textbf{u}\\), representing the change in a particle’s position relative to its original, or equilibrium, position. It’s important to note here that the particles themselves do not move from their positions; rather, they experience changes in shape, such as stretching or compression, relative to their equilibrium state. - The velocity of a particle, represented by \\(\\textbf{v}=\\frac{\\partial \\textbf{u}}{\\partial t}\\), is defined as the rate of change of displacement over time. - This velocity is a partial derivative, reflecting the fact that displacement can vary based on a particle’s specific location within the coordinate system (\\(x, y, z\\)) and time (\\(t\\)). This approach accounts for the infinite variety of particles’ behaviors, recognizing that, at any given moment, the displacement of one particle (for example, one of the black particle above) can differ from that of others due to its unique position and the specific time. This differential displacement underscores the complexity of the medium’s dynamics, where each particle’s movement is influenced by its spatial coordinates and the temporal dimension.\nLet’s define some key general equations (no linear approximation yet)\n\n1. Conservation of mass\n\\[\n\\frac{\\partial \\rho}{\\partial t} = -\\nabla \\cdot \\rho \\textbf{v}\n\\]\nwhere \\(\\rho\\) is the density, and \\(\\textbf{v}\\) is the velocity.\nThis is the eq. of conservation of mass (for a unit volume) - Mass is density times volume.\n\nThe equation is telling us that the variation of mass depends on how much the velocity converges or diverges: converging vectors, increasing mass and vice versa\nThe equation of the conservation of mass is normalised w.r.t to volume \\(V\\) (\\(m = \\rho V\\))\n\nEach particle has volume \\(dV = dx dy dz\\) and we are considering normalised volume.\n\n\n\\(\\nabla \\cdot \\textbf{v}\\) is the divergence of the velocity and can be interpreted as (the negative of) the fractional rate of change of the density of the fluid element.\nGiven a vector \\(\\textbf{v}=[v_x, v_y, v_z]^T\\), its divergence is a scalar defined as: \\[\n\\nabla \\cdot \\textbf{v} = \\frac{\\partial v_x}{\\partial x} + \\frac{\\partial v_y}{\\partial y} + \\frac{\\partial v_z}{\\partial z}\n\\]\nIt tells us, locally, how much the vectors of the vector field \\(\\textbf{v}\\) are converging or diverging.\n\n\n\n\n\n\n\n\nPositive divergence (Left); Negative divergence (Right).\n\n\n2. Newton’s 2nd law (Euler’s equation)\n\\[\n\\frac{\\partial \\textbf{v}}{\\partial t} + \\textbf{v} \\cdot \\nabla \\textbf{v} = -\\frac{1}{\\rho}\\nabla p (\\rho)\n\\]\n\n\\(F = ma\\)\nNormalised with respect to the volume (we divide by \\(\\frac{1}{\\rho}\\))\n\\(\\frac{\\partial \\textbf{v}}{\\partial t}\\) is the acceleration\n\\(\\nabla p\\) is the force\n\\(\\textbf{v} \\cdot \\nabla \\textbf{v}\\) is quadratic in the velocity\n\n\\(\\nabla \\textbf{v}\\) is the Jacobian Matrix (\\(\\textbf{v}\\) is a vector)\n\\(\\textbf{v} \\cdot \\nabla \\textbf{v}\\) is a: vector x matrix $ $ vector\n\n\n\n\n3. Adiabatic state equation\n\nWe also need a thermodynamic state equation to relate pressure with density\nThe adiabatic process is a thermodynamic process in which there is no heat transfer from in or out of the system\nWe need it in a form that is generic (Taylor expansion - could be Ideal gas law)\n\n\\[\np = p_0 + \\rho' \\Big [\\frac{\\partial p}{\\partial \\rho} \\Big]_{S} + \\frac{1}{2}(\\rho')^2\\Big [\\frac{\\partial^2 p}{\\partial \\rho^2} \\Big]_{S}  + ...\n\\]\nWe finally define:\n\\[\nc^2 = \\Big [ \\frac{\\partial p}{\\partial \\rho} \\Big ] _S\n\\]\n\npressure variation with respect to density, in the adiabatic state equation\n\\(c\\) will correspond to the sound speed (we will see this later)",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#small-perturbations-and-our-linear-approximation",
    "href": "the_wave_equation.html#small-perturbations-and-our-linear-approximation",
    "title": "The Wave Equation",
    "section": "Small perturbations and our linear approximation",
    "text": "Small perturbations and our linear approximation\nWe now introduce a linear approximation, considering small enough perturbation so that we can truncate to the first order all perturbations in the medium\nWe can then define pressure as: \\[\np = p_0 + p'\n\\]\nwhere \\(p_0\\) is the equilibrium pressure, \\(p'\\) is the pressure variation.\nWe can then define density as: \\[\n\\rho = \\rho_0 + \\rho'\n\\]\nwhere \\(\\rho_0\\) is the equilibrium density, \\(\\rho'\\) is the density variation.\nWe also assume that:\n\\[\n|\\textbf{v}(p', \\rho')| &lt;&lt; c\n\\]\ni.e., the particle velocity (which is function of \\((p', \\rho')\\), because at equilibrium the velocity would be zero) is much less than \\(c = \\sqrt{\\Big [ \\frac{\\partial p}{\\partial \\rho} \\Big ] _S}\\)\nUnder these hypothesis, our equations can be simplified as:\nConservation of mass \\[\n\\frac{\\partial \\rho'}{\\partial t} = -\\rho_o\\nabla\\cdot \\textbf{v} \\;\\;\\;\\;\\;\\; (1)\n\\]\nNewton’s 2nd Law: \\[\n\\frac{\\partial \\textbf{v}}{\\partial t} = -\\frac{1}{\\rho_0}\\nabla p'(\\rho)  \\;\\;\\;\\;\\;\\; (2)\n\\]\nand the (first-order) relationship between pressure variation and velocity variation becomes:\n\\[\np' = \\rho' c^2 \\;\\;\\Rightarrow\\;\\; c^2 =\\frac{p'}{\\rho'}\n\\]\ni.e., \\(c^2\\) is the ratio between pressure variation and velocity variation. This comes from the Taylor expansion of the eq. of state.\nWith a slight abuse of notation, in the rest of the calculations we will drop the apostrophe and use:\n\\[\np = p'\\;\\; \\rho = \\rho'\n\\]\nto represent our perturbations.\nThe linear differential wave equation can be obtained with respect to pressure and with respect to velocity.\n\nLinear Wave Equation with respect to Pressure\nWe take the time derivative of the conservation of mass (1):\n\\[\n\\frac{\\partial^2}{\\partial t^2}\\rho = -\\rho_o \\frac{\\partial}{\\partial t} \\nabla\\cdot \\textbf{v}\n\\]\nand the divergence of Netwton’s second law (2):\n\\[\n\\nabla \\cdot \\frac{\\partial \\textbf{v}}{\\partial t} = - \\frac{1}{\\rho_0}\\nabla \\cdot \\nabla p\n\\]\nwhere \\(p\\) and \\(\\rho\\) are the variations w.r.t to the respective equilibrium quantities (we called them \\(p'\\) and \\(\\rho'\\) before).\nLet’s now assume that we can replace time derivative with the divergence as (true under specific continuity assumptions):\n\\[\n\\nabla \\cdot \\frac{\\partial \\textbf{v}}{\\partial t} = \\frac{\\partial}{\\partial t}\\nabla \\cdot \\textbf{v}\n\\]\nThis means that the first term in the second equation is equal to the second term of the first equation.\nMoreover, we know, from the relation between pressure variation and velocity variation, that: \\[\n\\rho = \\frac{1}{c^2}p\n\\]\nand assume that \\(c\\) does not vary with time.\nWe can hence write:\n\\[\n\\frac{\\partial^2}{\\partial t^2}\\rho = \\frac{1}{c^2} \\frac{\\partial^2}{\\partial t^2}p = -\\rho_o \\Big (-\\frac{1}{\\rho_0} \\nabla \\cdot \\nabla p \\Big ) \\Rightarrow\n\\frac{1}{c^2} \\frac{\\partial^2}{\\partial t^2}p = \\nabla \\cdot \\nabla p\n\\]\nSince\n\\[\n\\nabla \\cdot \\nabla p = \\nabla^2 p = \\Delta p\n\\]\nWhich is the Laplacian of \\(p\\):\n\\[\n\\Delta p = \\frac{\\partial^2}{\\partial x^2}p + \\frac{\\partial^2}{\\partial y^2}p + \\frac{\\partial^2}{\\partial z^2}p\n\\]\nThe Laplacian of \\(p\\) is the sum of the second order space derivatives of \\(p\\).\nSo our equation: \\[\n\\frac{1}{c^2} \\frac{\\partial^2}{\\partial t^2}p = \\nabla \\cdot \\nabla p = \\frac{\\partial^2}{\\partial x^2}p + \\frac{\\partial^2}{\\partial y^2}p + \\frac{\\partial^2}{\\partial z^2}p\n\\]\nor\n\\[\n\\frac{\\partial^2}{\\partial x^2}p + \\frac{\\partial^2}{\\partial y^2}p + \\frac{\\partial^2}{\\partial z^2}p -\\frac{1}{c^2}\\frac{\\partial^2}{\\partial t^2}p = 0  \\;\\;\\;\\; \\text{(*)}\n\\]\nwhich is the linear wave equation with respect to pressure.\nMore in general:\nall linear wave equations establish the linear relation between second order space derivative of a field (in our case, pressure) with the second order time derivative\n\nLinear Wave Equation in a Fluid with respect to Pressure (Final form)\nAnd we can more generaly write the Linear Wave Equation in a Fluid w.r.t to pressure as:\n\\[\n\\rho\\nabla\\cdot \\Big (\\frac{1}{\\rho}\\nabla p \\Big ) - \\frac{1}{c^2}\\frac{\\partial^2 p}{\\partial t^2} = 0 \\;\\;\\;\\; (*)\n\\]\n\nNote that it is a scalar equation.\nw.r.t to our previous expression \\(\\rho\\) is also assumed to be changing. In practise we always assume it constant.\n\n\n\n\nLinear Wave Equation with respect to Velocity:\nWe start from the same equations, which are reported here again for convenienence \\[\n\\frac{\\partial \\rho'}{\\partial t} = -\\rho_o\\nabla\\cdot \\textbf{v} \\;\\;\\;\\;\\;\\; (1)\n\\]\n\\[\n\\frac{\\partial \\textbf{v}}{\\partial t} = -\\frac{1}{\\rho_0}\\nabla p'(\\rho)  \\;\\;\\;\\;\\;\\; (2)\n\\]\n\\[\np' = \\rho' c^2 \\;\\;\\Rightarrow\\;\\; c^2 =\\frac{p'}{\\rho'}\n\\]\n(remember also that we in our derivation we call \\(p=p'\\) and \\(\\rho = \\rho'\\) for simplicity)\nAnd we take the gradient of the conservation of mass (1):\n\\[\n\\nabla \\frac{\\partial}{\\partial t}\\rho = -\\rho_0\\nabla (\\nabla \\cdot \\textbf{v})\n\\]\nand the time derivative of Netwton’s second law (2):\n\\[\n\\frac{\\partial^2}{\\partial t^2}\\textbf{v} = -\\frac{1}{\\rho_0} \\frac{\\partial}{\\partial t}\\nabla p\\;\\;\\;\\;\\;(3)\n\\]\nwe then use the relation between pressure variation and velocity variation: \\[\n\\rho = \\frac{1}{c^2}p\n\\]\nWe can again swap the differential operators and write:\n\\[\n\\nabla\\frac{\\partial \\rho}{\\partial t} =  \\frac{1}{c^2} \\nabla \\frac{\\partial}{\\partial t}{p} = \\frac{1}{c^2} \\frac{\\partial}{\\partial t}\\nabla p\n\\]\nAnd from the first equation: \\[\n\\frac{1}{c^2} \\frac{\\partial}{\\partial t}\\nabla p = -\\rho_0\\nabla (\\nabla \\cdot \\textbf{v}) \\;\\;\\;\\;\\;(4)\n\\]\nWe note that \\(\\frac{\\partial}{\\partial t}{p}\\) is defined in eq. (3) and in (4)\nAnd hence from equation (2) we can write:\n\\[\n\\frac{\\partial^2}{\\partial t^2}\\textbf{v} = -\\frac{1}{\\rho_0} \\Big( -c^2 \\rho_0\\nabla (\\nabla \\cdot \\textbf{v}) \\Big ) =   c^2 \\nabla (\\nabla \\cdot \\textbf{v})\n\\]\nNote that this is a vector equation: \\[\n\\frac{\\partial^2}{\\partial t^2}\\textbf{v}\n\\]\nis a vector of the second order time derivative of the components of the velocity, and $ () $ gives the second order space derivative w.r.t \\((x, y, z)\\).\n\nLinear Wave Equation in a Fluid with respect to Velocity (Final form)\nWe can then write:\n\\[\n\\nabla (\\nabla \\cdot \\textbf{v}) = \\frac{1}{c^2} \\frac{\\partial^2}{\\partial t^2}\\textbf{v} \\;\\;\\;\\;\\;\\; (*)\n\\]\nwhich is again in the form of a wave equation (relation between second order spatial derivative of \\(\\textbf{v}\\) and second order time derivative of \\(\\textbf{v}\\)).\nThat we can also re-write as:\n\\[\n\\frac{1}{\\rho}\\nabla \\Big ( \\rho c^2 \\nabla \\cdot \\textbf{v} \\Big ) - \\frac{\\partial^2 \\textbf{v}}{\\partial t^2} = 0 \\;\\; (*)\n\\]\nThis equation assumes \\(\\rho\\) to be non constant and hence entering into the differential operators. If instead is constant (\\(\\rho_0\\), it can be simplified as in the equation above).\nThe wave equations are dynamic equations, that includes both a dependency on time and on space, and its solution will be a function:\n\\[p(x, y, z, t)\\]\nor\n\\[\n\\textbf{v} = \\begin{pmatrix}\nv_x(x, y, z, t) \\\\\nv_y(x, y, z, t) \\\\\nv_z(x, y, z, t)\n\\end{pmatrix}\n\\]\nwhose components are a function of \\((x, y, z, t)\\).",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#wave-potential",
    "href": "the_wave_equation.html#wave-potential",
    "title": "The Wave Equation",
    "section": "Wave Potential",
    "text": "Wave Potential\n\nSolving the wave equation we have the velocity (a vector) and the particle displacement (a vector)\nSolving vector equations is not trivial\nWe are intested in the velocity field \\(\\textbf{v}\\), a vector-valued function of space and time, but it would be simpler to work with scalar functions of space.\n\nHypothesis: - Is it possible that the velocity field \\(\\textbf{v}\\), a vector-valued function is the gradient of a scalar field? - What conditions on the velocity should we have to make it possible for the velocity to be the gradient of a scalar field?\nLet’s suppose that a scalar field \\(\\phi\\) exists.\nIf \\(\\textbf{v}\\) is the gradient of the scalar field \\(\\phi\\), then: \\[\n\\textbf{v} = \\nabla\\phi\n\\]\nWe can now replace this equation in our vector-valued wave equation to obtain (assuming constant density):\n\\[\n\\nabla \\Big ( c^2 \\nabla \\cdot \\textbf{v} \\Big ) - \\frac{\\partial^2 \\textbf{v}}{\\partial t^2} = 0 \\;\\; (*)\n\\]\n\\[\n\\nabla \\Big ( c^2 \\nabla^2 \\phi  - \\frac{\\partial^2  \\phi}{\\partial t^2} \\Big ) = 0\n\\]\n\nThe above equation is zero if its argument is zero:\n\n\\[\nc^2 \\nabla^2 \\phi  - \\frac{\\partial^2  \\phi}{\\partial t^2} = 0 \\;\\;\\Rightarrow\\;\\; \\nabla^2 \\phi  - \\frac{1}{c^2}\\frac{\\partial^2  \\phi}{\\partial t^2} = 0\\;\\;\\;\\;\\text{Wave potential for particle velocity}\n\\]\n\nNote that the term within the paranthesis is a scalar wave equation! (the equation is mathematically similar to the pressure wave equation).\nWe call \\(\\phi\\) the wave potential for particle velocity\nMore in general we say that: a scalar field, whose gradient is a vector field, is the potential of the vector field\n\nIn our case \\(\\phi\\) is the potential of \\(\\textbf{v}\\)\n\nWhat this means is that: for \\(\\textbf{v} = \\nabla\\phi\\) (i.e., there exists a velocity potential), \\(\\phi\\), the potential must satisfy the wave equation.\n\nIn other words, if I find a scalar function that satisfies the wave equation, this is a velocity potential.\n\n\nWe can do similar computations for the particle displacement, and obtain a scalar field \\(\\psi\\) for the particle displacement:\n\\[\n\\textbf{u} = \\nabla\\psi\n\\]\nAnd the potential for the displacement must satisfy the same wave equation:\n\\[\n\\nabla^2 \\psi  - \\frac{1}{c^2}\\frac{\\partial^2  \\psi}{\\partial t^2} = 0 \\;\\;\\;\\;\\text{Wave potential for particle displacement}\n\\]\nFinally, (after some additional passages) we can also say that the pressure:\n\\[\np = - K\\nabla^2\\psi\n\\]\n(pressure is equal to the Laplacian of the wave potential for the particle displacement)\nWhere \\(K=\\rho c^2\\)\nSince $ ^2= $:\n\\[\np = -\\rho\\frac{\\partial^2\\psi}{\\partial t^2}\n\\]\nwhere \\(\\rho\\) is the equilibrium density.",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#the-helmholtz-equation",
    "href": "the_wave_equation.html#the-helmholtz-equation",
    "title": "The Wave Equation",
    "section": "The Helmholtz Equation",
    "text": "The Helmholtz Equation\n\nThe wave potential equations for particle velocity and displacement are partial differential equation\nTo solve it we can apply the Laplace Transform and then we anti-transform to have the time domain solution\nIn our equations we have four differential operators (we are taking the derivative w.r.t. \\(x, y, z, t\\))\nApplying the Laplace Transform only applies to the time dependency that becomes algebric (i.e., no derivatives w.r.t. to time), however we will still have the derivatives w.r.t. space\nInstead of using the Laplace Transform we use the Fourier Transform of the wave potential equation\nRoughly speaking, the Laplace Transform and the Fourier Transform are “the same”, where we restrict \\(s=j\\omega\\), and \\(\\omega=(-\\inf, +\\inf)\\).\n\nLaplace Transform captures transient effects\nFourier Transform captures stationary effects\n\n\nLet’s apply the Fourier Transform to the scalar wave equation\n\\[\n\\nabla^2 \\psi  - \\frac{1}{c^2}\\frac{\\partial^2  \\psi}{\\partial t^2} = 0 \\;\\;\\;\\;\\text{Wave potential for particle displacement}\n\\]\n\n$^2 $ depends on space and does not depend on time (Fourier/Laplace operator does not apply to the different operator, however it does apply to \\(\\psi\\))\n\\(\\frac{1}{c^2}\\frac{\\partial^2  \\psi}{\\partial t^2}\\) depends on the second order time derivative\n\nSince:\n\\[\\ddot{y}(t) \\rightarrow \\mathcal{L}|_{s=j\\omega} \\rightarrow  (j\\omega)^2Y(j\\omega) = -\\omega^2Y(j\\omega)\\]\nWe obtain (grouping the Fourier transform of \\(\\psi\\) together):\n\\[\n[\\nabla^2 + k^2(\\textbf{r})]\\psi(\\textbf{r}, j\\omega)=0 \\;\\;\\;\\;\\text{Helmholtz equation}\n\\]\nwhere - \\(\\psi(\\textbf{r}, j\\omega)\\) is the Fourier Transform of \\(\\psi\\), which depends on a point in space \\(\\textbf{r}\\) and on \\(\\omega\\). - \\(k(\\textbf{r}) = \\frac{\\omega}{c(\\textbf{r})}\\), which is the wavenumber (see wave equation). - Note that \\(k(\\textbf{r})\\) is a function of \\(\\textbf{r}\\) because \\(c\\) is a function of \\(\\textbf{r}\\). The sound velocity is a function of space (and locally constant) because the equation holds everywhere in space - Note also that the Radian frequency \\(\\omega\\) is now a parameter of the equation, and the equation does not depend on time anymore.\nWe have simplified the equation which is now differential only w.r.t to space\nWhen we study the wave equation and we restrict ourselves to the Helmholtz equation, this is equivalent to assume that the wave equation has an harmonic solution:\n\\[\n\\Phi = \\phi e^{-i\\omega t}\n\\] - we assume a stationary wave of frequency \\(\\omega\\)\nand in fact, plugging this harmonic solution into the wave equation, we get a new wave equation:\n\\[\n\\nabla^2\\phi + k^2\\phi=0\n\\]\nComments\n\nWhen \\(r=(x,y,z)\\) we assume to have a Cartesian reference system\nUsing Polar or Cylindrical coordinates the differential operators are sligthly different, we need to do the coordinate transformation and use the Jacobian of the coordinate change (e.g., the Laplacian has a form that takes into account the Jacobian of the transformation).",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#solutions-to-the-helmholtz-equation",
    "href": "the_wave_equation.html#solutions-to-the-helmholtz-equation",
    "title": "The Wave Equation",
    "section": "Solutions to the Helmholtz Equation",
    "text": "Solutions to the Helmholtz Equation\n\nAnalytical solutions are available only in special cases: isotropy, omnidirection source: solutions are spherical waves\nDepending on the assumptions made on the medium (isotropy, anisotropy, and along which directions, etc), on the frequency and on the boundary conditions, different numerical solution methods can be defined\n\nWe have partial differential equations so we have boundary conditions\n\nThese numerical methods are the basis of acoustic models, as we call the simulators of acoustic propagation\n\nThis is different terminology from what we typically use in robotics (where models are the equations and the simultion is the numerical solution of the equation)\n\n\nTypical assumptions on the medium:\n\nRange dependent medium: \\(c(x,y,z) = c(r, z)\\)\nRange independent medium: $c(x,y,z) = c(z) $\n\n\nRay-Theory Solution\nUsing the Helmholtz equation it is equivalent to assume that the wave equation has an harmonic solution:\n\\[\n\\Phi = \\phi e^{-i\\omega t}\n\\]\nand if we plug this in in the wave equation we obtain:\n\\[\n\\nabla^2\\phi + k^2\\phi = 0\n\\]\nwhich is an equation in \\(\\phi\\) (unknown).\nIn this case \\(\\phi\\) can be separated into two components:\n\\[\n\\phi = F(x,y,z)e^{i\\varphi(x,y,z)}\n\\]\nwhere: - \\(F(x,y,z)\\) is the Amplitude function (real) - \\(\\varphi(x,y,z)\\) is the Phase function (real)\nNote: - This is never an exact solution of the Helmholtz equation - It is exact only when \\(\\omega \\rightarrow \\inf\\) - It is an approximate solution with an error that goes to zero as \\(\\omega \\rightarrow \\inf\\)\nThis means that it becomes a better approximation as the frequency increases - The Ray-Theory Solution is a High Frequency Approximation\n\nWhen is a frequency high?\nWe talk about high frequency when spatial variations in the medium (variations speed of sound) or properties of the boundaries (sea floor, surface) have dimentions much larger than the acoustic wavelength.\n\nWhat is the acoustic wavelength?\n\n\\(c \\approx 1500\\)m/s\nWavelength \\(\\lambda = \\frac{c}{f}\\)\nE.g. at 100 Hz: \\(\\lambda = 1500/100=15m\\)\n\n\nExample: Seasonal thermocline in Pianosa\n\n\n\n\n\n\n\n\nSeasonal thermocline in Pianosa started at about 20m and ended at 30m\nThis is a 10m\nThe variation of the properties of the medium is comparable to (in this case less than) the typical wavelength of a 100Hz signal.\n100Hz is a low frequency signal in this environment\nRay theory would not be suitable to model acoustic propagation\nIf instead we use a 100 kHz signal: \\(\\lambda = 1500/100000=0.015m = 15mm\\)\nThe spatial variations of the medium are now much larger then a \\(\\lambda=15mm\\) wavelength\n100 kHz is high frequency in this environment\nThe ray model is easy to understand, easy and fast to compute (ordinary differential equations), easy to visualise and can handle any medium anisotropy (this is why we had \\(F(x,y,z)\\) and \\(\\phi(x,y,z)\\) as a function of \\((x,y,z)\\))\nWe want to use the ray model when we can (and this depends on the environment!).\n\nConsider what happens in very shallow waters (e.g., 5 meters)\n\n\n\n\n\nNormal Modes and Fast Field Solution\n\nMethod that produces an exact solution with arbitrary precision\nApplies to range dependent and independent environments\nApplies to any frequency\n\nThe function \\(\\phi\\) is given by two functions, each dependent on only one variable (depth and range) \\[\n\\phi = F(z)G(r)\n\\]\nwhere - F is the depth function (complex: it has amplitude and phase) - G is the range function (complex)\n\nNote that we are not considering all three dimensions like we did for the ray model\nSolutions for full unisotropy is too complex to calculate\n\nThe depth function (which is then multiplied by the range function) is the series expansion of the so called normal modes, which is a weighted sum of eigenfunctions\n\n\n\n\n\n\n\nFigure: Normal modes, from Computational Ocean Acoustics\nIn the Figure above: - Depth 0: sea surface - Depth 100m: sea bottom\n\nSimilarly to a vibrant string, there are infinite but countable number of ways in which the string can vibrate: these are the modes\nSumming up these modes we can obtain all the possible movements of the string\nSumming up these modes we can obtain all the possible combinations of the acoustic field as a function of depth (we will be also multiplying this function by the range function)\nIf the sum of the modes gets to infinity (and hence we know how to analytically calculate the weights for each function), the solution is exact and can be calculated analytically\nSince we do not know how to calculate the weights analytically we need to use numerical methods\nSumming up an infinite number of functions is also not ideal so we truncate it\nThe more normal modes we use the better the solution\nNote that since we have an infinite series, the weights must go to zero (or the serie cannot converge)\n\nWe trucate when the weights decrease is under a desired threshold (typically trial and error)\n\nThe normal modes and fast field solution works at any frequency\n\nThe higher the frequency the higher the number of modes that we need to use\n\n\nThe range function: - The solution for the range function is calculated as solution of a Bessel equation via Hankel functions\n\nThe Bessel partial differential equation (pde) is the Helmholtz equation in cylindrical coordinates\n\nWhen the medium changes only as a function of range and depth we are in cylindrical coordinates\nWhen calculating the Laplacian operator in cylindical coordinates we have to consider the Jacobian of the coordinate transformation and we obtain a new equation: The Bessel equation\nThe Bessel equation can be solved more easily using Hankel functions\n\nVery accurate, long to compute\n\nWe typically only solve it for range independent environments\nTime to compute depends on the number of normal modes\nEasily an order of magnitude longer than the ray method, even for reduced number of modes (e.g. 30)\nWorks for every frequency, however:\n\nWe typically use it for low frequency when we can use lower number of modes\nAt high frequency it is more efficient to use the ray method (the result would be the same but with need higher number of modes, and rays are more efficient)\n\n\nNote that the range function \\(G(r)\\) is also needed for range-independent environments\n\n\n\nParabolic equation\n\nWe still have the product of two functions:\n\n\\[\n\\phi = F(r, \\theta, z)G(r)\n\\]\nwhere:\n\n\\(F(r, \\theta, z)\\) is the solution of the so-called parabolic equation (complex)\n\\(G\\): range function (complex)\nWe use cylindrical coordinates\nMedium can be fully anisotrope\nWell suited and valid for low-frequency, small grazing angle propagation (e.g., shallow water) and range-dependent environments\nGrazing angle (ITA: angolo di radenza): The 90-degree complement to angle of incidence is called the grazing angle or glancing angle.\n\n\n\n\n\n\n\n\n\nThis method is useful when the wavefront interacts with the seabed with small grazing angles.\n\nLet’s now see what happens what happens at the boundary between the sea bed and the water column.",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#water-seabed-interface",
    "href": "the_wave_equation.html#water-seabed-interface",
    "title": "The Wave Equation",
    "section": "Water-Seabed Interface",
    "text": "Water-Seabed Interface\n\nWhat happens at the boundary between the water and the seabed\nSeabed is typically non fluid but we approximate it as a fluid (for now)\nWe will look at what happens to acoustic propagation at a fluid-fluid interface (water-seabed interface)\nWe consider planar waves and we can draw the direction of propagation of the waves as in the picture below (the arrow is perpendicular to the wavefront of the planar wave)\nNote that the more we move away from the source the more the wavefronts can be approximated by planar wavefronts (assuming isotropy)\nWe assume a smooth interface between the two fluids\nIntrinsic attenuation in both fluids is negligible\n\n\n\n\n\n\n\n\n\nFluid 1: density \\(\\rho_1\\), speed of sound \\(c_1\\)\nFluid 2: density \\(\\rho_2\\), speed of sound \\(c_2\\)\nGiven an incident wave, it generates two wavefronts:\n\nA reflected wave back into the water (fluid 1) - same angle, sound speed is the same\nA transmitted wave into the second fluid - different angle, sound speed is different\n\nAs per Huygens’ Principle: Every point on a wavefront is itself the source of spherical wavelets, and the secondary wavelets emanating from different points mutually interfere. The sum of these spherical wavelets forms a new wavefront.\nSince the two fluids have different velocities, the wavefronts have a different grazing angle.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSee also Computational Ocean Acoustics, Chapter Fundamentals of Ocean Acoustics, Section 1.6 Bottom Loss. And How sound moves or Society of Exploration Geophysicists | Snell’s_law\n\nReflection at a fluid-fluid interface\nReflection coefficient R\n\nFor now, it is useful for us to define a quantity that relates the amplitude of the incident and the amplitude of the reflected wave.\nWe call this quantity Reflection coefficient R: ratio of the RMS amplitude of the reflected wave and of the incident wave (must be \\(\\le\\) 1).\n\n\\(\\theta_2\\) depends on the Snell’s Law (we expected this)\n\\[\n   \\frac{\\cos\\theta}{c} \\Rightarrow  k_2\\cos\\theta_2 = k_1\\cos\\theta_1\n   \\]\nwhere:\n\n\\[k_1 = \\frac{\\omega}{c_1}\\]\n\\[k_2 = \\frac{\\omega}{c_2}\\]\n\nare the wavenumbers in the two media. Note that \\(\\omega\\) is the same in both media.\nFrom the equation above we understand that when \\(c_2 &gt; c_1\\), the transmitted grazing angle is smaller than incident grazing angle (\\(\\theta_2 &lt; \\theta_1\\))\nThe reflection coefficient depends on the Snell’s Law:\n\nThe reflection coefficient assumes the following form:\n\n\\[\n   R = \\frac{\\rho_2c_2/\\sin\\theta_2 - \\rho_1c_1/\\sin\\theta_1}{\\rho_2c_2/\\sin\\theta_2 + \\rho_1c_1/\\sin\\theta_1} = \\frac{Z_2 - Z_1}{Z_2 + Z_1}\n   \\]\ndepends on: - the grazing angles - the sound speeds - the density of the two media\nComments: - We defined \\(\\rho c\\) as the acoustic impedence. In the reflection coefficient the acoustic impendence \\(\\rho c\\) is weighted by the sine of the grazing angles.\n\nThis means that \\(R\\) depends on \\(\\theta\\) and varies only based on the incident \\(\\theta_1\\) (we can always calculate \\(\\theta_2\\) based on the Snell’s Law).\n\nWe call: \\[\n   R = \\frac{Z_2 - Z_1}{Z_2 + Z_1}\\;\\;\\;\\;\\textbf{Rayleigh Reflection coefficient}\n   \\]\n\n\nCritical Angle\nWith the Rayleigh Reflection Coefficient, and specifically when \\(c_2&gt;c_1\\) (speed in the seabed higher than in water) it might happen that exists an angle \\(\\theta_1\\) where (remember that \\(\\omega_1=\\omega_2\\)):\n\\[\n\\cos\\theta_1 = \\frac{k_1}{k_2}=\\frac{c_1}{c_2}\n\\]\n\n\\(\\frac{c_1}{c_2} &lt; 1\\) so the angle \\(\\theta_1\\) is well defined\n\nSince,\n\\[k_2\\cos\\theta_2 = k_1\\cos\\theta_1\\]\nThis means that\n\\[\\cos\\theta_2=1 \\Rightarrow \\theta_2 = 0 \\Rightarrow R=1\\]\nThis implies exits an incident grazing angle for which the transmitted grazing angle is parallel to the interface between the two fluids. We call this angle critical grazing angle.\n\\[\n\\theta_c = \\arccos\\frac{c_1}{c_2}\n\\]\nAs \\(\\theta_1\\) decreases, and hence as \\(\\cos\\theta_1\\) increases, \\(\\cos\\theta_2\\) becomes larger than 1 (becomes imaginary and has a phase - see Figure below, dashed line - not too important for us )\\(\\Rightarrow\\) there is no transmission in the second fluid (total reflection).\n\\[\n\\theta &gt; \\theta_c \\Rightarrow |R| &lt; 1\n\\]\n\\[\n\\theta \\le \\theta_c \\Rightarrow |R| = 1\n\\]\n\nWhen \\(\\theta \\le \\theta_c\\) acoustic intensity is not lost due to the reflection.\nWhen \\(\\theta &gt; \\theta_c\\) acoustic intensity going back in the water is less.\n\n\n\n\n\n\n\n\nFigure: Reflection coefficient as a function of grazing angle for a hard-bottom halfspace. Solid curve: Magnitude. Dashed curve: Phase (Adapted from Computational Ocean Acoustics, Fig. 2.10)\n\nThe curve is calculated assigning specific values to \\(c_1, \\rho_1\\) and \\(c_2, \\rho_2\\) to calculate the coefficient R.\nWhen \\(\\theta \\le \\theta_c\\) the magnitude is 1 and it also has a phase (this is shown as dashed line in the picture above)\nIn the general case of lossy media (\\(c_i\\) complex), the reflection coefficient is complex, and, consequently, there is both a loss and a phase shift associated with each reflection.",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#intromission-angle",
    "href": "the_wave_equation.html#intromission-angle",
    "title": "The Wave Equation",
    "section": "Intromission Angle",
    "text": "Intromission Angle\n\nAnother special case of interest is when all energy is transmitted into the bottom, i.e., \\(|R| = 0\\)\nTotal transmission occurs at an angle \\(\\theta_0\\) given by:\n\n\\[\n\\theta_I = \\arctan \\sqrt \\frac{1-(c_2/c_1)^2}{[(\\rho_2c_2)/(\\rho_1c_1)]^2-1} \\Rightarrow R=0\n\\]\n\nThis angle is called the intromission angle\nCalculated from the Rayleigh Reflection Coefficient equation and from Snell’s Law.\n\nThis occurs when the fraction under the square root &gt;0. This happens when:\n\n\\(c_2 &lt; c_1\\) with \\(\\rho_2c_2 &gt; \\rho_1c_1 \\rightarrow \\rho_2 &gt; \\rho_1\\). Corresponds to low-speed, high-density sediments (e.g., muddy bottoms)\n\\(c_2 &gt; c_1\\) with \\(\\rho_2c_2 &lt; \\rho_1c_1\\). Corresponds to high-speed, low-density sediment and never occurs in ocean acoustics.\n\n\n\n\n\n\n\n\nFigure: Reflection coefficient as a function of grazing angle for a soft-bottom halfspace. Solid curve: Magnitude. Dashed curve: Phase (Adapted from Computational Ocean Acoustics, Fig. 2.12)\n\nNote that, grazing angle zero means that the planar wave is parallel to the halfspace and hence continue its propagation in the water (no transmission into the seabed, no reflection)",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#propagation-in-shallow-water",
    "href": "the_wave_equation.html#propagation-in-shallow-water",
    "title": "The Wave Equation",
    "section": "Propagation in shallow water",
    "text": "Propagation in shallow water\n\nLet’s see if the Reflection Coefficient is important\nFocus on shallow water propagation\nSummer Sound Speed Profile\nSource at 50m (in the thermocline)\nUse of a ray tracer to predict acoustic propagation\n\n\nfrom underwater_systems import ray_tracing\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n# bottom limited sound channel\nssp = ray_tracing.SSP([0, 15, 30, 50, 70, 80, 100],\n          [1530, 1530, 1525, 1510, 1509, 1508, 1508])\n\n\nplt.figure(figsize=(2, 3))\nssp.plot()\n\n\n\n\n\n\n\n\n\nt0, tf, dt = 0, 4, 0.01\nrt = ray_tracing.RayTracer(time=[t0, tf, dt], \n               source_depth=50, \n               min_range=0, \n               thetas=range(25, -25, -5), \n               ssp=ssp)\n\n\nplt.figure(figsize=(10, 4))\nrt.run()\n\n\n\n\n\n\n\n\n\nAll rays moving downwards reflect on the seabed\nEach ray would have its own grazing angle\nEvery time a ray hits the bottom, a part of the incident acoustic intensity carried by the ray comes back into the water\n\nFor example, a ray hitting the bottom at a 45deg, has a R=0.2 (see critical angle picture above) - wave with ampliture A, the first time hits the bottom reduces its intensity: 0.2*A, the second time, 0.2*0.2*A, … \\(0.2^n*A\\) - amplitude along the ray quickly decreases due to bottom reflections - these can have an impact that is higher than the intristric or geomatric attenuation\n\nNote that those rays with grazing angle less than the critical angle have \\(|R|=1\\) do not have attenuation, they all come back into the water column.\nThis means that in shallow water, where we always have bottom interactions, only those rays that bounce off the bottom with grazing angles less than the critical one, have no attenuation\n\nLong range propagation only at subcritical angles (low grazing)\n\nNote that the axis in the above plot have different scales (1:60)\nThis means that we have unavoidable interaction with the bottom\nThe plot below better represents the scenario\n\n\nplt.figure(figsize=(60, 1))\nrt.run()\n\n\n\n\n\n\n\n\n\nMore Realistic Seabeds\n\nWe have assumed so far that the bottom is a fluid\nOf course..they are not.\n\n\n\nWaves in an elastic medium\n\nIf the seabed is not fluid, it is elastic\nIn an elastic medium we have both:\n\nLongitudinal (or compressional) waves (Primary P waves) where each particle is deformed across the three dimentions (the same that propagates in a fluid).\nShear waves (Secondary S waves). Each particle can deform due to shear (each small volumes can rotately deform - twist). The movement of the particle due to a wave traveling in the x-axis, is a y-axis movement w.r.t to a x-axis propagation\n\n\n\n\n\n\n\n\n\n\n\n\nFigure: Images from University of Alicante\n\nThe two waves propagate in the same medium but have different propagation velocities:\n\n\\[c_s \\ll c_p\\]\n\n\nInterface waves (surface waves)\nClose to the interface between two media, and specifically between a fluid and an elastic medium, we have two more types of waves which are together called Surface waves,\n\nSurface waves can further distinguish into Love waves and Rayleigh waves, in honor to the scientists who theoretically demonstrated its existence.\nThey need to happen to satisfy the overall energy balance and to have continuity in the movement of the medium (displacement and velocity) - particles cannot detach.\n\n\n\n\n\n\n\n\n\n\n\nFigure: Images from University of Alicante\n\nLove waves moves along the y-axis, and their amplitude decreases as we move deeper into the medium (the farther away we are from the interface)\nRayleigh waves produce a circular motion of the particles. Amplitude decreases as we move away from the surface\nPropagation velocity close to that of S waves\n\n\n\nHeadwaves\n\nHead waves moves ahead the other waves\nMoves on the interface between the two mediums\nLongitudinal movement, but with a propagation speed of the second medium (when the speed of propagation of the Longitudinal waves is higher than the one of the first medium)\n\n\n\n\n\n\n\n\nFigure: Image from University of Utah",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#reflection-at-a-fluidsolid-interface",
    "href": "the_wave_equation.html#reflection-at-a-fluidsolid-interface",
    "title": "The Wave Equation",
    "section": "Reflection at a Fluid/Solid interface",
    "text": "Reflection at a Fluid/Solid interface\nAssumptions: - Planar wave - Smooth interface - Media attenuation negligible\nA Solid medium is characterised by two waves: - Transmitted Primary Wave (grazing angle \\(\\theta_P\\)) - Transmitted Seconday Wave (grazing angle \\(\\theta_S\\))\n\nSolid has a density \\(\\rho_2\\) and two propagation speeds (\\(c_P, c_S\\))\n\n\n\n\n\n\n\n\nWe can define the Rayleight Reflection Coefficient:\n\\[\nR = \\frac{Z_{tot}-Z_1}{Z_{tot}+Z_1}\n\\]\nwhere \\(Z_{tot}\\) is the total acoustic impendence and is defined as:\n\\[\nZ_{tot} = Z_P\\cos^2(2\\theta_P)+Z_S\\cos^2(2\\theta_S)\n\\]\nit is the weighted sum of the two impedence \\(Z_P\\) (acoustic impendence of the P wave), and of \\(Z_S\\) (acoustic impendence of the S wave)\nRemember that - the acoustic impedence is \\(Z=\\rho c\\) - sound is due the primary wave (so the sound speed is \\(c_P\\))\nSnell’s Law also holds for each one of the two waves:\n\\[\nk_1\\cos\\theta_1 = k_P\\cos\\theta_P = k_S\\cos\\theta_S\n\\]\nThis makes it possible to calculate \\(\\theta_P\\) and \\(\\theta_S\\) and hence to calculate the coefficient \\(R\\)\n\n\\(k\\)s are the wavenumbers for a planar wave with frequency \\(\\omega\\):\n\n\\(k_1 = \\omega/c_1\\)\n\\(k_P = \\omega/c_P\\)\n\\(k_S = \\omega/c_S\\)\n\n\nSince \\(c_S \\ll c_P\\), then \\(\\theta_P &lt; \\theta_S\\): - if \\(c_S &lt; c_1\\), the S wave has a grazing angle larger than the incident grazing angle (see figure above) - if \\(c_S &gt; c_1\\), the S wave grazing angle would be less than the incident grazing angle (and the",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#hard-vs-soft-bottoms",
    "href": "the_wave_equation.html#hard-vs-soft-bottoms",
    "title": "The Wave Equation",
    "section": "Hard vs Soft Bottoms",
    "text": "Hard vs Soft Bottoms\n\nClassify the rigidity of the seabed\nSeabed forms through two geological processes: sedimentation and compaction\nP and S wave velocities directly relate to the rigidity of the material\n\nWe can express the velocities as a function of the Lamé parameters or of the Young modulus\n\n\n\nSedimentation\n\nAccumulation of materials at the water-seabed interface (e.g. river outflows)\nPressure of layered sediments accumulated with time\n\nWe distinguish: - Unconsolidated sediments: material that is water saturated (e.g., sand, mud) with high porosity where the bond between grains is fragile. - Divided in three main classes (based only on their grain size): sand, silt, clay - I.e., average diameter of a gain of sand &gt; average diameter of a gain of clay - The difference between classes is only due to this (e.g., not due to chemical difference, etc)\n\nConsolidated sediments: as pressure grows due to stratification over the unconsolitated sediment pushes out the water and the sediment grains glue up (compaction).\n\nCompaction transforms unconsolidated sediment to consolidated: rocks\nConsolidated sediments have very low porosity\nTakes a very long time to happen\nExamples: limestone, sandstone (they retain in the name the unconsolidated sediment from which they originated\n\n\nAs we move down in the seabed we encounter a layer of Rocks due to results of geological/geophyical processes originated by the Earth interior and not due to compaction. - Example: basalts are due to this process\nAnd possible mixed situations\n\n\nGeoacoustic Properties\nThe table below provides some typical values for unconsolidated sediments (going from softer to harder sediments):\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\text{Sediment Type}\\)\n\\(M_z(\\phi)\\)\n\\(\\text{Porosity (%)}\\)\n\\(\\rho_2\\;\\;(g/cm^3)\\)\n\\(c_2\\;\\;(m/s)\\)\n\\(\\alpha_2\\;\\;(dB/\\lambda)\\)\n\\(c_{s,2}\\;\\;(m/s)\\)\n\n\n\n\n\\(\\text{Clay}\\)\n\\(9\\)\n\\(80\\)\n\\(1.2\\)\n\\(1470\\)\n\\(0.08\\)\n\\(-\\)\n\n\n\\(\\text{Silty clay}\\)\n\\(8\\)\n\\(75\\)\n\\(1.3\\)\n\\(1485\\)\n\\(0.10\\)\n\\(-\\)\n\n\n\\(\\text{Clayey silt}\\)\n\\(7\\)\n\\(70\\)\n\\(1.5\\)\n\\(1515\\)\n\\(0.15\\)\n\\(125\\)\n\n\n\\(\\text{Sand-silt-clay}\\)\n\\(6\\)\n\\(65\\)\n\\(1.6\\)\n\\(1560\\)\n\\(0.20\\)\n\\(290\\)\n\n\n\\(\\text{Sand-silt}\\)\n\\(5\\)\n\\(60\\)\n\\(1.7\\)\n\\(1605\\)\n\\(1.00\\)\n\\(340\\)\n\n\n\\(\\text{Silty-sand}\\)\n\\(4\\)\n\\(55\\)\n\\(1.8\\)\n\\(1650\\)\n\\(1.10\\)\n\\(390\\)\n\n\n\\(\\text{Very fine sand}\\)\n\\(3\\)\n\\(50\\)\n\\(1.9\\)\n\\(1680\\)\n\\(1.00\\)\n\\(410\\)\n\n\n\\(\\text{Fine sand}\\)\n\\(2\\)\n\\(45\\)\n\\(1.95\\)\n\\(1725\\)\n\\(0.80\\)\n\\(430\\)\n\n\n\\(\\text{Coarse sand}\\)\n\\(1\\)\n\\(40\\)\n\\(2.0\\)\n\\(1800\\)\n\\(0.90\\)\n\\(470\\)\n\n\n\n\n\\(M_z(\\phi)\\) represents the average size of the grains using the Krumbein phi (\\(\\phi\\)) logaritmic scale (\\(\\approx log_2(diameter)\\))\n\nvalue 1 is approximately 1mm\nvalue 9 is approximately 1μm\n\n\\(\\rho_2\\) is the density\n\\(c_2\\) typical value of the compressional wave speed (sound speed)\n\n\\(\\alpha_2\\) is the attenuation\n\\(c_{s,2}\\) propagation speed of the secondary waves (values &lt; 100m/s are not reported)\nAs we go towards harder sediment porosity decreases, density increases, sound speed increases, S wave speed increases, attenuation does not always increase\nNote that the attenuation \\(\\alpha_2\\) is higher than the attenuation of the compressional wave in the water column.\nGiven that porosity decreases, and density increases as we go down in the table we have harder and harder unconsolidated sediments.\nPorosity is a measure of the amount of void space, or empty space, in a material, such as rock, etc. It is defined as the ratio of the volume of empty space (voids) in a material to the total volume of the material (expressed as a percentage, and can range from 0% (completely solid) to 100% (completely empty)).\nNote that \\(c_s\\) is much slower than \\(c\\) and hence \\(\\theta_S &gt;&gt; \\theta_1\\)\nIn this case, when still have a critical angle but with \\(|R(\\theta_c)| &lt; 1\\) but there is some acoustic loss due to the secondary wave.\n\n\n\nReflection Coefficient for different seabeds\nNote that for some of the sediments (clay, silty clay and clayey silt) typical values of density \\(\\rho_2\\) and \\(c_2\\) favour the presence of an intromission angle. - We need to have \\(\\rho_2 &gt; \\rho_1\\) and \\(c_2&lt;c_1\\)\n\nWhen there are sediments, given that there are both a P and S transmitted wave, there is some acoustic transmission also for subcritical angles (compare this with results obtained with fuild-fluid interfaces)\nEnvironmental variations affect sound speed (especially in the water column) and create conditions to have intromission angles (e.g., clayey silt)\nDepending on the sediment, we still have a practical critical angle \\(\\theta_c\\), but for \\(\\theta=\\theta_c\\), \\(|R|\\) is slightly less than 1 (some acoustic intensity is lost in the seabed due to the fact that the seabed is solid)\n\n\n\n\n\n\n\n\n\nNo sediment has \\(|R|=1\\)\nHarder sediments have higher \\(|R|\\), more similar to the fluid-fluid case\nNote the presence of the intromission angle for clay and silty clay\nClayey silt has an in between behaviour and the presence of the intromission angle might depend on seasonal variations affecting the sound speed in the water and its relation to the sound speed in the sediment (e.g., warmer waters in summer would satisfy the intromission condition)\n\n\nSeabed transmission at subcritical angles\n\nThe effect of attenuation and seabed transmission at subcritical angles from the standpoint of the \\(R\\) coefficient can be obtained also considering a specific attenuation of the primary waves\nWe model the reflection coefficient when we are at the fluid-solid interface, and we obtain the same result:\n\ninserting a secondary wave speed or\nconsidering the interface as fluid-fluid and adding an intrinsic attenuation in the second medium\n\n\nIf we look at Case (b) in the sensitivity study shown in the picture below (specific values used are shown in the table below):\n\nIn the pictures below the Reflection Coefficient is represented as Loss (R=1 \\(\\Rightarrow\\) Loss=0)\nAs we vary the intrinsic attenuation \\(\\alpha_P\\):\n\nWhen \\(\\alpha_P=0\\), we have some Loss (or Reflection) until a critical angle (approx. 25deg)\nWhen \\(\\alpha_P=0.5\\), we have the same behaviour for angles larger than the critical, and a different behaviour under the critical angle (approx. 25deg). We are now modeling the seabed attenuation at subcritical angles (i.e., loss at subcritical angles) using the intrinsic attenuation coefficient in the second medium\n\n\nIf we look at Case (d) in the picture below: - We are now varying the speed of the S waves - If \\(c_S=0\\), is the case fluid-fluid and no attenuation (solid line corresponds to the solid line of Case (b) - As we increase \\(c_S\\) we start to have differences at both subcritical angles, and at supercritical angles.\n\nThis shows that we can model, at subcritical angles, the loss:\n\nconsidering a fluid-fluid interaction with high attenuation in the second fluid\nconsidering a fluid-solid interaction with a S wave speed of that should be \\(&gt;400m/s\\)\n\n\nComments: - Note that the two cases are especially different for supercritical angles - For shallow water propagation the supercritical propagation is quickly attenuated, and long range propagation can only happen at subcritical angles. - In this case, we can model acoustic propagation at subcritical angles considering the seabed as fluid but with a high and specific intrinsic attenuation\n\n\n\n\n\n\n\nFigure: Bottom-loss curves for different values of (a) the p-wave speed, (b) the p-wave attenuation, (c) the density, and (d) the s-wave speed. (From Computational Ocean Acoustics, Fig. 1.23)\nBottom parameters for reflection-loss calculations shown in the picture above (and \\(c_w=1500m/s\\), \\(\\rho_w=1000kg/m^3\\)):\n\n\n\n\n\n\n\n\n\n\n\n\n\\(c_P (m/s)\\)\n\\(c_S (m/s)\\)\n\\(\\alpha_P (dB/\\lambda_P)\\)\n\\(\\alpha_S (dB/\\lambda_s)\\)\n\\(\\rho (kg/m^3)\\)\n\n\n\n\n\\(\\text{Case (a)}\\)\n\\(-\\)\n\\(0\\)\n\\(0.5\\)\n\\(0\\)\n\\(2000\\)\n\n\n\\(\\text{Case (b)}\\)\n\\(1600\\)\n\\(0\\)\n\\(-\\)\n\\(0\\)\n\\(2000\\)\n\n\n\\(\\text{Case (c)}\\)\n\\(1600\\)\n\\(0\\)\n\\(0.5\\)\n\\(0\\)\n\\(-\\)\n\n\n\\(\\text{Case (d)}\\)\n\\(1600\\)\n\\(-\\)\n\\(0.0\\)\n\\(0\\)\n\\(2000\\)\n\n\n\n\n\n\nMore geoacoustic properties\n\nTypical values of other harder unconsolidated sediments\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\text{Sediment Type}\\)\n\\(\\text{Porosity (%)}\\)\n\\(\\rho_2\\;\\;(g/cm^3)\\)\n\\(c_2\\;\\;(m/s)\\)\n\\(\\alpha_2\\;\\;(dB/\\lambda)\\)\n\\(c_{s,2}\\;\\;(m/s)\\)\n\n\n\n\n\\(\\text{Gravel}\\)\n\\(35\\)\n\\(2.0\\)\n\\(1800\\)\n\\(0.6\\)\n\\(500\\)\n\n\n\\(\\text{Sandstone}\\)\n\\(-\\)\n\\(2.4\\)\n\\(3000\\)\n\\(0.1\\)\n\\(1500\\)\n\n\n\\(\\text{Basalt}\\)\n\\(-\\)\n\\(2.7\\)\n\\(5250\\)\n\\(0.1\\)\n\\(2500\\)\n\n\n\n\nNote how the secondary wave speed is now similar to that of the sound speed in the water (and much higher for the basalt)",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#is-the-water-seabed-interface-flat",
    "href": "the_wave_equation.html#is-the-water-seabed-interface-flat",
    "title": "The Wave Equation",
    "section": "Is the water-seabed interface flat?",
    "text": "Is the water-seabed interface flat?\n\nSo far we have assumed smooth interface, a plane\nSometimes is OK (e.g., plane of clay)\nMost of the time this assumption is much less valid (e.g., rocky seabed, sand ripples, etc.)",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#diffuse-reflection-scattering",
    "href": "the_wave_equation.html#diffuse-reflection-scattering",
    "title": "The Wave Equation",
    "section": "Diffuse reflection: scattering",
    "text": "Diffuse reflection: scattering\n\nIntroduces a further loss of acoustic intensity\nWe first need to have a way to measure the roughness of the surface\n\nGiven a surface:\n\n\n\n\n\n\n\n\nWe calculate the standard deviation \\(\\sigma\\) with respect to the flat surface of the function \\(\\zeta(x)\\):\n\n\\[\n\\sigma = \\frac{1}{\\bar{x}}\\sqrt{\\int_0^\\bar{x}\\zeta^2(x)dx}\n\\]\n\nHow do we measure the roughness of the seabed:\n\nthrough bathymetric measurements which measure the roughness with a specific resolution\nhigher resolutions can be obtained with more complex methods (e.g., underwater photogrammetry to reconstruct elevations)\n\nrobots with cameras can be helpful for this latter case where otherwise roughness can only be measured in shallow waters\n\n\nThe reflection on this rough surface is now more complex\n\nIf we think about the Huygens’ Principle: “Every point on a wavefront is itself the source of spherical wavelets, and the secondary wavelets emanating from different points mutually interfere. The sum of these spherical wavelets forms a new wavefront.” - In the planar case it is easy to see that the reflected wave is still a planar wave\n\n\n\n\n\n\n\n\nIn the case of a rough surface, the sum of the spherical wavelets interfere in a way that is not a planar wave\n\nReflections happen along all possible directions\n\nAmong all the directions that generate:\n\nOne corresponds to having an opposite direction of the incident wave. This is called backscatter direction\nOne corresponds to having the direction of the “normal” reflection (i.e., coherent reflection that we have with planar surfaces). This is called forward scatter direction\n\nSometime is called forward scatter direction everything that moves forward.\n\n\n\n\n\n\n\n\n\n\nRayleigh considered the reflection coefficient w.r.t to the forward scattering direction (the same as the coherent direction) and corrected the reflection coefficient of the planar waves to include the average roughness of the surface\nWhen we have scattering:\n\\[\nR^{'}(\\theta) = R(\\theta)e^{-0.5\\Gamma^2}\n\\]\nwhere \\(R(\\theta)\\) is the coherent reflection coefficient, \\(\\theta\\) is the grazing angle of the incident wave, and\n\\[\n\\Gamma = 2k\\sigma\\sin\\theta = 2\\frac{2\\pi}{\\lambda}\\sigma\\sin\\theta\n\\]\nwhere \\(k = \\frac{\\omega}{c} = \\frac{2\\pi}{\\lambda}\\) is the wavenumber, \\(\\lambda\\) is the wavelength, and \\(\\sigma\\) is the average roughness of the surface.\nComments:\n\nif \\(\\Gamma^2 \\rightarrow 0 \\;\\; \\Rightarrow e^{-0.5\\Gamma^2} \\rightarrow 1\\)\nif \\(\\Gamma^2 \\rightarrow \\inf \\;\\; \\Rightarrow e^{-0.5\\Gamma^2} \\rightarrow 0\\)\n\\(\\Gamma\\) depends on \\(\\theta\\) and this dependency means that the scattering effect decreases as the grazing angle decreases\n\nit is max when \\(\\theta\\)=90 deg, so when the incident wave is perpendicular to the surface of the seabed.\n\n\\(\\Gamma\\) depends on \\(\\frac{\\sigma}{\\lambda}\\). This means that is the wavelength \\(\\lambda\\) is much larger than \\(\\sigma\\) (average roughness), than \\(\\frac{\\sigma}{\\lambda}\\) is small, and \\(\\Gamma\\) is small.\n\nThis means that the original reflection coefficient does not need to be corrected\nRoughness of the surface is not absolute. Depends on the acoustic wavelength (frequency) of the incident wave.\nIf \\(f= 100Hz\\), wavelength \\(\\approx 15m\\). If we have sand ripples (i.e., \\(\\sigma \\approx 5cm\\)), \\(\\frac{\\sigma}{\\lambda} = \\frac{5e-2}{15}= 0.003\\). Scattering is not important.\nIf \\(f= 100kHz\\), wavelength \\(\\approx 15mm\\). \\(\\frac{\\sigma}{\\lambda} = \\frac{5e-2}{15e-3} = 3\\). Scattering is important and is an attenuation factor.\n\nWorking on the same seabed, depending on the frequency, scattering is something that I must consider or not.",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#scattering-strength-reverberation",
    "href": "the_wave_equation.html#scattering-strength-reverberation",
    "title": "The Wave Equation",
    "section": "Scattering Strength: Reverberation",
    "text": "Scattering Strength: Reverberation\nTo characterise scattering, we usually use these definitions:\nSurface (or Volume) Scattering Strength: ratio in dB of the intensity of the acoustic waves (of the sound) scattered by a unit surface area (or unit Volume), referenced to a unit distance, to the incident plane wave intensity \\[\nS = 10\\log\\frac{I_{scatt}}{I_{inc}}\n\\]\nNote the normalisation of the surface and of the distance.\nWhen do we have Volume Scattering? - When dealing with fish schools. They are not a continuos obstacle and we have scattering on each of the fish\nThe normalisation with respect to the surface, makes it possible to define:\nReverberation level (due to a unit intensity):\n\\[\nRL = S + 10\\log(A)  \\;\\; Surface\n\\]\nor\n\\[\nRL = S + 10\\log(V)  \\;\\; Volume\n\\]\nwhere \\(A\\) or \\(V\\) is the active scattering area or volume.\n\nActive area because we can have directionality with a specific footprint.\n\nThe reverberation level is \\(\\frac{I_{scatt}}{I_{inc}}\\cdot A\\) (for a surface).\nGiven that we have \\(10\\log(A)\\) (which can be higher than 0dB), the reverberation level can be higher than \\(0dB\\)",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#lamberts-law",
    "href": "the_wave_equation.html#lamberts-law",
    "title": "The Wave Equation",
    "section": "Lambert’s law",
    "text": "Lambert’s law\n\nCaptures the scattering strength empirically\n\nLambert’s law: Scattered and incident sound intensities both measured at unit distance from the scattering surface are related as: \\[\n\\frac{I_{scat}}{I_{inc}} = \\mu\\sin\\theta_i\\sin\\theta_s\n\\]\nwhere - \\(\\theta_i\\) is the incident angle - \\(\\theta_S\\) is the scattering angle that we are considering\nNote that this law can be applied for any angle (the Rayleigh reflection coeff. was valid for forward scatter only), and for the backscatter in particular.\nFor the backscattering: \\[\n\\theta_s=\\pi-\\theta_i\n\\]\nIn this case, the bottom backscattering strength: \\[\nS_B=10\\log\\mu + 10\\log\\sin^2\\theta_i\n\\]\nThe law is quite accurate thanks to the empirical factor \\(10\\log\\mu\\) that is obtained through in field measurements\n\\(10\\log\\mu\\) must be less than 0 dB. If zero we have no scattering (complete reflection).\nTypical values (obtained through historic field measurements): - silt: -35 dB (unconsolidated sediment, soft) - coarse sand: -20 dB (unconsolidated sediment, hard) - rock: -5 dB (consolidated sediment, hard)",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "the_wave_equation.html#parting-comments",
    "href": "the_wave_equation.html#parting-comments",
    "title": "The Wave Equation",
    "section": "Parting comments",
    "text": "Parting comments\n\nThe initial assumptions of smoothness of the surface, fluid-fluid, planar waves is not too bad\nWhen we have unconsolidated sediments, a wavelength which is bigger than roughness of the surface, the reflection can be modeled through the Rayleigh coefficient obtained for smooth surfaces, and fluid-fluid interfaces\nWhen we use acoustic models we need to decide how to model the environment\n\nIn the acoustic models we often encounter Bottom loss: reflection coefficient in dB\nSometime there are corrective parameters for scattering\nIf no corrective parameters are available, the models would be able to correctly capture only those cases where the wavelength is bigger than the roughness\nIf we need to work with wavelength and roughness that are comparable, and no corrective parameters are available, the model will underestimate the loss",
    "crumbs": [
      "The Wave Equation"
    ]
  },
  {
    "objectID": "environmental-variability.html#temperature-changes",
    "href": "environmental-variability.html#temperature-changes",
    "title": "Environmental Variability",
    "section": "Temperature changes",
    "text": "Temperature changes\n\n\n\n\n\n\n\n\nNote the variation in temperature across the hours of the day, and across days.\nGradient of temperature between 30m and 50m.\nSept. 21: three measurements\n\nnote how warming of surface temperature increases temperature of water with the thermocline that moves deeper and becomes steeper\nnote the presence of a surface duct in the first measurement at 06:53h. Warmer water is at 2m depth: in the morning the water is warmer at 2m depth.\n\nSept. 22: similar behaviour to that of Sept 21 but at 10:25h thermocline is higher.\nNote that different environments means different acoustic performance!\nFrom Sept 22 to Sept 28 bad weather and water mixing (not completely) which meant cooler water in the first part of the water column and less steep gradients.",
    "crumbs": [
      "Environmental Variability"
    ]
  },
  {
    "objectID": "environmental-variability.html#time-varying-thermocline",
    "href": "environmental-variability.html#time-varying-thermocline",
    "title": "Environmental Variability",
    "section": "Time-varying thermocline",
    "text": "Time-varying thermocline\nTranmission Loss - Source depth constant, SSP change\n\n\n\n\n\n\nFigure from John Potter, ACommsNet13.",
    "crumbs": [
      "Environmental Variability"
    ]
  },
  {
    "objectID": "environmental-variability.html#source-depth-variation",
    "href": "environmental-variability.html#source-depth-variation",
    "title": "Environmental Variability",
    "section": "Source depth variation",
    "text": "Source depth variation\nTranmission Loss - source depth change, SSP constant.\n\n\n\n\n\n\nFigure from John Potter, ACommsNet13.\n\nGeometry and environmental variations are key to characterise acoustic propagation, even in the same geographical location!",
    "crumbs": [
      "Environmental Variability"
    ]
  },
  {
    "objectID": "environmental-variability.html#what-is-the-extended-ellett-line",
    "href": "environmental-variability.html#what-is-the-extended-ellett-line",
    "title": "Environmental Variability",
    "section": "What is the Extended Ellett Line?",
    "text": "What is the Extended Ellett Line?\nThe Extended Ellett Line is a project to measure and understand the ocean west of the UK. We are looking at how and why the currents, temperature and salinity have changed over the past few decades. We also investigate the impact those changes have on ecosystems and local climate.\nEach year UK marine scientists cross the deep ocean between Scotland and Iceland on a research ship. Along the way the scientists measure the velocity, temperature and salinity of the ocean; at points 30 km apart, the ship stops and instruments are lowered though the water all the way to the seafloor. Water samples are also collected and analysed for a range of chemicals (including iron, nutrients and carbon) and biological content (including phytoplankton). The project is one of a small number of high-quality, long-term marine data sets in the North Atlantic Ocean and helps us to understand changes in ocean climate. It is relevant to the UK and northwest Europe because the warm water flowing past the Extended Ellett Line keeps winters warmer than expected for this latitude.\nThe history of the Extended Ellett Line began in 1948, when Jack R. Lumby of the Fisheries Laboratory in Lowestoft, UK, realised that use could be made of the regular passage of ships to the Ocean Weather Stations of the North Atlantic. These ships of opportunity collected underway measurements of sea surface temperature and salinity until 1996. From 1975 to 1996, scientists concentrated on the Rockall Trough, measuring the warm salty subtropical water flowing northwards west of the UK and Ireland. Since 1996 the annual expeditions travel as far Iceland in order to measure all the warm water that flows into the Nordics Seas from the eastern North Atlantic. We also measure cold northern water flowing southwards at the bottom of the sea.\nFrom https://projects.noc.ac.uk/ExtendedEllettLine/project-information\nEllet line, Glider Data",
    "crumbs": [
      "Environmental Variability"
    ]
  },
  {
    "objectID": "intro-short.html#lab-overview",
    "href": "intro-short.html#lab-overview",
    "title": "Underwater Systems (Short)",
    "section": "Lab overview",
    "text": "Lab overview\n\nRobots and Platforms\n\n\n\n\n\n\nAUV Zeno\n\n\n\n\n\n\n\nAUV X300\n\n\n\n\n\n\n\nBlueROV\n\n\n\n\n\n\n\nLocations\n\n\n\n\n\n\nHuman-Machine Teaming For the Maritime Environment",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#some-recent-and-current-projects",
    "href": "intro-short.html#some-recent-and-current-projects",
    "title": "Underwater Systems (Short)",
    "section": "Some Recent and Current Projects",
    "text": "Some Recent and Current Projects\n\nHuman-Machine Teaming For the Maritime Environment\n\n\n\n\n\n\nHuman-Machine Teaming For the Maritime Environment\n\n\n\n\n\n\n\nMultiple Autonomies\n\n\n\n\n\n\nMOOS-IvP autonomy system and human-machine teaming put into practice at the MIT facilities. (Courtesy of MIT)\n\n\n\n\n\n\n\nUnderwater acoustic source localization using a multi-robot system\n\n\n\n\n\n\nUnderwater acoustic source localization using a multi-robot system",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#whats-in-this-introduction",
    "href": "intro-short.html#whats-in-this-introduction",
    "title": "Underwater Systems (Short)",
    "section": "What’s in this introduction?",
    "text": "What’s in this introduction?\n\nMotivations\nWhy using robots to explore, monitor, inspect, etc. the sea?\nA short and rough description of underwater systems\nThe Topics of the course",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#motivations",
    "href": "intro-short.html#motivations",
    "title": "Underwater Systems (Short)",
    "section": "Motivations",
    "text": "Motivations\n\nScience Questions\n\n\n\n\nClimate Change\nClimate change, as we’ve seen in recent news and scientific reports, is a global phenomenon with far-reaching impacts on both terrestrial and aquatic ecosystems.\n\nGlobal Temperature Rise\nClimate change is fundamentally driven by the increase in global average temperatures year after year. This rise in temperature is not a uniform process but varies across different regions and timescales.\n\n\n\n\n\n\nThe plot illustrating this is the global average temperature relative to the pre-industrial average (1850-1900) shown above and taken from BBC | Global warming set to break key 1.5C limit for first time\nIn this plot: - Zero on the Vertical Axis: This represents a 50-year average temperature leading up to the 20th century. - Red and Blue Bars: These bars show annual average temperatures relative to the zero point. Red bars indicate years warmer than the average, and blue bars indicate cooler years.\nIt’s important to note that a global temperature rise of about 1.1 degrees Celsius over the last century might seem small, but it signifies a substantial energy imbalance in the Earth’s system. This energy imbalance is a key contributor to various climatic changes.\nThe energy required to raise the temperature of the Earth by one degree Celsius is immense.\n\n\n\nEffects of Temperature Rise\nThe consequences of this temperature rise are diverse, including:\n\nExtreme Weather Events: Such as droughts and floods.\nMelting Glaciers and Polar Ice Caps: Leading to rising sea levels.\nImpact on Marine Life: Changes in ocean temperatures and chemistry affect marine ecosystems.\n\n\nThe Role of Human Activities\nHuman activities, particularly the burning of fossil fuels like coal, oil, and gas, have been central to the rise in global temperatures.\n\n\n\n\n\n\nBurning fossil fuels releases greenhouse gases (GHGs) like carbon dioxide (CO2), methane (CH4), and others into the atmosphere. These gases trap heat from the sun, leading to a warming effect known as the greenhouse effect.\n\n\n\n\n\n\n\n\n\n\nMeasurements of air in ice cores show that for the past 800,000 years up until the 20th century, the atmospheric CO2 concentration stayed within the range 170 to 300 parts per million (ppm), making the recent rapid rise to more than 400 ppm over 200 years particularly remarkable.\n\nsee also here and here.\nThe levels of CO2 in the atmosphere have been remarkably stable over millennia but have shown an unprecedented rise in the last century. Understanding this requires examining historical data:\n\nIce Core Data: Scientists analyze ice cores to measure historical CO2 levels. These cores contain air bubbles that serve as time capsules, preserving atmospheric samples from the past.\nTrends Observed: Historical data shows a dramatic increase in CO2 levels, especially in recent decades. This rise is directly linked to human activities, particularly the burning of fossil fuels.\nAcceleration of CO2 Increase: The rate of increase in CO2 levels is not constant but accelerating. This acceleration implies a continually increasing rate of heat trapping in the atmosphere.\n\nSee also NASA | Ice Cores\n\n\nGlobal Temperature Anomalies\nLobal warming is not uniform across the Earth. Variations exist due to factors like geographical location, land-sea distribution, and atmospheric circulation patterns.\n\nfrom IPython.display import YouTubeVideo\n\nYouTubeVideo('LwRTw_7NNJs', width=800, height=600)\n\n\n\nOceans Are Absorbing Almost All of the Globe’s Excess Heat\n\n\n\n\n\n\n\nMore than 90 percent of the excess heat retained by the Earth as a result of increased greenhouse gases has been absorbed by the oceans.\nOcean temperatures have been consistently rising for at least three decades.\n\nMarine Robotics and Underwater Systems are central to this problem\n\n\n\nCelebrating Marie Tharp\n\nAmerican geologist and oceanographic cartographer who helped prove the theories of continental drift.\nShe co-published the first world map of the ocean floors.\nOn Nov 21, 1998, the Library of Congress named Tharp one of the greatest cartographers of the 20th century.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nManuscript painting of Heezen-Tharp “World ocean floor” map by Berann (~1955)",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#finding-the-endurance",
    "href": "intro-short.html#finding-the-endurance",
    "title": "Underwater Systems (Short)",
    "section": "Finding the Endurance",
    "text": "Finding the Endurance\nThe wreck of Sir Ernest Shackleton’s ship ‘Endurance’ has been found off the coast of Antarctica more than a century after it sank.\nHistorian Dan Snow, who is a member of the Endurance22 expedition team, said the discovery was ‘like a miracle’ and the ship is ‘almost perfectly preserved’\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsee this for more!",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#blackbox-recovery",
    "href": "intro-short.html#blackbox-recovery",
    "title": "Underwater Systems (Short)",
    "section": "Blackbox recovery",
    "text": "Blackbox recovery\nAir France 447 crash from Rio to Paris, June 1st, 2009\n\n\n\n\n\n\n&lt;/tr&gt;\n\n\n\n\n\n\n\n\n\nCountries involved - Origin - Destination - Airspace at accident location - Airline company - Engines manufactures - Insurance companies - Passengers citizenship\nRecovery\n\n13 aircrafts and 2 helicopters (Brasil, France, USA, Spain)\n8 Ships (Brasil, France, USA)\n2 6000m Manned Submarine (the Nautile)\n1 Nuclear Submarine (France)\n3 Autonomous Underwater Vehicles (AUVs)\n1 Remotely Operated Vehicle (ROV)\n1 million \\(km^2\\) of ocean explored\n\nAccording to Wikipedia, the continental United States of America (the 48 states between Canada and Mexico) is 8,080,464.4 square kilometers.\n\ncost \\(\\approx 30\\) MEuros (in 2009)\ncompleted 2Y after the crash\n\n&lt;td&gt; &lt;img src=\"./images/1.introduction/6.remora.png\" alt=\"black-box\" style=\"height: 150px;\"/&gt; &lt;/td&gt; \n&lt;/tr&gt;",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#installation-of-procution-well-jumper",
    "href": "intro-short.html#installation-of-procution-well-jumper",
    "title": "Underwater Systems (Short)",
    "section": "Installation of Procution Well Jumper",
    "text": "Installation of Procution Well Jumper",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#operating-rovs",
    "href": "intro-short.html#operating-rovs",
    "title": "Underwater Systems (Short)",
    "section": "Operating ROVs",
    "text": "Operating ROVs\n\nRemotely operated vehicles, or ROVs, allow us to explore the ocean without actually being in the ocean.\nThese underwater machines are controlled by a person typically on a surface vessel, using a joystick in a similar way that you would play a video game. A group of cables, or tether, connects the ROV to the ship, sending electrical signals back and forth between the operator and the vehicle.\nMost ROVs are equipped with at least a still camera, video camera, and lights, meaning that they can transit images and video back to the ship. Additional equipment, such as a manipulator or cutting arm, water samplers, and instruments that measure parameters like water clarity and temperature, may also be added to vehicles to allow for sample collection.\nFirst developed for industrial purposes, such as internal and external inspections of underwater pipelines and the structural testing of offshore platforms, ROVs are now used for many applications, many of them scientific.\nThey have proven extremely valuable in ocean exploration and are also used for educational programs at aquaria and to link to scientific expeditions live via the Internet.\nROVs range in size from that of a small computer to as large as a small truck. Larger ROVs are very heavy and need other equipment such as a winch to put them over the side of a ship and into the water.\nWhile using ROVs eliminates the “human presence” in the water, in most cases, ROV operations are simpler and safer to conduct than any type of occupied-submersible or diving operation because operators can stay safe (and dry!) on ship decks.\nROVs allow us to investigate areas that are too deep for humans to safely dive themselves, and ROVs can stay underwater much longer than a human diver, expanding the time available for exploration.\n\n\n\n\n\n\n\nWHOI Engineer Jared Schwartz pilots the remotely operated vehicle, Saab Seaeye Falcon to investigate an unrecovered mooring anchor. (Photo by Daniel Hentz, Woods Hole Oceanographic Institution). Ref. https://www.whoi.edu/news-insights/content/flight-of-the-underwater-falcon/\n\n\n\n\n\n\n\n\n\n\n\n\n\nOld approach:\n\nOff-shore operator acts on the vehicle\nOff-shore operator controls the arm motors directly (typically limited number of joints)\nInteractions between arm and vehicle’s body\nVoice coordination between the two\nManned Visual Feedback\n\n\nROV More recently\n\nStructured environments\n\nOperators know how the environment looks like\nROV have automatic controls for:\n\nstation keeping (attitude and position) using up to 8 motors (depends on how many DoF they can control)\n\nForce feedback to control the arm\nOperator acts on a representation of the manipulator (task space)\n\n\n\n\nWorking with ROVs\n\n13 people / 24h\n\n8 Pilot/Technicians (4h shift)\n4 Supervisors (4h shift)\n1 Superintendent (on call)\n\nHow long onboard?\n\n4 to 6 weeks\nROV crews work 6h 7/7\n\n\n\n\n\n\n\n\nPhoto by Woods Hole Oceanographic Institution. Ref. https://www.whoi.edu/press-room/news-release/whois-rov-jason-assists-with-the-successful-recovery-of-two-other-underwater-vehicles/\n\n\n\n\nOcean Exploration Trust’s ROV Hercules and Argus were stranded on the seafloor last week, but were recovered thanks to cooperation from several ocean science and exploration institutions Woods Hole, MA — On Thursday, September 2, 2021 the remotely operated vehicle (ROV) Jason succeeded in helping recover two other underwater vehicles, ROV Hercules and Argus, that were stranded on the seafloor off the coast of British Columbia last week when their tether to the surface broke. The operation came about as a result of close collaboration and mutual aid that are a hallmark of the ocean science and exploration community and the maritime community as a whole.",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#renewable-energy",
    "href": "intro-short.html#renewable-energy",
    "title": "Underwater Systems (Short)",
    "section": "Renewable energy",
    "text": "Renewable energy\n\nMarine energy: Tidal stream and wave power\nPower/communication cables\nFisheries and aquaculture\n\n\n\n\n\n\n\nNTNU AMOS - Centre for Autonomous Marine Operations and Systems\n\n\n\n\n\nFood\nHealth\nSecurity\nSafe",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#marine-autonomy-trends",
    "href": "intro-short.html#marine-autonomy-trends",
    "title": "Underwater Systems (Short)",
    "section": "Marine Autonomy Trends",
    "text": "Marine Autonomy Trends\n(Adapted from here)\n\n\n\n\n\n\n\nEarly commercial marine vehicles\nAt the turn of the century, there weren’t many commercial marine vehicles for sale",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#early-autonomy",
    "href": "intro-short.html#early-autonomy",
    "title": "Underwater Systems (Short)",
    "section": "Early Autonomy",
    "text": "Early Autonomy\n\n\n\n\nResearcher/Scientists were not content to be limited to the vehicle manufacturer’s autonomy system.\nHow can they run the autonomy system from the payload computer, i.e., Payload Autonomy\nDo you see limitations or concerns with this?\n\nAutonomy can be complex, sometime is data driven, might be not deterministic and might increase the risk of losing a vehicle. Losing an AUV might set a research group back many years.",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#marine-autonomy-trends-1",
    "href": "intro-short.html#marine-autonomy-trends-1",
    "title": "Underwater Systems (Short)",
    "section": "Marine Autonomy Trends",
    "text": "Marine Autonomy Trends\n\nScripted to Adaptive to Human-Machine Systems\n\n&lt;/tr&gt;\n\n\n\n\n\n\n\n\n\nScripted: trajectory largely determined before the vehicle is launched.\nSensing: Robot needs to know where it is.\nAdaptive, collaborative: trajectory depends in part on what collaborative vehicles are doing\nSensing: Robot needs to know about others\n\n\nScripted Missions\n\n20 years ago, marine autonomy was not a familiar term\nRobots went from waypoint to waypoint and were retrieved.\nScientist then offloaded the data for analysis.\nThe control system, navigation system and all software, were part of what the vehicle manufacturer sold with the platform.\n\n\n\n\n\n\n\n\n\nCan you think of limitations? and of advantages?\n\n\n\nAdaptive autonomy\n\n10 years later (10 years ago): the rise of adaptive autonomy.\nSensor data was no longer just retrieved, post-mission.\nRobots processed sensor data during the mission and adapted their mission trajectories.\nUnscripted, dynamic missions: the autonomy design space becomes huge.\nVehicle manafurers focused their supported missions based on core users.\nOpened payload interface to allow third party autonomy (industry, academic labs, defense labs)\n\n    &lt;td&gt;&lt;/td&gt;\n&lt;td&gt; &lt;img src=\"./images/1.introduction/22.adaptive-autonomy-reacquire.png\" alt=\"23.human-machine\" style=\"height: 350px;\"/&gt; &lt;/td&gt;\n&lt;/tr&gt;",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#marine-autonomy-trends-2",
    "href": "intro-short.html#marine-autonomy-trends-2",
    "title": "Underwater Systems (Short)",
    "section": "Marine Autonomy Trends",
    "text": "Marine Autonomy Trends\n\nMOOS-IvP: Increased level of adoption (original and highly recommended slide pack available here\n\n\n\n\n\n\n\n\n\nA tangible example\nAnd a blog post on the World’s first autonomous ferry\n\n\n\n\n\nAutonomy Trends\n\nAfter more than a decade of software innovation in the payload, there are now many good options for specialized autonomy, sensing, navigation and communications\nMany of these software solutions come from different developers/vendors.\n\n\n\n\n\nGreat benefits for end-users when best-of-practice solutions can be combined\nKey challenge: how to design system protocols/messages to develop systems of autonomy systems",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#autonomous-vehicles",
    "href": "intro-short.html#autonomous-vehicles",
    "title": "Underwater Systems (Short)",
    "section": "Autonomous Vehicles",
    "text": "Autonomous Vehicles\n\nROV\nAUV\nGliders\nSurface vehicles",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "intro-short.html#next-challenges",
    "href": "intro-short.html#next-challenges",
    "title": "Underwater Systems (Short)",
    "section": "Next Challenges",
    "text": "Next Challenges\n\n\n\n\n\n\n\nSee 00_Syllabus.ipynb\n\nfor course structure.",
    "crumbs": [
      "Underwater Systems (Short)"
    ]
  },
  {
    "objectID": "faq.html#general-questions",
    "href": "faq.html#general-questions",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "General Questions",
    "text": "General Questions\nQ: Who is this course intended for?\nA: This course is designed for students, researchers and professionals interested in ocean acoustics, sonar technology, and underwater vehicle dynamics.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "faq.html#course-content",
    "href": "faq.html#course-content",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "Course Content",
    "text": "Course Content\nQ: What are the main topics covered in this course?\nA: The course covers Ocean Acoustics, Ray Tracing, Oceanography, Wave Equations, Acoustic Systems, Sonar Equations, Networked Systems, Maritime Navigation, Dynamic Models of Underwater Vehicles, and a final project.\nQ: Are there any practical sessions?\nA: Yes, practical exercises, case studies, and simulations are incorporated throughout the course.\nQ: Will there be guest lectures?\nA: Yes, in 2025 guest lectures include:\n\nFlorian Schultz from ATLAS Elektronik on Acoustic Communications (May 2025)\nDavide Fenucci from National Oceanography Centre on Autonomy and Underwater Navigation (April/May 2025)",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "faq.html#assessment-and-projects",
    "href": "faq.html#assessment-and-projects",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "Assessment and Projects",
    "text": "Assessment and Projects\nQ: How are students assessed in this course?\nA: Assessment is through group reports, periodic discussions, a final project, and a final oral examination.\nQ: What does the final project involve?\nA: The final project involves designing or analyzing an acoustic system, a case study in ocean acoustics, or a project in underwater robotics, using ROS1 for practical implementation. Projects are handed out in Week 7, and students need to self-organize in groups of 3. If not, they will be assigned by the instructors.\nQ: What are the requirements for the final project?\nA: For the project, students will use ROS1. The preferred way to use it is using an Ubuntu virtual machine in Windows, or directly using Ubuntu. Students are required to learn ROS by themselves, although some of its concepts might be covered in class.\nQ: Are there resources available for learning ROS?\nA: Yes, key ROS resources include:\n\nThe official ROS website: ROS.org\nROS Wiki for tutorials and documentation: wiki.ros.org\nIt’s recommended to complete at least up to tutorial 12, plus tutorials 17 and 18 on the ROS Wiki. Further exploration of other tutorials will be an added value.\n\nQ: What operating system is recommended for using ROS?\nA: For Windows users, it is suggested to start with a virtual machine running Linux to utilize ROS. This setup should be sufficient for most tasks. However, creating a Linux partition might be convenient or necessary at a later stage. As for the ROS version, we recommend using ROS Melodic for Ubuntu 18.04, which is the same version currently running on Zeno.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "faq.html#enrollment-and-prerequisites",
    "href": "faq.html#enrollment-and-prerequisites",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "Enrollment and Prerequisites",
    "text": "Enrollment and Prerequisites\nQ: Are there any prerequisites for this course?\nA: There are no strict prerequisites for this course, as all necessary topics will be comprehensively covered to ensure understanding and success. However, possessing a foundational knowledge in Robotics can be beneficial for grasping the concepts more quickly.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "faq.html#msc-thesis-opportunities",
    "href": "faq.html#msc-thesis-opportunities",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "MSc Thesis Opportunities",
    "text": "MSc Thesis Opportunities\nQ: Are there opportunities to pursue a Master’s thesis related to the course topics?\nA: Yes, our MSc Thesis Program offers groundbreaking opportunities in underwater systems. We focus on five areas:\n\nHuman-Machine Teaming and Shared Autonomy\nMulti-Robot Collaboration\nPath Planning for Persistent Missions\nPolar Robotics\nQuantum Sensing and Navigation\n\nQ: What are the benefits of joining the MSc Thesis Program?\nA: The program offers:\n\nInnovative research topics with real-world impact\nExpert supervision by leading researchers\nAccess to state-of-the-art facilities\nA collaborative environment with peers and industry partners\nExcellent opportunities for career advancement in a rapidly evolving field\n\nQ: How can I apply for the MSc Thesis Program?\nA: The best way to apply is to send an email to me at andrea.munafo@unipi.it or talk to me during class. For detailed application procedures and deadlines, visit our MSc website. We welcome students with strong backgrounds in robotics, AI, or related fields.\nQ: Who can I contact for more information about the MSc Thesis Program?\nA: For more details, please feel free to talk to me in class or contact me via email at andrea.munafo@unipi.it.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "faq.html#additional-information",
    "href": "faq.html#additional-information",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "Additional Information",
    "text": "Additional Information\nQ: Where can I find more information about the course schedule and materials?\nA: Detailed information is available on the course website under the Syllabus and Course Materials sections.\nQ: Who can I contact for more questions?\nA: For further inquiries, please contact the course coordinator at andrea.munafo@unipi.it.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "toc.html",
    "href": "toc.html",
    "title": "Table of Contents",
    "section": "",
    "text": "from bin.toc import display_table_of_contents\n\n\n# Call this in your notebook to display the table of contents\ndisplay_table_of_contents(notebook_dir='.', exclude_list=['index.ipynb'], font_size='18px')\n\nNotebooks00_FAQ.ipynb00_Getting_started_with_Python_and_Jupyter_Notebook.ipynb00_MSc_Thesis_Program.ipynb00_Syllabus.ipynb00_TOC.ipynb01_intro.ipynb02_ocean_acoustics.ipynb03_the_acoustic_channel.ipynb04_ray_tracing.ipynb05_environmental-variability.ipynb06_oceanographic_sensors.ipynb07_the_wave_equation.ipynb08_acoustic_systems.ipynb09_the_sonar_equations.ipynb10_sonar_practical_applications.ipynb11_underwater_navigation.ipynb12_References.ipynbnews.ipynb",
    "crumbs": [
      "Table of Contents"
    ]
  },
  {
    "objectID": "msc_thesis_program.html",
    "href": "msc_thesis_program.html",
    "title": "Explore the Frontier of Underwater Systems: Join our MSc Thesis Program",
    "section": "",
    "text": "Dive into the future of robotics and AI with our MSc thesis opportunities in underwater systems. We’re seeking passionate and ambitious students ready to shape the future of this dynamic field.\nJoin us and contribute to pioneering research in one of our five key areas, underpinned by Autonomy and AI:\n\nHuman-Machine Teaming and Shared Autonomy: Get into the complexities of human-robot interaction and develop systems where human intelligence and robotic efficiency seamlessly merge. Your research will pave the way for advanced underwater exploration and operations, enhancing human-robot collaboration in challenging environments.\nMulti-Robot Collaboration: Imagine controlling a squad of autonomous underwater vehicles (AUVs) that intelligently adapt to complex mission objectives. Your work will focus on developing algorithms and strategies for effective multi-robot teamwork, revolutionizing how we conduct large-scale underwater missions.\nPath Planning for Persistent Missions: Tackle the challenges of long-duration underwater missions by creating innovative path-planning solutions. Your research will contribute to the development of AUVs capable of autonomously avoiding hazards like adverse weather or detection systems, ensuring mission success in even the most demanding conditions.\nPolar Robotics: Venture into the unexplored realms of polar environments. Your thesis will contribute to the design and deployment of robotic systems capable of withstanding extreme conditions, opening new doors for scientific discovery and environmental monitoring in the polar regions.\nQuantum Sensing and Navigation: Be at the forefront of integrating quantum technologies into underwater navigation systems. Your research will explore the potential of quantum sensors in enhancing the precision and reliability of underwater navigation, setting new standards in the field.\n\nWhy Choose Our Program?\n\nInnovative Research Topics: Engage with cutting-edge research that has real-world impact.\nExpert Supervision: Work alongside leading researchers in robotics and AI.\nState-of-the-Art Facilities: Access advanced labs and equipment.\nCollaborative Environment: Join a community of like-minded peers and industry partners.\nCareer Advancement: Position yourself at the forefront of a rapidly evolving industry.\n\nApplication Process Ready to embark on this exciting journey? Visit our website for more information on application procedures and deadlines. We welcome students with a strong background in robotics, AI, or related fields.\nContact Us For more details, feel free to contact Prof. Andrea Munafo at andrea.munafo@unipi.it.\nEmbark on a journey of innovation and discovery. Shape the future of underwater systems with us!",
    "crumbs": [
      "Explore the Frontier of Underwater Systems: Join our MSc Thesis Program"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Underwater Systems",
    "section": "",
    "text": "The course provides an extensive foundation in oceanic engineering, covering both theoretical concepts and practical applications.\nIt is part of the Master Degree in Robotics and Automation Engineering, University of Pisa, Italy\nTeaching semester: Spring 2025\nLanguage of instruction: Italian and English",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "index.html#course-coordinators",
    "href": "index.html#course-coordinators",
    "title": "Underwater Systems",
    "section": "Course coordinators:",
    "text": "Course coordinators:\nRiccardo Costanzi and Andrea Munafo",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "index.html#facts",
    "href": "index.html#facts",
    "title": "Underwater Systems",
    "section": "Facts",
    "text": "Facts\n\nVersion: 1\nCredits: 6\nStudy level: Master’s degree level",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "Underwater Systems",
    "section": "How to use",
    "text": "How to use\nYou can open and run each notebook in any order your prefer depending on your interest.",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "index.html#installation-instructions",
    "href": "index.html#installation-instructions",
    "title": "Underwater Systems",
    "section": "Installation Instructions",
    "text": "Installation Instructions\nThis repository’s notebooks are designed for Python 3.10 and depend on several Python libraries:\n\nnumpy\npandas\nmatplotlib\n\nFor a quick guide on setting up an Anaconda environment, refer to the 00_Getting_started_with_Python_and_Jupyter_Notebook.ipynb\n\nnotebook.\n\nTroubleshooting\nIn case you encounter the following error:\nModuleNotFoundError: No module named 'underwater_systems'\nIt indicates that the underwater_system package is missing. To install it, execute the following command in your terminal, ideally from the root directory of this repository:\npip install -e '.[dev]'\nExplanation of the command components: - -e: Stands for “editable”, allowing you to modify and immediately utilize the package during development. - .: Targets the current directory, implying the package is installed from here. - [dev]: Specifies additional “development” dependencies, which are required for tasks like documentation and testing, but not for the package’s core functionality.",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "index.html#automating-jupyter-book-pdf-generation-with-images",
    "href": "index.html#automating-jupyter-book-pdf-generation-with-images",
    "title": "Underwater Systems",
    "section": "Automating Jupyter Book PDF Generation with Images",
    "text": "Automating Jupyter Book PDF Generation with Images\n\nOverview\nThe build_jupyterbook_with_images.py script automates the process of including images in the PDF version of your Jupyter Book. It copies an ‘images’ directory to the appropriate location within the Jupyter Book build directory and then executes the build process.\n\n\nPrerequisites\n\nPython 3.x installed.\nJupyter Book and its dependencies are installed.\npyppeteer\n\n\n\nStructure Assumptions\n\nThe script is located in the bin directory at the project root.\nThe images folder, which contains the images to be included in the PDF, is at the project root.\nThe Jupyter notebooks are in a directory named nbs at the project root.\n\n\n\nUsage Instructions\n\nNavigate to the bin directory where the script is located.\nRun the script using Python:\npython bin/build_jupyterbook_with_images.py\nThe script will copy the images folder to the Jupyter Book build directory and then start the build process for the PDF version of your Jupyter Book.\nUpon successful execution, the script will output a confirmation message. If any issues occur, error messages will be displayed.\n\n\n\nFix for pyppeteer.errors.TimeoutError\nIf you encounter a timeout error (pyppeteer.errors.TimeoutError: Navigation Timeout Exceeded: 30000 ms exceeded) when building your Jupyter Book, a simple fix can be applied.\n\nSteps to Apply the Fix\n\nLocate the pdf.py file in your Jupyter Book or pyppeteer environment.\nOpen pdf.py and navigate to line 50.\nModify the line from:\nawait page.goto(f\"file:///{html_file}\", {\"waitUntil\": [\"networkidle2\"]})\nto:\nawait page.goto(f\"file:///{html_file}\", {\"timeout\": 0, \"waitUntil\": [\"networkidle2\"]})\n\nThis change sets the timeout to zero, effectively removing the timeout limit, and allows the page to load completely before proceeding, which can resolve the timeout issue encountered during the PDF generation process.",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "index.html#acknowledgements-and-references",
    "href": "index.html#acknowledgements-and-references",
    "title": "Underwater Systems",
    "section": "Acknowledgements and references",
    "text": "Acknowledgements and references\n\nRelevant textbooks and resources used to prepare these notebooks are reported in 00_Syllabus.ipynb",
    "crumbs": [
      "Underwater Systems"
    ]
  },
  {
    "objectID": "index.html#frequently-asked-questions-faq",
    "href": "index.html#frequently-asked-questions-faq",
    "title": "Underwater Systems",
    "section": "Frequently Asked Questions (FAQ)",
    "text": "Frequently Asked Questions (FAQ)\n\nsee notebook 00_FAQ.ipynb",
    "crumbs": [
      "Underwater Systems"
    ]
  }
]